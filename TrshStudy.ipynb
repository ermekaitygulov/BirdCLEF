{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c13125d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('Lab02_NMT')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from neural_network import NN_CATALOG\n",
    "from dataset.bird_clef import load_wav\n",
    "from dataset.augmentations import Normalize\n",
    "from experiment.base import get_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b9db757",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_meta = pd.read_csv('data/train_metadata_extended.csv')\n",
    "with open('data/scored_birds.json') as fin:\n",
    "    test_birds = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b6327e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_meta.loc[:, 'secondary_labels'] = all_meta.secondary_labels.apply(eval)\n",
    "all_meta['target_raw'] = all_meta.secondary_labels + all_meta.primary_label.apply(lambda x: [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28bb7ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_species = sorted(set(all_meta.target_raw.sum()))\n",
    "species2id = {s: i for i, s in enumerate(all_species)}\n",
    "id2species = {i: s for i, s in enumerate(all_species)}\n",
    "\n",
    "all_meta['target'] = all_meta.target_raw.apply(lambda species: [int(s in species) for s in all_species])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ce1c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data_root, meta_pd, augmentations=None, split_size=30):\n",
    "        super().__init__()\n",
    "        self.data_root = data_root\n",
    "        self.meta_pd = meta_pd\n",
    "        self.fnames = meta_pd.filename.values\n",
    "        self.augmentations = augmentations\n",
    "        self.split_size = split_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "    \n",
    "    def pad(self, wav, sr):\n",
    "        padded = wav\n",
    "        if len(wav) % int(sr * self.split_size) != 0:\n",
    "            crop_size = int(sr * self.split_size)\n",
    "            padded_shape = (len(wav) // crop_size  + 1) * crop_size \n",
    "            padded = np.zeros(padded_shape)\n",
    "            padded[:len(wav)] = wav\n",
    "        return padded\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fpath = os.path.join(self.data_root, self.fnames[idx])\n",
    "        wav, sr = load_wav(fpath, 0, 300)\n",
    "        if self.augmentations:\n",
    "            wav = self.augmentations(wav, None)\n",
    "        wav = self.pad(wav, sr)\n",
    "        wav = torch.tensor(wav).float()\n",
    "        \n",
    "        wav_len = wav.shape[0]\n",
    "        split_factor =  wav_len // (self.split_size * sr)\n",
    "        wav = wav.reshape((split_factor, wav_len // split_factor))\n",
    "        return wav\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb1bd01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, val_meta = train_test_split(all_meta, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d2b480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(\n",
    "    'data/train_audio',\n",
    "    val_meta, \n",
    "    augmentations=Normalize(p=1)\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=False,   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dd920b",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e89da60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "586a00c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttentionNet(\n",
       "  (audio2image): Sequential(\n",
       "    (0): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "    (1): AmplitudeToDB()\n",
       "  )\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=, flatten=False)\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (head): Attention(\n",
       "    (attn): Conv1d(512, 152, kernel_size=(1,), stride=(1,))\n",
       "    (cla): Conv1d(512, 152, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (loss): BCEWithLogitsLoss()\n",
       "  (mixup): Mixup()\n",
       "  (maxpool): Sequential(\n",
       "    (0): AdaptiveMaxPool1d(output_size=1)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path = 'Lab02_NMT/configs/baseline_config.yaml'\n",
    "model_path = f'Lab02_NMT/model_save/baseline_072/final-model.pt'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "with open(config_path) as fin:\n",
    "    config = yaml.safe_load(fin)\n",
    "\n",
    "model_config = config['model']\n",
    "if 'backbone_config' in model_config['params']:\n",
    "    model_config['params']['backbone_config']['pretrained'] = False\n",
    "data_config = config['data']\n",
    "model_class = NN_CATALOG[model_config['name']]\n",
    "\n",
    "model = model_class(len(all_species), int(data_config['crop_len'] // data_config['test_wav_len']),\n",
    "                    **model_config['params'])\n",
    "model.to(device)\n",
    "\n",
    "state_dict = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "53e2472a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2971/2971 [01:21<00:00, 36.43it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "treshold = 0.1\n",
    "split_size = test_dataset.split_size\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm(enumerate(test_dataloader), total = len(test_dataloader)):\n",
    "        batch = batch[0]\n",
    "        pred = model(batch.to(device))['logits']\n",
    "        pred = pred.cpu().numpy()\n",
    "        pred = pred.max(axis=0)\n",
    "        \n",
    "        fname = test_dataset.fnames[i]\n",
    "        target = test_dataset.meta_pd.iloc[i].target\n",
    "        \n",
    "        pred_list.append({\n",
    "            'filename': fname,\n",
    "            'pred': pred,\n",
    "            'target': target,\n",
    "        })\n",
    "pred_pd = pd.DataFrame(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "013b2338",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_np = np.array([p for p in pred_pd.pred])\n",
    "target_np = np.array([t for t in pred_pd.target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bf58a1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_pred(true, pred):\n",
    "    if true.sum() == 0:\n",
    "        return np.nan\n",
    "    return balanced_accuracy_score(\n",
    "            true,\n",
    "            pred\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aa8de16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_stat = []\n",
    "trsh = [*[0.01 * i for i in range(1, 10)], 0.1, 0.15, 0.2, 0.25]\n",
    "\n",
    "for t in trsh:\n",
    "    score_stat.append({\n",
    "        b: score_pred(\n",
    "            target_np[:, species2id[b]],\n",
    "            pred_np[:, species2id[b]] > t\n",
    "        )\n",
    "        for b in test_birds\n",
    "    })\n",
    "    \n",
    "score_stat = pd.DataFrame(score_stat).T\n",
    "score_stat.columns = trsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2ec20f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.02</th>\n",
       "      <th>0.03</th>\n",
       "      <th>0.04</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.06</th>\n",
       "      <th>0.07</th>\n",
       "      <th>0.08</th>\n",
       "      <th>0.09</th>\n",
       "      <th>0.10</th>\n",
       "      <th>0.15</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>akiapo</th>\n",
       "      <td>0.990226</td>\n",
       "      <td>0.992248</td>\n",
       "      <td>0.993428</td>\n",
       "      <td>0.993933</td>\n",
       "      <td>0.995113</td>\n",
       "      <td>0.995956</td>\n",
       "      <td>0.996124</td>\n",
       "      <td>0.996630</td>\n",
       "      <td>0.996967</td>\n",
       "      <td>0.997135</td>\n",
       "      <td>0.873315</td>\n",
       "      <td>0.748652</td>\n",
       "      <td>0.749326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aniani</th>\n",
       "      <td>0.985497</td>\n",
       "      <td>0.993086</td>\n",
       "      <td>0.827263</td>\n",
       "      <td>0.828612</td>\n",
       "      <td>0.829117</td>\n",
       "      <td>0.829792</td>\n",
       "      <td>0.829961</td>\n",
       "      <td>0.830467</td>\n",
       "      <td>0.830467</td>\n",
       "      <td>0.831141</td>\n",
       "      <td>0.832322</td>\n",
       "      <td>0.749325</td>\n",
       "      <td>0.749494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apapan</th>\n",
       "      <td>0.933666</td>\n",
       "      <td>0.945037</td>\n",
       "      <td>0.951996</td>\n",
       "      <td>0.935900</td>\n",
       "      <td>0.937427</td>\n",
       "      <td>0.940143</td>\n",
       "      <td>0.942010</td>\n",
       "      <td>0.943367</td>\n",
       "      <td>0.944725</td>\n",
       "      <td>0.945743</td>\n",
       "      <td>0.930156</td>\n",
       "      <td>0.891853</td>\n",
       "      <td>0.873211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barpet</th>\n",
       "      <td>0.795597</td>\n",
       "      <td>0.822552</td>\n",
       "      <td>0.828111</td>\n",
       "      <td>0.663129</td>\n",
       "      <td>0.663803</td>\n",
       "      <td>0.664477</td>\n",
       "      <td>0.664814</td>\n",
       "      <td>0.664982</td>\n",
       "      <td>0.665656</td>\n",
       "      <td>0.665824</td>\n",
       "      <td>0.666330</td>\n",
       "      <td>0.666498</td>\n",
       "      <td>0.666498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crehon</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elepai</th>\n",
       "      <td>0.890110</td>\n",
       "      <td>0.902256</td>\n",
       "      <td>0.907148</td>\n",
       "      <td>0.909003</td>\n",
       "      <td>0.911702</td>\n",
       "      <td>0.913727</td>\n",
       "      <td>0.915076</td>\n",
       "      <td>0.915751</td>\n",
       "      <td>0.844997</td>\n",
       "      <td>0.845672</td>\n",
       "      <td>0.849889</td>\n",
       "      <td>0.850564</td>\n",
       "      <td>0.852926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ercfra</th>\n",
       "      <td>0.499495</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hawama</th>\n",
       "      <td>0.954868</td>\n",
       "      <td>0.967546</td>\n",
       "      <td>0.936691</td>\n",
       "      <td>0.939564</td>\n",
       "      <td>0.941931</td>\n",
       "      <td>0.905497</td>\n",
       "      <td>0.906850</td>\n",
       "      <td>0.908878</td>\n",
       "      <td>0.909554</td>\n",
       "      <td>0.909892</td>\n",
       "      <td>0.912766</td>\n",
       "      <td>0.914456</td>\n",
       "      <td>0.876840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hawcre</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hawgoo</th>\n",
       "      <td>0.980633</td>\n",
       "      <td>0.746800</td>\n",
       "      <td>0.748484</td>\n",
       "      <td>0.748653</td>\n",
       "      <td>0.749326</td>\n",
       "      <td>0.749495</td>\n",
       "      <td>0.749663</td>\n",
       "      <td>0.499663</td>\n",
       "      <td>0.499663</td>\n",
       "      <td>0.499663</td>\n",
       "      <td>0.499663</td>\n",
       "      <td>0.499663</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hawhaw</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hawpet1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>houfin</th>\n",
       "      <td>0.845423</td>\n",
       "      <td>0.897955</td>\n",
       "      <td>0.902931</td>\n",
       "      <td>0.915587</td>\n",
       "      <td>0.922521</td>\n",
       "      <td>0.915535</td>\n",
       "      <td>0.918655</td>\n",
       "      <td>0.914989</td>\n",
       "      <td>0.918109</td>\n",
       "      <td>0.919323</td>\n",
       "      <td>0.916324</td>\n",
       "      <td>0.914911</td>\n",
       "      <td>0.912285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iiwi</th>\n",
       "      <td>0.959052</td>\n",
       "      <td>0.974619</td>\n",
       "      <td>0.980372</td>\n",
       "      <td>0.983249</td>\n",
       "      <td>0.986633</td>\n",
       "      <td>0.987817</td>\n",
       "      <td>0.988494</td>\n",
       "      <td>0.989340</td>\n",
       "      <td>0.990017</td>\n",
       "      <td>0.990017</td>\n",
       "      <td>0.992893</td>\n",
       "      <td>0.994585</td>\n",
       "      <td>0.995601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jabwar</th>\n",
       "      <td>0.873481</td>\n",
       "      <td>0.851799</td>\n",
       "      <td>0.854169</td>\n",
       "      <td>0.856032</td>\n",
       "      <td>0.857894</td>\n",
       "      <td>0.858741</td>\n",
       "      <td>0.858910</td>\n",
       "      <td>0.859079</td>\n",
       "      <td>0.831302</td>\n",
       "      <td>0.831640</td>\n",
       "      <td>0.832825</td>\n",
       "      <td>0.833164</td>\n",
       "      <td>0.805386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maupar</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omao</th>\n",
       "      <td>0.928577</td>\n",
       "      <td>0.934147</td>\n",
       "      <td>0.936004</td>\n",
       "      <td>0.937861</td>\n",
       "      <td>0.938536</td>\n",
       "      <td>0.939380</td>\n",
       "      <td>0.940224</td>\n",
       "      <td>0.940562</td>\n",
       "      <td>0.940900</td>\n",
       "      <td>0.941237</td>\n",
       "      <td>0.942588</td>\n",
       "      <td>0.942925</td>\n",
       "      <td>0.943094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>puaioh</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skylar</th>\n",
       "      <td>0.905325</td>\n",
       "      <td>0.927794</td>\n",
       "      <td>0.936214</td>\n",
       "      <td>0.942674</td>\n",
       "      <td>0.942191</td>\n",
       "      <td>0.940486</td>\n",
       "      <td>0.943279</td>\n",
       "      <td>0.940352</td>\n",
       "      <td>0.937076</td>\n",
       "      <td>0.938647</td>\n",
       "      <td>0.937640</td>\n",
       "      <td>0.939561</td>\n",
       "      <td>0.940783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warwhe1</th>\n",
       "      <td>0.829727</td>\n",
       "      <td>0.773244</td>\n",
       "      <td>0.754416</td>\n",
       "      <td>0.756790</td>\n",
       "      <td>0.736606</td>\n",
       "      <td>0.737623</td>\n",
       "      <td>0.739658</td>\n",
       "      <td>0.717778</td>\n",
       "      <td>0.718626</td>\n",
       "      <td>0.719304</td>\n",
       "      <td>0.698950</td>\n",
       "      <td>0.700137</td>\n",
       "      <td>0.678597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yefcan</th>\n",
       "      <td>0.982607</td>\n",
       "      <td>0.888855</td>\n",
       "      <td>0.891895</td>\n",
       "      <td>0.893752</td>\n",
       "      <td>0.894428</td>\n",
       "      <td>0.895441</td>\n",
       "      <td>0.896116</td>\n",
       "      <td>0.896454</td>\n",
       "      <td>0.896792</td>\n",
       "      <td>0.896960</td>\n",
       "      <td>0.897636</td>\n",
       "      <td>0.897974</td>\n",
       "      <td>0.848311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0.01      0.02      0.03      0.04      0.05      0.06      0.07  \\\n",
       "akiapo   0.990226  0.992248  0.993428  0.993933  0.995113  0.995956  0.996124   \n",
       "aniani   0.985497  0.993086  0.827263  0.828612  0.829117  0.829792  0.829961   \n",
       "apapan   0.933666  0.945037  0.951996  0.935900  0.937427  0.940143  0.942010   \n",
       "barpet   0.795597  0.822552  0.828111  0.663129  0.663803  0.664477  0.664814   \n",
       "crehon        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "elepai   0.890110  0.902256  0.907148  0.909003  0.911702  0.913727  0.915076   \n",
       "ercfra   0.499495  0.500000  0.500000  0.500000  0.500000  0.500000  0.500000   \n",
       "hawama   0.954868  0.967546  0.936691  0.939564  0.941931  0.905497  0.906850   \n",
       "hawcre        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "hawgoo   0.980633  0.746800  0.748484  0.748653  0.749326  0.749495  0.749663   \n",
       "hawhaw   0.500000  0.500000  0.500000  0.500000  0.500000  0.500000  0.500000   \n",
       "hawpet1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "houfin   0.845423  0.897955  0.902931  0.915587  0.922521  0.915535  0.918655   \n",
       "iiwi     0.959052  0.974619  0.980372  0.983249  0.986633  0.987817  0.988494   \n",
       "jabwar   0.873481  0.851799  0.854169  0.856032  0.857894  0.858741  0.858910   \n",
       "maupar        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "omao     0.928577  0.934147  0.936004  0.937861  0.938536  0.939380  0.940224   \n",
       "puaioh        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "skylar   0.905325  0.927794  0.936214  0.942674  0.942191  0.940486  0.943279   \n",
       "warwhe1  0.829727  0.773244  0.754416  0.756790  0.736606  0.737623  0.739658   \n",
       "yefcan   0.982607  0.888855  0.891895  0.893752  0.894428  0.895441  0.896116   \n",
       "\n",
       "             0.08      0.09      0.10      0.15      0.20      0.25  \n",
       "akiapo   0.996630  0.996967  0.997135  0.873315  0.748652  0.749326  \n",
       "aniani   0.830467  0.830467  0.831141  0.832322  0.749325  0.749494  \n",
       "apapan   0.943367  0.944725  0.945743  0.930156  0.891853  0.873211  \n",
       "barpet   0.664982  0.665656  0.665824  0.666330  0.666498  0.666498  \n",
       "crehon        NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "elepai   0.915751  0.844997  0.845672  0.849889  0.850564  0.852926  \n",
       "ercfra   0.500000  0.500000  0.500000  0.500000  0.500000  0.500000  \n",
       "hawama   0.908878  0.909554  0.909892  0.912766  0.914456  0.876840  \n",
       "hawcre        NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "hawgoo   0.499663  0.499663  0.499663  0.499663  0.499663  0.500000  \n",
       "hawhaw   0.500000  0.500000  0.500000  0.500000  0.500000  0.500000  \n",
       "hawpet1       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "houfin   0.914989  0.918109  0.919323  0.916324  0.914911  0.912285  \n",
       "iiwi     0.989340  0.990017  0.990017  0.992893  0.994585  0.995601  \n",
       "jabwar   0.859079  0.831302  0.831640  0.832825  0.833164  0.805386  \n",
       "maupar        NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "omao     0.940562  0.940900  0.941237  0.942588  0.942925  0.943094  \n",
       "puaioh        NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "skylar   0.940352  0.937076  0.938647  0.937640  0.939561  0.940783  \n",
       "warwhe1  0.717778  0.718626  0.719304  0.698950  0.700137  0.678597  \n",
       "yefcan   0.896454  0.896792  0.896960  0.897636  0.897974  0.848311  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d93d4a6",
   "metadata": {},
   "source": [
    "use teacher, no maxpool loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b4003a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'akiapo': 0.01,\n",
       " 'aniani': 0.01,\n",
       " 'apapan': 0.01,\n",
       " 'barpet': 0.01,\n",
       " 'crehon': nan,\n",
       " 'elepai': 0.01,\n",
       " 'ercfra': 0.05,\n",
       " 'hawama': 0.01,\n",
       " 'hawcre': nan,\n",
       " 'hawgoo': 0.2,\n",
       " 'hawhaw': 0.05,\n",
       " 'hawpet1': nan,\n",
       " 'houfin': 0.05,\n",
       " 'iiwi': 0.2,\n",
       " 'jabwar': 0.01,\n",
       " 'maupar': nan,\n",
       " 'omao': 0.1,\n",
       " 'puaioh': nan,\n",
       " 'skylar': 0.05,\n",
       " 'warwhe1': 0.01,\n",
       " 'yefcan': 0.01}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_stat.idxmax(axis=1).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763a707",
   "metadata": {},
   "source": [
    "no teacher, use maxpool loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5205294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'akiapo': 0.05,\n",
       " 'aniani': 0.01,\n",
       " 'apapan': 0.01,\n",
       " 'barpet': 0.01,\n",
       " 'crehon': nan,\n",
       " 'elepai': 0.01,\n",
       " 'ercfra': 0.01,\n",
       " 'hawama': 0.01,\n",
       " 'hawcre': nan,\n",
       " 'hawgoo': 0.1,\n",
       " 'hawhaw': 0.01,\n",
       " 'hawpet1': nan,\n",
       " 'houfin': 0.01,\n",
       " 'iiwi': 0.01,\n",
       " 'jabwar': 0.01,\n",
       " 'maupar': nan,\n",
       " 'omao': 0.01,\n",
       " 'puaioh': nan,\n",
       " 'skylar': 0.01,\n",
       " 'warwhe1': 0.01,\n",
       " 'yefcan': 0.01}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_stat.idxmax(axis=1).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366ec67b",
   "metadata": {},
   "source": [
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5ab736e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'akiapo': 0.1,\n",
       " 'aniani': 0.02,\n",
       " 'apapan': 0.03,\n",
       " 'barpet': 0.03,\n",
       " 'crehon': 0.05,\n",
       " 'elepai': 0.08,\n",
       " 'ercfra': 0.02,\n",
       " 'hawama': 0.02,\n",
       " 'hawcre': 0.05,\n",
       " 'hawgoo': 0.01,\n",
       " 'hawhaw': 0.01,\n",
       " 'hawpet1': 0.05,\n",
       " 'houfin': 0.05,\n",
       " 'iiwi': 0.25,\n",
       " 'jabwar': 0.01,\n",
       " 'maupar': 0.05,\n",
       " 'omao': 0.25,\n",
       " 'puaioh': 0.05,\n",
       " 'skylar': 0.07,\n",
       " 'warwhe1': 0.01,\n",
       " 'yefcan': 0.01}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_stat.idxmax(axis=1).fillna(0.05).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc7fa2b",
   "metadata": {},
   "source": [
    "teacher eff focal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "34c4e891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'akiapo': 0.08,\n",
       " 'aniani': 0.03,\n",
       " 'apapan': 0.07,\n",
       " 'barpet': 0.01,\n",
       " 'crehon': 0.05,\n",
       " 'elepai': 0.09,\n",
       " 'ercfra': 0.09,\n",
       " 'hawama': 0.06,\n",
       " 'hawcre': 0.05,\n",
       " 'hawgoo': 0.25,\n",
       " 'hawhaw': 0.02,\n",
       " 'hawpet1': 0.05,\n",
       " 'houfin': 0.1,\n",
       " 'iiwi': 0.09,\n",
       " 'jabwar': 0.05,\n",
       " 'maupar': 0.05,\n",
       " 'omao': 0.07,\n",
       " 'puaioh': 0.05,\n",
       " 'skylar': 0.1,\n",
       " 'warwhe1': 0.07,\n",
       " 'yefcan': 0.05}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_stat.idxmax(axis=1).fillna(0.05).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31f43512",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Lab02_NMT/model_save/baseline_39fvwny4/trsh.json', 'w') as fout:\n",
    "    json.dump(score_stat.idxmax(axis=1).fillna(0.05).to_dict(), fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32eb03d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
