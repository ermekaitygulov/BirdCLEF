{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f153a5d6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-07T06:57:34.357969Z",
     "iopub.status.busy": "2022-05-07T06:57:34.357170Z",
     "iopub.status.idle": "2022-05-07T06:57:40.846737Z",
     "shell.execute_reply": "2022-05-07T06:57:40.847526Z",
     "shell.execute_reply.started": "2022-05-07T06:48:40.278864Z"
    },
    "papermill": {
     "duration": 6.524553,
     "end_time": "2022-05-07T06:57:40.847927",
     "exception": false,
     "start_time": "2022-05-07T06:57:34.323374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import sys\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import random\n",
    "\n",
    "import librosa\n",
    "\n",
    "import torch\n",
    "import torchaudio as ta\n",
    "import timm\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e228ac9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T06:57:40.898654Z",
     "iopub.status.busy": "2022-05-07T06:57:40.897809Z",
     "iopub.status.idle": "2022-05-07T06:57:41.097859Z",
     "shell.execute_reply": "2022-05-07T06:57:41.098499Z",
     "shell.execute_reply.started": "2022-05-07T06:48:46.378871Z"
    },
    "papermill": {
     "duration": 0.230318,
     "end_time": "2022-05-07T06:57:41.098731",
     "exception": false,
     "start_time": "2022-05-07T06:57:40.868413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_root = '/kaggle/input/birdclef-2022'\n",
    "train_meta = pd.read_csv('../input/birdclef-data-with-wav-durations/train_metadata_extended.csv')\n",
    "ebird_taxonomy = pd.read_csv(os.path.join(data_root, 'eBird_Taxonomy_v2021.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3f44d92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T06:57:41.141580Z",
     "iopub.status.busy": "2022-05-07T06:57:41.140809Z",
     "iopub.status.idle": "2022-05-07T06:57:41.475243Z",
     "shell.execute_reply": "2022-05-07T06:57:41.475754Z",
     "shell.execute_reply.started": "2022-05-07T06:48:46.574369Z"
    },
    "papermill": {
     "duration": 0.357792,
     "end_time": "2022-05-07T06:57:41.475989",
     "exception": false,
     "start_time": "2022-05-07T06:57:41.118197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_meta.loc[:, 'secondary_labels'] = train_meta.secondary_labels.apply(eval)\n",
    "train_meta['target_raw'] = train_meta.secondary_labels + train_meta.primary_label.apply(lambda x: [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d586f66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T06:57:41.986760Z",
     "iopub.status.busy": "2022-05-07T06:57:41.525238Z",
     "iopub.status.idle": "2022-05-07T06:57:42.464054Z",
     "shell.execute_reply": "2022-05-07T06:57:42.463377Z",
     "shell.execute_reply.started": "2022-05-07T06:48:46.856279Z"
    },
    "papermill": {
     "duration": 0.967596,
     "end_time": "2022-05-07T06:57:42.464260",
     "exception": false,
     "start_time": "2022-05-07T06:57:41.496664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_species = sorted(set(train_meta.target_raw.sum()))\n",
    "species2id = {s: i for i, s in enumerate(all_species)}\n",
    "id2species = {i: s for i, s in enumerate(all_species)}\n",
    "\n",
    "train_meta['target'] = train_meta.target_raw.apply(lambda species: [int(s in species) for s in all_species])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d108b0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T06:57:42.511083Z",
     "iopub.status.busy": "2022-05-07T06:57:42.510332Z",
     "iopub.status.idle": "2022-05-07T06:57:42.513580Z",
     "shell.execute_reply": "2022-05-07T06:57:42.512956Z",
     "shell.execute_reply.started": "2022-05-07T06:48:47.762156Z"
    },
    "papermill": {
     "duration": 0.029646,
     "end_time": "2022-05-07T06:57:42.513744",
     "exception": false,
     "start_time": "2022-05-07T06:57:42.484098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_wav(fname, offset, duration):\n",
    "#     fname = 'afrsil1/XC125458.ogg'\n",
    "    fpath = os.path.join(data_root, 'train_audio', fname)\n",
    "    wav, sr = librosa.load(fpath, sr=None, duration=duration)\n",
    "    assert sr <= 32000, sr\n",
    "    return wav, sr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6e7ab8",
   "metadata": {
    "papermill": {
     "duration": 0.02014,
     "end_time": "2022-05-07T06:57:42.553618",
     "exception": false,
     "start_time": "2022-05-07T06:57:42.533478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63237e1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T06:57:42.608513Z",
     "iopub.status.busy": "2022-05-07T06:57:42.607551Z",
     "iopub.status.idle": "2022-05-07T06:57:42.612365Z",
     "shell.execute_reply": "2022-05-07T06:57:42.611661Z",
     "shell.execute_reply.started": "2022-05-07T06:48:47.769280Z"
    },
    "papermill": {
     "duration": 0.031893,
     "end_time": "2022-05-07T06:57:42.612550",
     "exception": false,
     "start_time": "2022-05-07T06:57:42.580657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_SIZE = 5 \n",
    "CONFIG = {\n",
    "    'crop_len': 30,\n",
    "    'sample_rate': 32000,    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8e9411c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T06:57:42.673347Z",
     "iopub.status.busy": "2022-05-07T06:57:42.667639Z",
     "iopub.status.idle": "2022-05-07T06:57:42.680131Z",
     "shell.execute_reply": "2022-05-07T06:57:42.681072Z",
     "shell.execute_reply.started": "2022-05-07T06:48:47.786582Z"
    },
    "papermill": {
     "duration": 0.042713,
     "end_time": "2022-05-07T06:57:42.681374",
     "exception": false,
     "start_time": "2022-05-07T06:57:42.638661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        duration = CONFIG['crop_len']\n",
    "        sample_rate = CONFIG['sample_rate']\n",
    "        \n",
    "        fname = self.df.iloc[idx]['filename']\n",
    "        wav_len = train_meta.iloc[0]['duration']\n",
    "        \n",
    "        max_offset = max(0, wav_len - duration)\n",
    "        random_offset = random.randint(0, max_offset)\n",
    "                \n",
    "        wav, sr = load_wav(fname, random_offset, duration)\n",
    "        to_pad = duration * sample_rate - wav.shape[0]\n",
    "        if to_pad > 0:\n",
    "            wav = np.pad(wav, (0, to_pad))\n",
    "            \n",
    "        target = self.df.iloc[idx]['target']\n",
    "        \n",
    "        # TODO: add weighting\n",
    "            \n",
    "        wav = torch.tensor(wav)\n",
    "        target = torch.tensor(target, dtype=float)\n",
    "        return {\n",
    "            'wav': wav,\n",
    "            'target': target,\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84a5483",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T09:17:01.036366Z",
     "iopub.status.busy": "2022-04-21T09:17:01.036048Z",
     "iopub.status.idle": "2022-04-21T09:17:01.05202Z",
     "shell.execute_reply": "2022-04-21T09:17:01.050779Z",
     "shell.execute_reply.started": "2022-04-21T09:17:01.036334Z"
    },
    "papermill": {
     "duration": 0.020214,
     "end_time": "2022-05-07T06:57:42.731581",
     "exception": false,
     "start_time": "2022-05-07T06:57:42.711367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3eb6f8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T06:57:42.792542Z",
     "iopub.status.busy": "2022-05-07T06:57:42.791355Z",
     "iopub.status.idle": "2022-05-07T06:57:42.833021Z",
     "shell.execute_reply": "2022-05-07T06:57:42.831689Z",
     "shell.execute_reply.started": "2022-05-07T06:53:09.104589Z"
    },
    "papermill": {
     "duration": 0.080888,
     "end_time": "2022-05-07T06:57:42.833267",
     "exception": false,
     "start_time": "2022-05-07T06:57:42.752379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.distributions import Beta\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, output_len, batch_time_factor,\n",
    "                 preproc_config=None, backbone_config=None,\n",
    "                 backbone_path=None):\n",
    "        super().__init__()\n",
    "        preproc_config = preproc_config or {}\n",
    "        backbone_config = backbone_config or {}\n",
    "\n",
    "        self.audio2image = self._init_audio2image(**preproc_config)\n",
    "        self.backbone = self._init_backbone(**backbone_config)\n",
    "        self.load_backbone(backbone_path)\n",
    "        self.head = self._init_head(self.backbone.feature_info[-1]['num_chs'], output_len)\n",
    "        self.loss = torch.nn.BCEWithLogitsLoss()\n",
    "        self.mixup = Mixup()\n",
    "        self.batch_time_factor = batch_time_factor\n",
    "\n",
    "    def forward(self, wav_tensor, y=None):\n",
    "        if self.training:\n",
    "            wav_tensor = self.batch_crop(wav_tensor)\n",
    "\n",
    "        spectrogram = self.audio2image(wav_tensor)\n",
    "        spectrogram = spectrogram.permute(0, 2, 1)\n",
    "        spectrogram = spectrogram[:, None, :, :]\n",
    "\n",
    "        if self.training:\n",
    "            spectrogram, y = self.apply_mixup(spectrogram, y)\n",
    "\n",
    "        x = self.backbone(spectrogram)\n",
    "        if self.training:\n",
    "            x = x.permute(0, 2, 1, 3)\n",
    "            x = self.batch_uncrop(x)\n",
    "            x = x.permute(0, 2, 1, 3)\n",
    "\n",
    "        logits = self.head(x)\n",
    "        loss = None\n",
    "        if y is not None:\n",
    "            loss = self.loss(logits, y)\n",
    "\n",
    "        return {'loss': loss, 'logits': logits.sigmoid()}\n",
    "\n",
    "    def apply_mixup(self, spectrogram, y):\n",
    "        spectrogram = spectrogram.permute(0, 2, 1, 3)\n",
    "        spectrogram = self.batch_uncrop(spectrogram)\n",
    "\n",
    "        spectrogram, y = self.mixup(spectrogram, y)\n",
    "\n",
    "        spectrogram = self.batch_crop(spectrogram)\n",
    "        spectrogram = spectrogram.permute(0, 2, 1, 3)\n",
    "        return spectrogram, y\n",
    "\n",
    "    def batch_crop(self, tensor):\n",
    "        factor = self.batch_time_factor\n",
    "        b, t = tensor.shape[:2]\n",
    "        tensor = tensor.reshape(b * factor, t // factor, *tensor.shape[2:])\n",
    "        return tensor\n",
    "\n",
    "    def batch_uncrop(self, tensor):\n",
    "        factor = self.batch_time_factor\n",
    "        b, t = tensor.shape[:2]\n",
    "        tensor = tensor.reshape(b // factor, t * factor, *tensor.shape[2:])\n",
    "        return tensor\n",
    "\n",
    "    @staticmethod\n",
    "    def _init_audio2image(sample_rate=32000, n_fft=2048, win_length=2048,\n",
    "                          hop_length=512, f_min=16, f_max=16386, pad=0,\n",
    "                          n_mels=256, power=2, normalized=False, top_db=80.):\n",
    "        mel = ta.transforms.MelSpectrogram(\n",
    "            sample_rate=sample_rate,\n",
    "            n_fft=n_fft,\n",
    "            win_length=win_length,\n",
    "            hop_length=hop_length,\n",
    "            f_min=f_min,\n",
    "            f_max=f_max,\n",
    "            pad=pad,\n",
    "            n_mels=n_mels,\n",
    "            power=power,\n",
    "            normalized=normalized,\n",
    "        )\n",
    "        db_scale = ta.transforms.AmplitudeToDB(top_db=top_db)\n",
    "        audio2image = torch.nn.Sequential(mel, db_scale)\n",
    "        return audio2image\n",
    "\n",
    "    @staticmethod\n",
    "    def _init_backbone(**backbone_kwargs):\n",
    "        backbone = timm.create_model(\n",
    "            **backbone_kwargs,\n",
    "            num_classes=0,\n",
    "            global_pool=\"\",\n",
    "            in_chans=1,\n",
    "        )\n",
    "        return backbone\n",
    "\n",
    "    @staticmethod\n",
    "    def _init_head(input_chs, output_len):\n",
    "        head = torch.nn.Sequential(\n",
    "            torch.nn.AdaptiveAvgPool2d(output_size=1),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(input_chs, output_len)\n",
    "        )\n",
    "        return head\n",
    "\n",
    "    def load_backbone(self, weights_path=None):\n",
    "        if weights_path:\n",
    "            state_dict = torch.load(weights_path)\n",
    "            conv1_weight = state_dict['conv1.weight']\n",
    "            state_dict['conv1.weight'] = conv1_weight.sum(dim=1, keepdim=True)\n",
    "            state_dict.pop('fc.bias')\n",
    "            state_dict.pop('fc.weight')\n",
    "            self.backbone.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "class Mixup(nn.Module):\n",
    "    def __init__(self, mix_beta=1):\n",
    "        super(Mixup, self).__init__()\n",
    "        self.beta_distribution = Beta(mix_beta, mix_beta)\n",
    "\n",
    "    def forward(self, X, Y, sample_weight=None):\n",
    "\n",
    "        bs = X.shape[0]\n",
    "        n_dims = len(X.shape)\n",
    "        perm = torch.randperm(bs)\n",
    "        mixup_weight = self.beta_distribution.rsample(torch.Size((bs,))).to(X.device)\n",
    "\n",
    "        if n_dims == 2:\n",
    "            X = mixup_weight.view(-1, 1) * X + (1 - mixup_weight.view(-1, 1)) * X[perm]\n",
    "        elif n_dims == 3:\n",
    "            X = mixup_weight.view(-1, 1, 1) * X + (1 - mixup_weight.view(-1, 1, 1)) * X[perm]\n",
    "        else:\n",
    "            X = mixup_weight.view(-1, 1, 1, 1) * X + (1 - mixup_weight.view(-1, 1, 1, 1)) * X[perm]\n",
    "\n",
    "        Y = mixup_weight.view(-1, 1) * Y + (1 - mixup_weight.view(-1, 1)) * Y[perm]\n",
    "\n",
    "        if sample_weight is None:\n",
    "            return X, Y\n",
    "        else:\n",
    "            sample_weight = mixup_weight.view(-1) * sample_weight + (1 - mixup_weight.view(-1)) * sample_weight[perm]\n",
    "            return X, Y, sample_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3791553f",
   "metadata": {
    "papermill": {
     "duration": 0.019702,
     "end_time": "2022-05-07T06:57:42.874105",
     "exception": false,
     "start_time": "2022-05-07T06:57:42.854403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2c31eb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T06:57:42.920002Z",
     "iopub.status.busy": "2022-05-07T06:57:42.919195Z",
     "iopub.status.idle": "2022-05-07T06:57:44.040373Z",
     "shell.execute_reply": "2022-05-07T06:57:44.040994Z",
     "shell.execute_reply.started": "2022-05-07T06:55:34.815230Z"
    },
    "papermill": {
     "duration": 1.146534,
     "end_time": "2022-05-07T06:57:44.041296",
     "exception": false,
     "start_time": "2022-05-07T06:57:42.894762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (audio2image): Sequential(\n",
       "    (0): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "    (1): AmplitudeToDB()\n",
       "  )\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=, flatten=Identity())\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=1)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=512, out_features=152, bias=True)\n",
       "  )\n",
       "  (loss): BCEWithLogitsLoss()\n",
       "  (mixup): Mixup()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = '../input/birdclefsubmit/final-model.pt'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "state_dict = torch.load(model_path, map_location=device)\n",
    "model = Net(len(all_species), int(CONFIG['crop_len'] // TEST_SIZE),\n",
    "            backbone_config=dict(model_name='resnet18', pretrained=False))\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731f4b67",
   "metadata": {
    "papermill": {
     "duration": 0.026115,
     "end_time": "2022-05-07T06:57:44.092294",
     "exception": false,
     "start_time": "2022-05-07T06:57:44.066179",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5ba99c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T06:57:44.147478Z",
     "iopub.status.busy": "2022-05-07T06:57:44.146528Z",
     "iopub.status.idle": "2022-05-07T06:57:44.155711Z",
     "shell.execute_reply": "2022-05-07T06:57:44.155008Z",
     "shell.execute_reply.started": "2022-05-07T06:55:41.521914Z"
    },
    "papermill": {
     "duration": 0.039347,
     "end_time": "2022-05-07T06:57:44.155904",
     "exception": false,
     "start_time": "2022-05-07T06:57:44.116557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_root, 'scored_birds.json')) as fin:\n",
    "    test_birds = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4adbb5ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T06:57:44.212351Z",
     "iopub.status.busy": "2022-05-07T06:57:44.211313Z",
     "iopub.status.idle": "2022-05-07T06:57:44.213279Z",
     "shell.execute_reply": "2022-05-07T06:57:44.213843Z",
     "shell.execute_reply.started": "2022-05-07T06:55:44.045136Z"
    },
    "papermill": {
     "duration": 0.035332,
     "end_time": "2022-05-07T06:57:44.214095",
     "exception": false,
     "start_time": "2022-05-07T06:57:44.178763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_folder):\n",
    "        super().__init__()\n",
    "        self.test_folder = test_folder\n",
    "        self.fnames = [f for f in os.listdir(test_folder) if f.endswith('.ogg')]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fpath = os.path.join(self.test_folder, self.fnames[idx])\n",
    "        wav, sr = load_wav(fpath, 0, None)\n",
    "        wav = torch.tensor(wav)\n",
    "        assert (13 * 5 * sr) > len(wav) \n",
    "        wav = wav[:len(wav) // 12 * 12].reshape((12, len(wav) // 12))\n",
    "        return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56dc2b6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T06:57:44.265689Z",
     "iopub.status.busy": "2022-05-07T06:57:44.264764Z",
     "iopub.status.idle": "2022-05-07T06:57:44.274340Z",
     "shell.execute_reply": "2022-05-07T06:57:44.274940Z",
     "shell.execute_reply.started": "2022-05-07T06:55:50.380979Z"
    },
    "papermill": {
     "duration": 0.037666,
     "end_time": "2022-05-07T06:57:44.275213",
     "exception": false,
     "start_time": "2022-05-07T06:57:44.237547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(os.path.join(data_root, 'test_soundscapes'))\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    drop_last=False,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fe84ddd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T06:57:44.335088Z",
     "iopub.status.busy": "2022-05-07T06:57:44.331396Z",
     "iopub.status.idle": "2022-05-07T06:57:45.798286Z",
     "shell.execute_reply": "2022-05-07T06:57:45.797405Z",
     "shell.execute_reply.started": "2022-05-07T06:55:52.279853Z"
    },
    "papermill": {
     "duration": 1.500086,
     "end_time": "2022-05-07T06:57:45.798548",
     "exception": false,
     "start_time": "2022-05-07T06:57:44.298462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.41s/it]\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "treshold = 0.1\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm(enumerate(test_dataloader)):\n",
    "        batch_size, part_count, part_size = batch.shape\n",
    "        batch = batch.reshape(batch_size * part_count, part_size)\n",
    "        pred = model(batch.to(device))['logits']\n",
    "        pred = pred.cpu().numpy()\n",
    "        pred = pred > treshold\n",
    "        \n",
    "        for j, chunk_pred in enumerate(pred):\n",
    "            inbatch_number = j // part_count\n",
    "            chunk_number = j % part_count + 1\n",
    "            f_idx = i * batch_size + inbatch_number\n",
    "            fname = test_dataset.fnames[f_idx]\n",
    "            prefix = fname.split('.')[0]\n",
    "            sufix = f'{5 * chunk_number}'\n",
    "            \n",
    "            pred_list.extend([{\n",
    "                'row_id': '_'.join([prefix, b, sufix]),\n",
    "                'target': chunk_pred[species2id[b]]\n",
    "            } for b in test_birds])\n",
    "pred_pd = pd.DataFrame(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "436578d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T06:57:45.854667Z",
     "iopub.status.busy": "2022-05-07T06:57:45.853786Z",
     "iopub.status.idle": "2022-05-07T06:57:45.878815Z",
     "shell.execute_reply": "2022-05-07T06:57:45.879519Z",
     "shell.execute_reply.started": "2022-05-07T06:55:59.342833Z"
    },
    "papermill": {
     "duration": 0.056897,
     "end_time": "2022-05-07T06:57:45.879751",
     "exception": false,
     "start_time": "2022-05-07T06:57:45.822854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_453028782_akiapo_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soundscape_453028782_aniani_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soundscape_453028782_apapan_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soundscape_453028782_barpet_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soundscape_453028782_crehon_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>soundscape_453028782_omao_60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>soundscape_453028782_puaioh_60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>soundscape_453028782_skylar_60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>soundscape_453028782_warwhe1_60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>soundscape_453028782_yefcan_60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              row_id  target\n",
       "0      soundscape_453028782_akiapo_5   False\n",
       "1      soundscape_453028782_aniani_5   False\n",
       "2      soundscape_453028782_apapan_5   False\n",
       "3      soundscape_453028782_barpet_5   False\n",
       "4      soundscape_453028782_crehon_5   False\n",
       "..                               ...     ...\n",
       "247     soundscape_453028782_omao_60   False\n",
       "248   soundscape_453028782_puaioh_60   False\n",
       "249   soundscape_453028782_skylar_60   False\n",
       "250  soundscape_453028782_warwhe1_60   False\n",
       "251   soundscape_453028782_yefcan_60   False\n",
       "\n",
       "[252 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_pd.to_csv(\"submission.csv\", index=False)\n",
    "pred_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824aafcf",
   "metadata": {
    "papermill": {
     "duration": 0.024344,
     "end_time": "2022-05-07T06:57:45.929290",
     "exception": false,
     "start_time": "2022-05-07T06:57:45.904946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25.841512,
   "end_time": "2022-05-07T06:57:47.771609",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-07T06:57:21.930097",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
