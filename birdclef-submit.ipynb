{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nsys.path.append('../input/birdclefmodels/')\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport librosa\n\nfrom matplotlib import pyplot as plt\nimport json\nimport random\nfrom tqdm import tqdm\nimport os\nimport yaml\n\nimport torch\nfrom torch import nn\nimport torchaudio as ta\nimport timm\nfrom torch.utils.data import Dataset, DataLoader\n\nimport neural_network","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-17T21:18:08.042636Z","iopub.execute_input":"2022-05-17T21:18:08.042999Z","iopub.status.idle":"2022-05-17T21:18:13.910124Z","shell.execute_reply.started":"2022-05-17T21:18:08.042917Z","shell.execute_reply":"2022-05-17T21:18:13.909321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_root = '/kaggle/input/birdclef-2022'\ntrain_meta = pd.read_csv('../input/birdclef-data-with-wav-durations/train_metadata_extended.csv')\nebird_taxonomy = pd.read_csv(os.path.join(data_root, 'eBird_Taxonomy_v2021.csv'))","metadata":{"execution":{"iopub.status.busy":"2022-05-17T21:18:21.930991Z","iopub.execute_input":"2022-05-17T21:18:21.931275Z","iopub.status.idle":"2022-05-17T21:18:22.126221Z","shell.execute_reply.started":"2022-05-17T21:18:21.931227Z","shell.execute_reply":"2022-05-17T21:18:22.125512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_meta.loc[:, 'secondary_labels'] = train_meta.secondary_labels.apply(eval)\ntrain_meta['target_raw'] = train_meta.secondary_labels + train_meta.primary_label.apply(lambda x: [x])","metadata":{"execution":{"iopub.status.busy":"2022-05-17T21:18:23.318793Z","iopub.execute_input":"2022-05-17T21:18:23.319059Z","iopub.status.idle":"2022-05-17T21:18:23.557273Z","shell.execute_reply.started":"2022-05-17T21:18:23.319029Z","shell.execute_reply":"2022-05-17T21:18:23.556556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_species = sorted(set(train_meta.target_raw.sum()))\nspecies2id = {s: i for i, s in enumerate(all_species)}\nid2species = {i: s for i, s in enumerate(all_species)}\n\ntrain_meta['target'] = train_meta.target_raw.apply(lambda species: [int(s in species) for s in all_species])","metadata":{"execution":{"iopub.status.busy":"2022-05-17T21:18:23.677599Z","iopub.execute_input":"2022-05-17T21:18:23.677998Z","iopub.status.idle":"2022-05-17T21:18:24.646142Z","shell.execute_reply.started":"2022-05-17T21:18:23.677966Z","shell.execute_reply":"2022-05-17T21:18:24.645444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_wav(fname, offset, duration):\n#     fname = 'afrsil1/XC125458.ogg'\n    fpath = os.path.join(data_root, 'train_audio', fname)\n    wav, sr = librosa.load(fpath, sr=None, duration=duration)\n    assert sr <= 32000, sr\n    return wav, sr","metadata":{"execution":{"iopub.status.busy":"2022-05-17T21:18:25.533555Z","iopub.execute_input":"2022-05-17T21:18:25.534039Z","iopub.status.idle":"2022-05-17T21:18:25.538809Z","shell.execute_reply.started":"2022-05-17T21:18:25.534002Z","shell.execute_reply":"2022-05-17T21:18:25.538106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model load","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndef init_model(config_path, model_path):\n    with open(config_path) as fin:\n        config = yaml.safe_load(fin)\n\n    model_config = config['model']\n    if 'backbone_config' in model_config['params']:\n        model_config['params']['backbone_config']['pretrained'] = False\n    else:\n        model_config['params']['backbone_config'] = {'pretrained': False}\n    data_config = config['data']\n    model_class = NN_CATALOG[model_config['name']]\n\n    model = model_class(len(all_species), int(data_config['crop_len'] // data_config['test_wav_len']),\n                        **model_config['params'])\n    model.to(device)\n\n    state_dict = torch.load(model_path, map_location=device)\n    model.load_state_dict(state_dict)\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2022-05-18T17:36:28.638092Z","iopub.execute_input":"2022-05-18T17:36:28.638738Z","iopub.status.idle":"2022-05-18T17:36:28.667075Z","shell.execute_reply.started":"2022-05-18T17:36:28.638641Z","shell.execute_reply":"2022-05-18T17:36:28.666378Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from neural_network import NN_CATALOG\n\nckpt_root = '../input/birdclefsubmit'\neff_path = ('eff/baseline_config.yaml', 'eff/final-model.pt')\nbaseline_path = ('baseline/baseline_config.yaml', 'baseline/final-model.pt')\n\nmodels = [init_model(*p) for p in [eff_path, baseline_path]]\nweights = None\n","metadata":{"execution":{"iopub.status.busy":"2022-05-17T21:18:29.190038Z","iopub.execute_input":"2022-05-17T21:18:29.19078Z","iopub.status.idle":"2022-05-17T21:18:32.911756Z","shell.execute_reply.started":"2022-05-17T21:18:29.19074Z","shell.execute_reply":"2022-05-17T21:18:32.911085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Blending(nn.Module):\n    def __init__(self, models, weights):\n        self.models = models\n        self.weights = weights or [1 / len(models) for _ in range(models)]\n        \n    def forward(self, wav_tensor):\n        pred = [m(wav_tensor)['logits'] for m in self.models]\n        pred = sum(p * w for p, w in zip(pred, self.weights))\n        return pred","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Torch Dataset","metadata":{}},{"cell_type":"code","source":"with open(os.path.join(data_root, 'scored_birds.json')) as fin:\n    test_birds = json.load(fin)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T21:18:35.890992Z","iopub.execute_input":"2022-05-17T21:18:35.891314Z","iopub.status.idle":"2022-05-17T21:18:35.900183Z","shell.execute_reply.started":"2022-05-17T21:18:35.891279Z","shell.execute_reply":"2022-05-17T21:18:35.89929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Compose:\n    def __init__(self, transforms: list):\n        self.transforms = transforms\n\n    def __call__(self, y: np.ndarray, sr):\n        for trns in self.transforms:\n            y = trns(y, sr)\n        return y\n    \n    \nclass AudioTransform:\n    def __init__(self, always_apply=False, p=0.5):\n        self.always_apply = always_apply\n        self.p = p\n\n    def __call__(self, y: np.ndarray, sr):\n        if self.always_apply:\n            return self.apply(y, sr=sr)\n        else:\n            if np.random.rand() < self.p:\n                return self.apply(y, sr=sr)\n            else:\n                return y\n\n    def apply(self, y: np.ndarray, **params):\n        raise NotImplementedError\n        \n        \nclass Normalize(AudioTransform):\n    def __init__(self, always_apply=False, p=1):\n        super().__init__(always_apply, p)\n\n    def apply(self, y: np.ndarray, **params):\n        max_vol = np.abs(y).max()\n        y_vol = y / max_vol\n        assert not np.isnan(y_vol).any(), f'{max_vol}'\n        return y_vol","metadata":{"execution":{"iopub.status.busy":"2022-05-17T21:18:37.381842Z","iopub.execute_input":"2022-05-17T21:18:37.382122Z","iopub.status.idle":"2022-05-17T21:18:37.393569Z","shell.execute_reply.started":"2022-05-17T21:18:37.382088Z","shell.execute_reply":"2022-05-17T21:18:37.392626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, test_folder, augmentations=None):\n        super().__init__()\n        self.test_folder = test_folder\n        self.fnames = [f for f in os.listdir(test_folder) if f.endswith('.ogg')]\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.fnames)\n    \n    def __getitem__(self, idx):\n        fpath = os.path.join(self.test_folder, self.fnames[idx])\n        wav, sr = load_wav(fpath, 0, None)\n        if self.augmentations:\n            wav = self.augmentations(wav, None)\n        wav = torch.tensor(wav)\n        assert (13 * 5 * sr) > len(wav) \n        wav = wav[:len(wav) // 12 * 12].reshape((12, len(wav) // 12))\n        return wav","metadata":{"execution":{"iopub.status.busy":"2022-05-17T21:18:38.279767Z","iopub.execute_input":"2022-05-17T21:18:38.280032Z","iopub.status.idle":"2022-05-17T21:18:38.290659Z","shell.execute_reply.started":"2022-05-17T21:18:38.28Z","shell.execute_reply":"2022-05-17T21:18:38.289899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(\n    os.path.join(data_root, 'test_soundscapes'),\n    Compose([Normalize(p=1)])\n)\ntest_dataloader = DataLoader(\n    test_dataset,\n    batch_size=1,\n    shuffle=False,\n    num_workers=2,\n    drop_last=False,   \n)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T21:18:39.135868Z","iopub.execute_input":"2022-05-17T21:18:39.136128Z","iopub.status.idle":"2022-05-17T21:18:39.14428Z","shell.execute_reply.started":"2022-05-17T21:18:39.136098Z","shell.execute_reply":"2022-05-17T21:18:39.143484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_topk(pred_proba, max_birds=5):\n    pred_proba = pred_proba[:, [species2id[b] for b in test_birds]]\n    mean_proba = pred_proba.mean(axis=0)\n    topk_birds = [i for i, _ in sorted(enumerate(mean_proba),\n                                       key=lambda x: x[1],\n                                       reverse=True)][:max_birds]\n    return topk_birds","metadata":{"execution":{"iopub.status.busy":"2022-05-17T21:18:39.772959Z","iopub.execute_input":"2022-05-17T21:18:39.7732Z","iopub.status.idle":"2022-05-17T21:18:39.778755Z","shell.execute_reply.started":"2022-05-17T21:18:39.773173Z","shell.execute_reply":"2022-05-17T21:18:39.777959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"treshold_dict = {'akiapo': 0.1,\n 'aniani': 0.05,\n 'apapan': 0.05,\n 'barpet': 0.05,\n 'crehon': 0.05,\n 'elepai': 0.05,\n 'ercfra': 0.01,\n 'hawama': 0.05,\n 'hawcre': 0.05,\n 'hawgoo': 0.05,\n 'hawhaw': 0.01,\n 'hawpet1': 0.05,\n 'houfin': 0.1,\n 'iiwi': 0.2,\n 'jabwar': 0.05,\n 'maupar': 0.05,\n 'omao': 0.05,\n 'puaioh': 0.05,\n 'skylar': 0.1,\n 'warwhe1': 0.05,\n 'yefcan': 0.15}","metadata":{"execution":{"iopub.status.busy":"2022-05-17T21:18:41.290078Z","iopub.execute_input":"2022-05-17T21:18:41.290356Z","iopub.status.idle":"2022-05-17T21:18:41.296613Z","shell.execute_reply.started":"2022-05-17T21:18:41.290325Z","shell.execute_reply":"2022-05-17T21:18:41.295737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_list = []\ntreshold = 0.1\nmodel.eval()\nwith torch.no_grad():\n    for i, batch in tqdm(enumerate(test_dataloader)):\n        batch_size, part_count, part_size = batch.shape\n        batch = batch.reshape(batch_size * part_count, part_size)\n        pred = model(batch.to(device))['logits']\n        pred = pred.cpu().numpy()\n#         topk_birds = find_topk(pred_proba, max_birds=10)\n        \n        for j, chunk_pred in enumerate(pred):\n            inbatch_number = j // part_count\n            chunk_number = j % part_count + 1\n            f_idx = i * batch_size + inbatch_number\n            fname = test_dataset.fnames[f_idx]\n            prefix = fname.split('.')[0]\n            sufix = f'{5 * chunk_number}'\n            \n            pred_list.extend([{\n                'row_id': '_'.join([prefix, b, sufix]),\n                'target': chunk_pred[species2id[b]] > treshold_dict[b] # if species2id[b] in topk_birds else False\n            } for b in test_birds])\npred_pd = pd.DataFrame(pred_list)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T21:18:48.618756Z","iopub.execute_input":"2022-05-17T21:18:48.619027Z","iopub.status.idle":"2022-05-17T21:18:55.144714Z","shell.execute_reply.started":"2022-05-17T21:18:48.618996Z","shell.execute_reply":"2022-05-17T21:18:55.143706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_pd.to_csv(\"submission.csv\", index=False)\npred_pd","metadata":{"execution":{"iopub.status.busy":"2022-05-17T21:18:56.822628Z","iopub.execute_input":"2022-05-17T21:18:56.822909Z","iopub.status.idle":"2022-05-17T21:18:56.846008Z","shell.execute_reply.started":"2022-05-17T21:18:56.822878Z","shell.execute_reply":"2022-05-17T21:18:56.845148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}