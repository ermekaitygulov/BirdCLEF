{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92514e5d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-22T18:23:04.709556Z",
     "iopub.status.busy": "2022-05-22T18:23:04.708521Z",
     "iopub.status.idle": "2022-05-22T18:23:13.050270Z",
     "shell.execute_reply": "2022-05-22T18:23:13.050940Z",
     "shell.execute_reply.started": "2022-05-22T17:35:06.681267Z"
    },
    "papermill": {
     "duration": 8.397798,
     "end_time": "2022-05-22T18:23:13.051266",
     "exception": false,
     "start_time": "2022-05-22T18:23:04.653468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "sys.path.append('../input/birdclefmodels/')\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import librosa\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchaudio as ta\n",
    "import timm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b69ac991",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T18:23:13.153518Z",
     "iopub.status.busy": "2022-05-22T18:23:13.152487Z",
     "iopub.status.idle": "2022-05-22T18:23:13.398601Z",
     "shell.execute_reply": "2022-05-22T18:23:13.399613Z",
     "shell.execute_reply.started": "2022-05-22T17:35:13.422174Z"
    },
    "papermill": {
     "duration": 0.305104,
     "end_time": "2022-05-22T18:23:13.399891",
     "exception": false,
     "start_time": "2022-05-22T18:23:13.094787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_root = '/kaggle/input/birdclef-2022'\n",
    "train_meta = pd.read_csv('../input/birdclef-data-with-wav-durations/train_metadata_extended.csv')\n",
    "ebird_taxonomy = pd.read_csv(os.path.join(data_root, 'eBird_Taxonomy_v2021.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d1dee4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T18:23:13.512111Z",
     "iopub.status.busy": "2022-05-22T18:23:13.510782Z",
     "iopub.status.idle": "2022-05-22T18:23:13.657872Z",
     "shell.execute_reply": "2022-05-22T18:23:13.658657Z",
     "shell.execute_reply.started": "2022-05-22T17:35:13.587990Z"
    },
    "papermill": {
     "duration": 0.214333,
     "end_time": "2022-05-22T18:23:13.658853",
     "exception": false,
     "start_time": "2022-05-22T18:23:13.444520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_meta.loc[:, 'secondary_labels'] = train_meta.secondary_labels.apply(eval)\n",
    "train_meta['target_raw'] = train_meta.secondary_labels + train_meta.primary_label.apply(lambda x: [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ee374b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T18:23:13.760927Z",
     "iopub.status.busy": "2022-05-22T18:23:13.760053Z",
     "iopub.status.idle": "2022-05-22T18:23:14.854051Z",
     "shell.execute_reply": "2022-05-22T18:23:14.853087Z",
     "shell.execute_reply.started": "2022-05-22T17:35:13.668984Z"
    },
    "papermill": {
     "duration": 1.146437,
     "end_time": "2022-05-22T18:23:14.854221",
     "exception": false,
     "start_time": "2022-05-22T18:23:13.707784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_species = sorted(set(train_meta.target_raw.sum()))\n",
    "species2id = {s: i for i, s in enumerate(all_species)}\n",
    "id2species = {i: s for i, s in enumerate(all_species)}\n",
    "\n",
    "train_meta['target'] = train_meta.target_raw.apply(lambda species: [int(s in species) for s in all_species])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89a73149",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T18:23:14.912198Z",
     "iopub.status.busy": "2022-05-22T18:23:14.911204Z",
     "iopub.status.idle": "2022-05-22T18:23:14.914537Z",
     "shell.execute_reply": "2022-05-22T18:23:14.913868Z",
     "shell.execute_reply.started": "2022-05-22T17:35:14.425249Z"
    },
    "papermill": {
     "duration": 0.033969,
     "end_time": "2022-05-22T18:23:14.914652",
     "exception": false,
     "start_time": "2022-05-22T18:23:14.880683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_wav(fname, offset, duration):\n",
    "#     fname = 'afrsil1/XC125458.ogg'\n",
    "    fpath = os.path.join(data_root, 'train_audio', fname)\n",
    "    wav, sr = librosa.load(fpath, sr=None, duration=duration)\n",
    "    assert sr <= 32000, sr\n",
    "    return wav, sr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea1d655",
   "metadata": {
    "papermill": {
     "duration": 0.024016,
     "end_time": "2022-05-22T18:23:14.964157",
     "exception": false,
     "start_time": "2022-05-22T18:23:14.940141",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### No call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cee19b22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T18:23:15.042216Z",
     "iopub.status.busy": "2022-05-22T18:23:15.031586Z",
     "iopub.status.idle": "2022-05-22T18:23:15.046194Z",
     "shell.execute_reply": "2022-05-22T18:23:15.046688Z",
     "shell.execute_reply.started": "2022-05-22T17:35:20.319765Z"
    },
    "papermill": {
     "duration": 0.057996,
     "end_time": "2022-05-22T18:23:15.046871",
     "exception": false,
     "start_time": "2022-05-22T18:23:14.988875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MelSpecComputer:\n",
    "    def __init__(self, sr, n_mels, fmin, fmax, **kwargs):\n",
    "        self.sr = sr\n",
    "        self.n_mels = n_mels\n",
    "        self.fmin = fmin\n",
    "        self.fmax = fmax\n",
    "        kwargs[\"n_fft\"] = kwargs.get(\"n_fft\", self.sr//10)\n",
    "        kwargs[\"hop_length\"] = kwargs.get(\"hop_length\", self.sr//(10*4))\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __call__(self, y):\n",
    "\n",
    "        melspec = librosa.feature.melspectrogram(\n",
    "            y=y, sr=self.sr, n_mels=self.n_mels, fmin=self.fmin, fmax=self.fmax, **self.kwargs,\n",
    "        )\n",
    "\n",
    "        melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "        return melspec\n",
    "    \n",
    "    \n",
    "def mono_to_color(X, eps=1e-6, mean=None, std=None):\n",
    "    mean = mean or X.mean()\n",
    "    std = std or X.std()\n",
    "    X = (X - mean) / (std + eps)\n",
    "    \n",
    "    _min, _max = X.min(), X.max()\n",
    "\n",
    "    if (_max - _min) > eps:\n",
    "        V = np.clip(X, _min, _max)\n",
    "        V = 255 * (V - _min) / (_max - _min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        V = np.zeros_like(X, dtype=np.uint8)\n",
    "\n",
    "    return V\n",
    "\n",
    "def crop_or_pad(y, length):\n",
    "    if len(y) < length:\n",
    "        y = np.concatenate([y, np.zeros(length - len(y))])        \n",
    "    elif len(y) > length:\n",
    "        y = y[:length]\n",
    "    return y\n",
    "\n",
    "\n",
    "class NoCallDataset(Dataset):\n",
    "    def __init__(self, test_folder):\n",
    "        super().__init__()\n",
    "        self.test_folder = test_folder\n",
    "        self.fnames = [f for f in os.listdir(test_folder) if f.endswith('.ogg')]\n",
    "        self.mel_spectrogram = MelSpecComputer(\n",
    "            sr=32000,\n",
    "            n_mels=128,\n",
    "            fmin=0,\n",
    "            fmax=16000\n",
    "        )\n",
    "        self.augmentations = A.Compose([\n",
    "            A.Resize(128, 281),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "    def audio2image(self, wav):\n",
    "        melspec = self.mel_spectrogram(wav) \n",
    "        image = mono_to_color(melspec)\n",
    "        image = np.stack((image,)*3, -1)\n",
    "        image = self.augmentations(image=image)['image']\n",
    "        return image\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fpath = os.path.join(self.test_folder, self.fnames[idx])\n",
    "        wav, sr = load_wav(fpath, 0, None)\n",
    "        wav = wav[:sr * 60]\n",
    "        spectrograms = []\n",
    "        crop_size = 5 * sr\n",
    "        model_crop_size = 10 * sr\n",
    "        for left in range(0, 60, 5):\n",
    "            left = left * sr\n",
    "            right = left + crop_size\n",
    "            left = max(left - crop_size, 0)\n",
    "            crop = wav[left:right]\n",
    "#             print(crop.shape)\n",
    "            crop = crop_or_pad(crop, model_crop_size)\n",
    "            spectrograms.append(self.audio2image(crop))\n",
    "        spectrograms = torch.stack(spectrograms) \n",
    "        return spectrograms\n",
    "    \n",
    "    \n",
    "class CustomResNext(nn.Module):\n",
    "    def __init__(self, model_name='resnext50_32x4d'):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=False)\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(n_features, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecbebe32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T18:23:15.174115Z",
     "iopub.status.busy": "2022-05-22T18:23:15.173144Z",
     "iopub.status.idle": "2022-05-22T18:23:21.372495Z",
     "shell.execute_reply": "2022-05-22T18:23:21.371874Z",
     "shell.execute_reply.started": "2022-05-22T17:35:22.581024Z"
    },
    "papermill": {
     "duration": 6.299998,
     "end_time": "2022-05-22T18:23:21.372662",
     "exception": false,
     "start_time": "2022-05-22T18:23:15.072664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "nocall_model = CustomResNext()\n",
    "nocall_model.to(device)\n",
    "\n",
    "state_dict = torch.load('../input/nocall-classifier/resnext50_32x4d_best.pth', map_location=device)\n",
    "nocall_model.load_state_dict(state_dict['model'])\n",
    "\n",
    "nocall_dataset = NoCallDataset(os.path.join(data_root, 'test_soundscapes'))\n",
    "nocall_dataloader = DataLoader(\n",
    "    nocall_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    drop_last=False,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3624b0e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T18:23:21.435270Z",
     "iopub.status.busy": "2022-05-22T18:23:21.434447Z",
     "iopub.status.idle": "2022-05-22T18:23:29.183736Z",
     "shell.execute_reply": "2022-05-22T18:23:29.184505Z",
     "shell.execute_reply.started": "2022-05-22T17:42:28.727138Z"
    },
    "papermill": {
     "duration": 7.785014,
     "end_time": "2022-05-22T18:23:29.184749",
     "exception": false,
     "start_time": "2022-05-22T18:23:21.399735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:07,  7.67s/it]\n"
     ]
    }
   ],
   "source": [
    "nocall_list = []\n",
    "part_count = 12\n",
    "nocall_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm(enumerate(nocall_dataloader)):\n",
    "        batch = batch[0]\n",
    "        pred = nocall_model(batch.to(device))\n",
    "        pred = torch.softmax(pred, dim=1)\n",
    "        pred = pred.cpu().numpy()[:, 0] < 0.9\n",
    "        \n",
    "        for j, chunk_pred in enumerate(pred):\n",
    "            fname = nocall_dataset.fnames[i]\n",
    "            prefix = fname.split('.')[0]\n",
    "            \n",
    "            nocall_list.append({\n",
    "                'fname': fname,\n",
    "                'r_sec': 5 * (j + 1),\n",
    "                'iscall': chunk_pred\n",
    "            })\n",
    "nocall_pd = pd.DataFrame(nocall_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2167721",
   "metadata": {
    "papermill": {
     "duration": 0.027423,
     "end_time": "2022-05-22T18:23:29.242956",
     "exception": false,
     "start_time": "2022-05-22T18:23:29.215533",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9b8e4d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T18:23:29.311170Z",
     "iopub.status.busy": "2022-05-22T18:23:29.310095Z",
     "iopub.status.idle": "2022-05-22T18:23:29.313615Z",
     "shell.execute_reply": "2022-05-22T18:23:29.312981Z",
     "shell.execute_reply.started": "2022-05-22T17:35:27.777041Z"
    },
    "papermill": {
     "duration": 0.04238,
     "end_time": "2022-05-22T18:23:29.313749",
     "exception": false,
     "start_time": "2022-05-22T18:23:29.271369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def init_model(config_fname, model_fname, model_root):\n",
    "    config_path = os.path.join(model_root, config_fname)\n",
    "    model_path = os.path.join(model_root, model_fname)\n",
    "    \n",
    "    with open(config_path) as fin:\n",
    "        config = yaml.safe_load(fin)\n",
    "\n",
    "    model_config = config['model']\n",
    "    if 'backbone_config' in model_config['params']:\n",
    "        model_config['params']['backbone_config']['pretrained'] = False\n",
    "    else:\n",
    "        model_config['params']['backbone_config'] = {'pretrained': False}\n",
    "    if 'model_name' in model_config['params']['backbone_config']:\n",
    "        model_config['params']['backbone_config'].pop('model_name')\n",
    "        \n",
    "    data_config = config['data']\n",
    "    model_class = NN_CATALOG[model_config['name']]\n",
    "\n",
    "    model = model_class(len(all_species), int(data_config['crop_len'] // data_config['test_wav_len']),\n",
    "                        **model_config['params'])\n",
    "    model.to(device)\n",
    "\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e636ebab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T18:23:29.376105Z",
     "iopub.status.busy": "2022-05-22T18:23:29.375411Z",
     "iopub.status.idle": "2022-05-22T18:23:33.931995Z",
     "shell.execute_reply": "2022-05-22T18:23:33.931044Z",
     "shell.execute_reply.started": "2022-05-22T18:21:05.170896Z"
    },
    "papermill": {
     "duration": 4.589787,
     "end_time": "2022-05-22T18:23:33.932154",
     "exception": false,
     "start_time": "2022-05-22T18:23:29.342367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from neural_network import NN_CATALOG\n",
    "\n",
    "\n",
    "ckpt_root = '../input/birdclefsubmit'\n",
    "baseline_path = ('baseline/baseline_config.yaml', 'baseline/final-model.pt')\n",
    "eff_crop_path = [('eff_crop_cv/baseline_config.yaml', f'eff_crop_cv/{i}-fold-model.pt') for i in range(5)]\n",
    "all_data_path = [\n",
    "    ('all_data_train/baseline_config.yaml', f'all_data_train/final-model.pt'),\n",
    "    ('all_data_train/baseline_config.yaml', f'all_data_train/main_stage-4-model.pt'),\n",
    "]\n",
    "path_list = [\n",
    "    *eff_crop_path,\n",
    "    baseline_path,\n",
    "    *all_data_path\n",
    "]\n",
    "\n",
    "models = [init_model(*p, ckpt_root) for p in path_list]\n",
    "weights = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee1112c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T18:23:33.994748Z",
     "iopub.status.busy": "2022-05-22T18:23:33.994128Z",
     "iopub.status.idle": "2022-05-22T18:23:33.998703Z",
     "shell.execute_reply": "2022-05-22T18:23:33.998221Z",
     "shell.execute_reply.started": "2022-05-22T18:21:12.912395Z"
    },
    "papermill": {
     "duration": 0.03942,
     "end_time": "2022-05-22T18:23:33.998825",
     "exception": false,
     "start_time": "2022-05-22T18:23:33.959405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Blending(nn.Module):\n",
    "    def __init__(self, models, weights):\n",
    "        super().__init__()\n",
    "        for m in models:\n",
    "            m.eval()\n",
    "        self.models = models\n",
    "        self.weights = weights or [1 / len(models) for _ in models]\n",
    "        \n",
    "    def forward(self, wav_tensor):\n",
    "        pred = [m(wav_tensor)['logits'] for m in self.models]\n",
    "        pred = sum(p * w for p, w in zip(pred, self.weights))\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "830d8c2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T18:23:34.068780Z",
     "iopub.status.busy": "2022-05-22T18:23:34.067692Z",
     "iopub.status.idle": "2022-05-22T18:23:34.070264Z",
     "shell.execute_reply": "2022-05-22T18:23:34.070708Z",
     "shell.execute_reply.started": "2022-05-22T18:21:13.876026Z"
    },
    "papermill": {
     "duration": 0.044725,
     "end_time": "2022-05-22T18:23:34.070850",
     "exception": false,
     "start_time": "2022-05-22T18:23:34.026125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Blending(models, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975088ca",
   "metadata": {
    "papermill": {
     "duration": 0.027224,
     "end_time": "2022-05-22T18:23:34.125311",
     "exception": false,
     "start_time": "2022-05-22T18:23:34.098087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fa064ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T18:23:34.187346Z",
     "iopub.status.busy": "2022-05-22T18:23:34.186512Z",
     "iopub.status.idle": "2022-05-22T18:23:34.194690Z",
     "shell.execute_reply": "2022-05-22T18:23:34.194195Z",
     "shell.execute_reply.started": "2022-05-22T18:21:26.838888Z"
    },
    "papermill": {
     "duration": 0.042728,
     "end_time": "2022-05-22T18:23:34.194844",
     "exception": false,
     "start_time": "2022-05-22T18:23:34.152116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_root, 'scored_birds.json')) as fin:\n",
    "    test_birds = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e04fd50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T18:23:34.267484Z",
     "iopub.status.busy": "2022-05-22T18:23:34.266361Z",
     "iopub.status.idle": "2022-05-22T18:23:34.268623Z",
     "shell.execute_reply": "2022-05-22T18:23:34.269161Z",
     "shell.execute_reply.started": "2022-05-22T18:21:29.358694Z"
    },
    "papermill": {
     "duration": 0.044303,
     "end_time": "2022-05-22T18:23:34.269307",
     "exception": false,
     "start_time": "2022-05-22T18:23:34.225004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Compose:\n",
    "    def __init__(self, transforms: list):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, y: np.ndarray, sr):\n",
    "        for trns in self.transforms:\n",
    "            y = trns(y, sr)\n",
    "        return y\n",
    "    \n",
    "    \n",
    "class AudioTransform:\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        self.always_apply = always_apply\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, y: np.ndarray, sr):\n",
    "        if self.always_apply:\n",
    "            return self.apply(y, sr=sr)\n",
    "        else:\n",
    "            if np.random.rand() < self.p:\n",
    "                return self.apply(y, sr=sr)\n",
    "            else:\n",
    "                return y\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "        \n",
    "class Normalize(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=1):\n",
    "        super().__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        max_vol = np.abs(y).max()\n",
    "        y_vol = y / max_vol\n",
    "        assert not np.isnan(y_vol).any(), f'{max_vol}'\n",
    "        return y_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c1cc227",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T18:23:34.335812Z",
     "iopub.status.busy": "2022-05-22T18:23:34.333723Z",
     "iopub.status.idle": "2022-05-22T18:23:34.336668Z",
     "shell.execute_reply": "2022-05-22T18:23:34.337279Z",
     "shell.execute_reply.started": "2022-05-22T18:21:31.055667Z"
    },
    "papermill": {
     "duration": 0.041461,
     "end_time": "2022-05-22T18:23:34.337444",
     "exception": false,
     "start_time": "2022-05-22T18:23:34.295983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_folder, augmentations=None):\n",
    "        super().__init__()\n",
    "        self.test_folder = test_folder\n",
    "        self.fnames = [f for f in os.listdir(test_folder) if f.endswith('.ogg')]\n",
    "        self.augmentations = augmentations\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fpath = os.path.join(self.test_folder, self.fnames[idx])\n",
    "        wav, sr = load_wav(fpath, 0, None)\n",
    "        if self.augmentations:\n",
    "            wav = self.augmentations(wav, None)\n",
    "        wav = torch.tensor(wav)\n",
    "        assert (13 * 5 * sr) > len(wav) \n",
    "        wav = wav[:len(wav) // 12 * 12].reshape((12, len(wav) // 12))\n",
    "        return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55b3d7a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T18:23:34.397490Z",
     "iopub.status.busy": "2022-05-22T18:23:34.396409Z",
     "iopub.status.idle": "2022-05-22T18:23:34.401129Z",
     "shell.execute_reply": "2022-05-22T18:23:34.400565Z",
     "shell.execute_reply.started": "2022-05-22T18:21:31.436986Z"
    },
    "papermill": {
     "duration": 0.036002,
     "end_time": "2022-05-22T18:23:34.401266",
     "exception": false,
     "start_time": "2022-05-22T18:23:34.365264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(\n",
    "    os.path.join(data_root, 'test_soundscapes'),\n",
    "    Compose([Normalize(p=1)])\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    drop_last=False,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96cc74e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T18:23:34.462257Z",
     "iopub.status.busy": "2022-05-22T18:23:34.461495Z",
     "iopub.status.idle": "2022-05-22T18:23:34.464894Z",
     "shell.execute_reply": "2022-05-22T18:23:34.464398Z",
     "shell.execute_reply.started": "2022-05-22T18:21:32.418140Z"
    },
    "papermill": {
     "duration": 0.036264,
     "end_time": "2022-05-22T18:23:34.465071",
     "exception": false,
     "start_time": "2022-05-22T18:23:34.428807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_topk(pred_proba, max_birds=5):\n",
    "    pred_proba = pred_proba[:, [species2id[b] for b in test_birds]]\n",
    "    mean_proba = pred_proba.mean(axis=0)\n",
    "    topk_birds = [i for i, _ in sorted(enumerate(mean_proba),\n",
    "                                       key=lambda x: x[1],\n",
    "                                       reverse=True)][:max_birds]\n",
    "    return topk_birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34adfafe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T18:23:34.544018Z",
     "iopub.status.busy": "2022-05-22T18:23:34.527853Z",
     "iopub.status.idle": "2022-05-22T18:23:34.557231Z",
     "shell.execute_reply": "2022-05-22T18:23:34.557750Z",
     "shell.execute_reply.started": "2022-05-22T18:21:33.039072Z"
    },
    "papermill": {
     "duration": 0.066008,
     "end_time": "2022-05-22T18:23:34.557919",
     "exception": false,
     "start_time": "2022-05-22T18:23:34.491911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'akiapo': 0.11571428571428573,\n",
       " 'aniani': 0.08,\n",
       " 'apapan': 0.13571428571428573,\n",
       " 'barpet': 0.09,\n",
       " 'crehon': 0.049999999999999996,\n",
       " 'elepai': 0.09714285714285716,\n",
       " 'ercfra': 0.08,\n",
       " 'hawama': 0.09428571428571429,\n",
       " 'hawcre': 0.08714285714285716,\n",
       " 'hawgoo': 0.10857142857142858,\n",
       " 'hawhaw': 0.027142857142857146,\n",
       " 'hawpet1': 0.051428571428571435,\n",
       " 'houfin': 0.09285714285714286,\n",
       " 'iiwi': 0.12142857142857143,\n",
       " 'jabwar': 0.051428571428571435,\n",
       " 'maupar': 0.04428571428571428,\n",
       " 'omao': 0.08571428571428573,\n",
       " 'puaioh': 0.05142857142857143,\n",
       " 'skylar': 0.1142857142857143,\n",
       " 'warwhe1': 0.05142857142857143,\n",
       " 'yefcan': 0.06571428571428571}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treshold_dict = [\n",
    "    {\n",
    "        'akiapo': 0.01,\n",
    "        'aniani': 0.05,\n",
    "        'apapan': 0.1,\n",
    "        'barpet': 0.01,\n",
    "        'crehon': 0.05,\n",
    "        'elepai': 0.01,\n",
    "        'ercfra': 0.1,\n",
    "        'hawama': 0.05,\n",
    "        'hawcre': 0.05,\n",
    "        'hawgoo': 0.25,\n",
    "        'hawhaw': 0.01,\n",
    "        'hawpet1': 0.05,\n",
    "        'houfin': 0.1,\n",
    "        'iiwi': 0.1,\n",
    "        'jabwar': 0.05,\n",
    "        'maupar': 0.05,\n",
    "        'omao': 0.05,\n",
    "        'puaioh': 0.05,\n",
    "        'skylar': 0.1,\n",
    "        'warwhe1': 0.05,\n",
    "        'yefcan': 0.05\n",
    "    },\n",
    "    {\n",
    "        'akiapo': 0.1,\n",
    "        'aniani': 0.05,\n",
    "        'apapan': 0.05,\n",
    "        'barpet': 0.01,\n",
    "        'crehon': 0.05,\n",
    "        'elepai': 0.01,\n",
    "        'ercfra': 0.15,\n",
    "        'hawama': 0.05,\n",
    "        'hawcre': 0.05,\n",
    "        'hawgoo': 0.2,\n",
    "        'hawhaw': 0.01,\n",
    "        'hawpet1': 0.05,\n",
    "        'houfin': 0.1,\n",
    "        'iiwi': 0.1,\n",
    "        'jabwar': 0.05,\n",
    "        'maupar': 0.05,\n",
    "        'omao': 0.05,\n",
    "        'puaioh': 0.05,\n",
    "        'skylar': 0.15,\n",
    "        'warwhe1': 0.05,\n",
    "        'yefcan': 0.05\n",
    "    },\n",
    "    {\n",
    "        'akiapo': 0.15,\n",
    "        'aniani': 0.15,\n",
    "        'apapan': 0.25,\n",
    "        'barpet': 0.15,\n",
    "        'crehon': 0.05,\n",
    "        'elepai': 0.05,\n",
    "        'ercfra': 0.05,\n",
    "        'hawama': 0.25,\n",
    "        'hawcre': 0.1,\n",
    "        'hawgoo': 0.05,\n",
    "        'hawhaw': 0.05,\n",
    "        'hawpet1': 0.05,\n",
    "        'houfin': 0.1,\n",
    "        'iiwi': 0.1,\n",
    "        'jabwar': 0.05,\n",
    "        'maupar': 0.05,\n",
    "        'omao': 0.05,\n",
    "        'puaioh': 0.05,\n",
    "        'skylar': 0.15,\n",
    "        'warwhe1': 0.1,\n",
    "        'yefcan': 0.15\n",
    "    },\n",
    "    {\n",
    "        'akiapo': 0.25,\n",
    "        'aniani': 0.2,\n",
    "        'apapan': 0.25,\n",
    "        'barpet': 0.15,\n",
    "        'crehon': 0.05,\n",
    "        'elepai': 0.15,\n",
    "        'ercfra': 0.1,\n",
    "        'hawama': 0.1,\n",
    "        'hawcre': 0.2,\n",
    "        'hawgoo': 0.05,\n",
    "        'hawhaw': 0.05,\n",
    "        'hawpet1': 0.05,\n",
    "        'houfin': 0.1,\n",
    "        'iiwi': 0.1,\n",
    "        'jabwar': 0.05,\n",
    "        'maupar': 0.05,\n",
    "        'omao': 0.05,\n",
    "        'puaioh': 0.1,\n",
    "        'skylar': 0.1,\n",
    "        'warwhe1': 0.05,\n",
    "        'yefcan': 0.05\n",
    "    },\n",
    "    {\n",
    "        'akiapo': 0.05,\n",
    "        'aniani': 0.05,\n",
    "        'apapan': 0.15,\n",
    "        'barpet': 0.15,\n",
    "        'crehon': 0.05,\n",
    "        'elepai': 0.2,\n",
    "        'ercfra': 0.1,\n",
    "        'hawama': 0.15,\n",
    "        'hawcre': 0.15,\n",
    "        'hawgoo': 0.15,\n",
    "        'hawhaw': 0.05,\n",
    "        'hawpet1': 0.1,\n",
    "        'houfin': 0.1,\n",
    "        'iiwi': 0.1,\n",
    "        'jabwar': 0.1,\n",
    "        'maupar': 0.01,\n",
    "        'omao': 0.25,\n",
    "        'puaioh': 0.01,\n",
    "        'skylar': 0.15,\n",
    "        'warwhe1': 0.05,\n",
    "        'yefcan': 0.1\n",
    "    },\n",
    "    {\n",
    "        'akiapo': 0.2,\n",
    "        'aniani': 0.05,\n",
    "        'apapan': 0.05,\n",
    "        'barpet': 0.15,\n",
    "        'crehon': 0.05,\n",
    "        'elepai': 0.01,\n",
    "        'ercfra': 0.05,\n",
    "        'hawama': 0.05,\n",
    "        'hawcre': 0.01,\n",
    "        'hawgoo': 0.05,\n",
    "        'hawhaw': 0.01,\n",
    "        'hawpet1': 0.01,\n",
    "        'houfin': 0.1,\n",
    "        'iiwi': 0.1,\n",
    "        'jabwar': 0.05,\n",
    "        'maupar': 0.05,\n",
    "        'omao': 0.1,\n",
    "        'puaioh': 0.05,\n",
    "        'skylar': 0.1,\n",
    "        'warwhe1': 0.05,\n",
    "        'yefcan': 0.05\n",
    "    },\n",
    "    {\n",
    "        'akiapo': 0.05,\n",
    "        'aniani': 0.01,\n",
    "        'apapan': 0.1,\n",
    "        'barpet': 0.01,\n",
    "        'crehon': 0.05,\n",
    "        'elepai': 0.25,\n",
    "        'ercfra': 0.01,\n",
    "        'hawama': 0.01,\n",
    "        'hawcre': 0.05,\n",
    "        'hawgoo': 0.01,\n",
    "        'hawhaw': 0.01,\n",
    "        'hawpet1': 0.05,\n",
    "        'houfin': 0.05,\n",
    "        'iiwi': 0.25,\n",
    "        'jabwar': 0.01,\n",
    "        'maupar': 0.05,\n",
    "        'omao': 0.05,\n",
    "        'puaioh': 0.05,\n",
    "        'skylar': 0.05,\n",
    "        'warwhe1': 0.01,\n",
    "        'yefcan': 0.01\n",
    "    }\n",
    "]\n",
    "treshold_dict = {key: np.mean([t[key] for t in treshold_dict]) for key, _ in treshold_dict[0].items()}\n",
    "treshold_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fece84c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T18:23:34.626675Z",
     "iopub.status.busy": "2022-05-22T18:23:34.625466Z",
     "iopub.status.idle": "2022-05-22T18:23:35.583139Z",
     "shell.execute_reply": "2022-05-22T18:23:35.582573Z",
     "shell.execute_reply.started": "2022-05-22T18:21:34.481036Z"
    },
    "papermill": {
     "duration": 0.997116,
     "end_time": "2022-05-22T18:23:35.583294",
     "exception": false,
     "start_time": "2022-05-22T18:23:34.586178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "treshold = 0.1\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm(enumerate(test_dataloader)):\n",
    "        batch_size, part_count, part_size = batch.shape\n",
    "        batch = batch.reshape(batch_size * part_count, part_size)\n",
    "        pred = model(batch.to(device))\n",
    "        pred = pred.cpu().numpy()\n",
    "#         topk_birds = find_topk(pred_proba, max_birds=10)\n",
    "        \n",
    "        for j, chunk_pred in enumerate(pred):\n",
    "            inbatch_number = j // part_count\n",
    "            chunk_number = j % part_count + 1\n",
    "            f_idx = i * batch_size + inbatch_number\n",
    "            fname = test_dataset.fnames[f_idx]\n",
    "            prefix = fname.split('.')[0]\n",
    "            sufix = f'{5 * chunk_number}'\n",
    "            nocall = nocall_pd[(nocall_pd.fname == fname) & (nocall_pd.r_sec == 5 * chunk_number)]['iscall'].values[0]\n",
    "            \n",
    "            pred_list.extend([{\n",
    "                'row_id': '_'.join([prefix, b, sufix]),\n",
    "                'target': (chunk_pred[species2id[b]] > treshold_dict[b]) and nocall # if species2id[b] in topk_birds else False\n",
    "            } for b in test_birds])\n",
    "pred_pd = pd.DataFrame(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fe23280",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T18:23:35.648883Z",
     "iopub.status.busy": "2022-05-22T18:23:35.648230Z",
     "iopub.status.idle": "2022-05-22T18:23:35.666787Z",
     "shell.execute_reply": "2022-05-22T18:23:35.667369Z",
     "shell.execute_reply.started": "2022-05-22T18:21:36.293155Z"
    },
    "papermill": {
     "duration": 0.053378,
     "end_time": "2022-05-22T18:23:35.667506",
     "exception": false,
     "start_time": "2022-05-22T18:23:35.614128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_453028782_akiapo_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soundscape_453028782_aniani_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soundscape_453028782_apapan_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soundscape_453028782_barpet_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soundscape_453028782_crehon_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>soundscape_453028782_omao_60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>soundscape_453028782_puaioh_60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>soundscape_453028782_skylar_60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>soundscape_453028782_warwhe1_60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>soundscape_453028782_yefcan_60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              row_id  target\n",
       "0      soundscape_453028782_akiapo_5   False\n",
       "1      soundscape_453028782_aniani_5   False\n",
       "2      soundscape_453028782_apapan_5   False\n",
       "3      soundscape_453028782_barpet_5   False\n",
       "4      soundscape_453028782_crehon_5   False\n",
       "..                               ...     ...\n",
       "247     soundscape_453028782_omao_60   False\n",
       "248   soundscape_453028782_puaioh_60   False\n",
       "249   soundscape_453028782_skylar_60   False\n",
       "250  soundscape_453028782_warwhe1_60   False\n",
       "251   soundscape_453028782_yefcan_60   False\n",
       "\n",
       "[252 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_pd.to_csv(\"submission.csv\", index=False)\n",
    "pred_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac9ee1be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T18:23:35.731372Z",
     "iopub.status.busy": "2022-05-22T18:23:35.730367Z",
     "iopub.status.idle": "2022-05-22T18:23:35.741566Z",
     "shell.execute_reply": "2022-05-22T18:23:35.741055Z",
     "shell.execute_reply.started": "2022-05-22T18:21:37.286016Z"
    },
    "papermill": {
     "duration": 0.043338,
     "end_time": "2022-05-22T18:23:35.741684",
     "exception": false,
     "start_time": "2022-05-22T18:23:35.698346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>soundscape_453028782_warwhe1_10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>soundscape_453028782_jabwar_15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>soundscape_453028782_warwhe1_15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>soundscape_453028782_jabwar_20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>soundscape_453028782_jabwar_25</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>soundscape_453028782_warwhe1_40</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>soundscape_453028782_jabwar_45</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>soundscape_453028782_warwhe1_45</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              row_id  target\n",
       "40   soundscape_453028782_warwhe1_10    True\n",
       "56    soundscape_453028782_jabwar_15    True\n",
       "61   soundscape_453028782_warwhe1_15    True\n",
       "77    soundscape_453028782_jabwar_20    True\n",
       "98    soundscape_453028782_jabwar_25    True\n",
       "166  soundscape_453028782_warwhe1_40    True\n",
       "182   soundscape_453028782_jabwar_45    True\n",
       "187  soundscape_453028782_warwhe1_45    True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_pd[pred_pd.target]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 43.679591,
   "end_time": "2022-05-22T18:23:38.227417",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-22T18:22:54.547826",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
