{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f2c3934",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-11T16:22:08.170720Z",
     "iopub.status.busy": "2022-05-11T16:22:08.169147Z",
     "iopub.status.idle": "2022-05-11T16:22:13.817847Z",
     "shell.execute_reply": "2022-05-11T16:22:13.818346Z",
     "shell.execute_reply.started": "2022-05-11T16:03:44.437757Z"
    },
    "papermill": {
     "duration": 5.686459,
     "end_time": "2022-05-11T16:22:13.818625",
     "exception": false,
     "start_time": "2022-05-11T16:22:08.132166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import sys\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import random\n",
    "# import colorednoise as cn\n",
    "\n",
    "import librosa\n",
    "\n",
    "import torch\n",
    "import torchaudio as ta\n",
    "import timm\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d134382d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T16:22:13.878380Z",
     "iopub.status.busy": "2022-05-11T16:22:13.877794Z",
     "iopub.status.idle": "2022-05-11T16:22:14.209327Z",
     "shell.execute_reply": "2022-05-11T16:22:14.208755Z",
     "shell.execute_reply.started": "2022-05-11T16:03:50.081334Z"
    },
    "papermill": {
     "duration": 0.362976,
     "end_time": "2022-05-11T16:22:14.209469",
     "exception": false,
     "start_time": "2022-05-11T16:22:13.846493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_root = '/kaggle/input/birdclef-2022'\n",
    "train_meta = pd.read_csv('../input/birdclef-data-with-wav-durations/train_metadata_extended.csv')\n",
    "ebird_taxonomy = pd.read_csv(os.path.join(data_root, 'eBird_Taxonomy_v2021.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90e0acbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T16:22:14.298271Z",
     "iopub.status.busy": "2022-05-11T16:22:14.277108Z",
     "iopub.status.idle": "2022-05-11T16:22:14.342861Z",
     "shell.execute_reply": "2022-05-11T16:22:14.342386Z",
     "shell.execute_reply.started": "2022-05-11T16:03:50.413912Z"
    },
    "papermill": {
     "duration": 0.10663,
     "end_time": "2022-05-11T16:22:14.343000",
     "exception": false,
     "start_time": "2022-05-11T16:22:14.236370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_meta.loc[:, 'secondary_labels'] = train_meta.secondary_labels.apply(eval)\n",
    "train_meta['target_raw'] = train_meta.secondary_labels + train_meta.primary_label.apply(lambda x: [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e62e4225",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T16:22:14.850180Z",
     "iopub.status.busy": "2022-05-11T16:22:14.819469Z",
     "iopub.status.idle": "2022-05-11T16:22:15.149392Z",
     "shell.execute_reply": "2022-05-11T16:22:15.148852Z",
     "shell.execute_reply.started": "2022-05-11T16:03:51.912589Z"
    },
    "papermill": {
     "duration": 0.780524,
     "end_time": "2022-05-11T16:22:15.149518",
     "exception": false,
     "start_time": "2022-05-11T16:22:14.368994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_species = sorted(set(train_meta.target_raw.sum()))\n",
    "species2id = {s: i for i, s in enumerate(all_species)}\n",
    "id2species = {i: s for i, s in enumerate(all_species)}\n",
    "\n",
    "train_meta['target'] = train_meta.target_raw.apply(lambda species: [int(s in species) for s in all_species])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf4e277",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T16:22:15.209353Z",
     "iopub.status.busy": "2022-05-11T16:22:15.207683Z",
     "iopub.status.idle": "2022-05-11T16:22:15.209927Z",
     "shell.execute_reply": "2022-05-11T16:22:15.210359Z",
     "shell.execute_reply.started": "2022-05-11T16:03:54.482565Z"
    },
    "papermill": {
     "duration": 0.034969,
     "end_time": "2022-05-11T16:22:15.210514",
     "exception": false,
     "start_time": "2022-05-11T16:22:15.175545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_wav(fname, offset, duration):\n",
    "#     fname = 'afrsil1/XC125458.ogg'\n",
    "    fpath = os.path.join(data_root, 'train_audio', fname)\n",
    "    wav, sr = librosa.load(fpath, sr=None, duration=duration, offset=offset)\n",
    "    assert sr <= 32000, sr\n",
    "    return wav, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be4b9e05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T16:22:15.268851Z",
     "iopub.status.busy": "2022-05-11T16:22:15.267191Z",
     "iopub.status.idle": "2022-05-11T16:22:15.269452Z",
     "shell.execute_reply": "2022-05-11T16:22:15.269857Z",
     "shell.execute_reply.started": "2022-05-11T16:03:56.456043Z"
    },
    "papermill": {
     "duration": 0.032874,
     "end_time": "2022-05-11T16:22:15.270001",
     "exception": false,
     "start_time": "2022-05-11T16:22:15.237127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# duration = 30\n",
    "# sample_rate = 32000\n",
    "\n",
    "# wav, sr = load_wav('afrsil1/XC125458.ogg', 5, duration)\n",
    "# to_pad = duration * sample_rate - wav.shape[0]\n",
    "\n",
    "# if to_pad > 0:\n",
    "#     wav = np.pad(wav, (0, to_pad))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8975f63a",
   "metadata": {
    "papermill": {
     "duration": 0.025611,
     "end_time": "2022-05-11T16:22:15.323193",
     "exception": false,
     "start_time": "2022-05-11T16:22:15.297582",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc45e7be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T16:22:15.384024Z",
     "iopub.status.busy": "2022-05-11T16:22:15.383057Z",
     "iopub.status.idle": "2022-05-11T16:22:15.414928Z",
     "shell.execute_reply": "2022-05-11T16:22:15.414401Z",
     "shell.execute_reply.started": "2022-05-11T16:04:20.700432Z"
    },
    "papermill": {
     "duration": 0.06613,
     "end_time": "2022-05-11T16:22:15.415050",
     "exception": false,
     "start_time": "2022-05-11T16:22:15.348920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Compose:\n",
    "    def __init__(self, transforms: list):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, y: np.ndarray, sr):\n",
    "        for trns in self.transforms:\n",
    "            y = trns(y, sr)\n",
    "        return y\n",
    "\n",
    "\n",
    "class AudioTransform:\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        self.always_apply = always_apply\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, y: np.ndarray, sr):\n",
    "        if self.always_apply:\n",
    "            return self.apply(y, sr=sr)\n",
    "        else:\n",
    "            if np.random.rand() < self.p:\n",
    "                return self.apply(y, sr=sr)\n",
    "            else:\n",
    "                return y\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class OneOf(Compose):\n",
    "    # https://github.com/albumentations-team/albumentations/blob/master/albumentations/core/composition.py\n",
    "    def __init__(self, transforms, p=0.5):\n",
    "        super().__init__(transforms)\n",
    "        self.p = p\n",
    "        transforms_ps = [t.p for t in transforms]\n",
    "        s = sum(transforms_ps)\n",
    "        self.transforms_ps = [t / s for t in transforms_ps]\n",
    "\n",
    "    def __call__(self, y: np.ndarray, sr):\n",
    "        data = y\n",
    "        if self.transforms_ps and (random.random() < self.p):\n",
    "            random_state = np.random.RandomState(random.randint(0, 2 ** 32 - 1))\n",
    "            t = random_state.choice(self.transforms, p=self.transforms_ps)\n",
    "            data = t(y, sr)\n",
    "        return data\n",
    "\n",
    "\n",
    "class Normalize(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=1):\n",
    "        super().__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        max_vol = np.abs(y).max()\n",
    "        y_vol = y / max_vol\n",
    "        assert not np.isnan(y_vol).any(), f'{max_vol}'\n",
    "        return y_vol\n",
    "\n",
    "\n",
    "class NewNormalize(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=1):\n",
    "        super().__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        y_mm = y - y.mean()\n",
    "        return y_mm / y_mm.abs().max()\n",
    "\n",
    "\n",
    "class NoiseInjection(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, max_noise_level=0.5):\n",
    "        super().__init__(always_apply, p)\n",
    "\n",
    "        self.noise_level = (0.0, max_noise_level)\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        noise_level = np.random.uniform(*self.noise_level)\n",
    "        noise = np.random.randn(len(y))\n",
    "        augmented = (y + noise * noise_level).astype(y.dtype)\n",
    "        \n",
    "        assert not np.isnan(augmented).any(), f'{noise_level}'\n",
    "        max_vol = np.abs(augmented).max()\n",
    "        assert max_vol != 0.\n",
    "        return augmented\n",
    "\n",
    "\n",
    "class GaussianNoise(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, min_snr=5, max_snr=20):\n",
    "        super().__init__(always_apply, p)\n",
    "\n",
    "        self.min_snr = min_snr\n",
    "        self.max_snr = max_snr\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        snr = np.random.uniform(self.min_snr, self.max_snr)\n",
    "        a_signal = np.sqrt(y ** 2).max()\n",
    "        a_noise = a_signal / (10 ** (snr / 20))\n",
    "\n",
    "        white_noise = np.random.randn(len(y))\n",
    "        a_white = np.sqrt(white_noise ** 2).max()\n",
    "        augmented = (y + white_noise * 1 / a_white * a_noise).astype(y.dtype)\n",
    "        \n",
    "        assert not np.isnan(augmented).any(), f'{a_noise}, {snr}'\n",
    "        max_vol = np.abs(augmented).max()\n",
    "        assert max_vol != 0.\n",
    "        return augmented\n",
    "\n",
    "\n",
    "# class PinkNoise(AudioTransform):\n",
    "#     def __init__(self, always_apply=False, p=0.5, min_snr=5, max_snr=20):\n",
    "#         super().__init__(always_apply, p)\n",
    "\n",
    "#         self.min_snr = min_snr\n",
    "#         self.max_snr = max_snr\n",
    "\n",
    "#     def apply(self, y: np.ndarray, **params):\n",
    "#         snr = np.random.uniform(self.min_snr, self.max_snr)\n",
    "#         a_signal = np.sqrt(y ** 2).max()\n",
    "#         a_noise = a_signal / (10 ** (snr / 20))\n",
    "\n",
    "#         pink_noise = cn.powerlaw_psd_gaussian(1, len(y))\n",
    "#         a_pink = np.sqrt(pink_noise ** 2).max()\n",
    "#         augmented = (y + pink_noise * 1 / a_pink * a_noise).astype(y.dtype)\n",
    "#         return augmented\n",
    "\n",
    "\n",
    "class PitchShift(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, max_range=5):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.max_range = max_range\n",
    "\n",
    "    def apply(self, y: np.ndarray, sr, **params):\n",
    "        n_steps = np.random.randint(-self.max_range, self.max_range)\n",
    "        augmented = librosa.effects.pitch_shift(y, sr, n_steps)\n",
    "        return augmented\n",
    "\n",
    "\n",
    "class TimeStretch(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, max_rate=1):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.max_rate = max_rate\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        rate = np.random.uniform(0, self.max_rate)\n",
    "        augmented = librosa.effects.time_stretch(y, rate)\n",
    "        return augmented\n",
    "\n",
    "\n",
    "def _db2float(db: float, amplitude=True):\n",
    "    if amplitude:\n",
    "        return 10 ** (db / 20)\n",
    "    else:\n",
    "        return 10 ** (db / 10)\n",
    "\n",
    "\n",
    "def volume_down(y: np.ndarray, db: float):\n",
    "    \"\"\"\n",
    "    Low level API for decreasing the volume\n",
    "    Parameters\n",
    "    ----------\n",
    "    y: numpy.ndarray\n",
    "        stereo / monaural input audio\n",
    "    db: float\n",
    "        how much decibel to decrease\n",
    "    Returns\n",
    "    -------\n",
    "    applied: numpy.ndarray\n",
    "        audio with decreased volume\n",
    "    \"\"\"\n",
    "    applied = y * _db2float(-db)\n",
    "    return applied\n",
    "\n",
    "\n",
    "def volume_up(y: np.ndarray, db: float):\n",
    "    \"\"\"\n",
    "    Low level API for increasing the volume\n",
    "    Parameters\n",
    "    ----------\n",
    "    y: numpy.ndarray\n",
    "        stereo / monaural input audio\n",
    "    db: float\n",
    "        how much decibel to increase\n",
    "    Returns\n",
    "    -------\n",
    "    applied: numpy.ndarray\n",
    "        audio with increased volume\n",
    "    \"\"\"\n",
    "    applied = y * _db2float(db)\n",
    "    return applied\n",
    "\n",
    "\n",
    "class RandomVolume(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, limit=10):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.limit = limit\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        db = np.random.uniform(-self.limit, self.limit)\n",
    "        if db >= 0:\n",
    "            augmented = volume_up(y, db) \n",
    "        else:\n",
    "            augmented = volume_down(y, db)\n",
    "        assert not np.isnan(augmented).any(), f'{db}'\n",
    "        max_vol = np.abs(augmented).max()\n",
    "        assert max_vol != 0.\n",
    "        return augmented\n",
    "\n",
    "\n",
    "class CosineVolume(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, limit=10):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.limit = limit\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        db = np.random.uniform(-self.limit, self.limit)\n",
    "        cosine = np.cos(np.arange(len(y)) / len(y) * np.pi * 2)\n",
    "        dbs = _db2float(cosine * db)\n",
    "        return y * dbs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121d1d37",
   "metadata": {
    "papermill": {
     "duration": 0.025625,
     "end_time": "2022-05-11T16:22:15.466636",
     "exception": false,
     "start_time": "2022-05-11T16:22:15.441011",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e0effe8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T16:22:15.523239Z",
     "iopub.status.busy": "2022-05-11T16:22:15.522533Z",
     "iopub.status.idle": "2022-05-11T16:22:15.525372Z",
     "shell.execute_reply": "2022-05-11T16:22:15.524867Z",
     "shell.execute_reply.started": "2022-05-11T16:04:37.026826Z"
    },
    "papermill": {
     "duration": 0.033084,
     "end_time": "2022-05-11T16:22:15.525520",
     "exception": false,
     "start_time": "2022-05-11T16:22:15.492436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_SIZE = 5 \n",
    "CONFIG = {\n",
    "    'crop_len': 30,\n",
    "    'sample_rate': 32000,    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5dfd478",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T16:22:15.588024Z",
     "iopub.status.busy": "2022-05-11T16:22:15.587141Z",
     "iopub.status.idle": "2022-05-11T16:22:15.589241Z",
     "shell.execute_reply": "2022-05-11T16:22:15.589687Z",
     "shell.execute_reply.started": "2022-05-11T16:04:39.786333Z"
    },
    "papermill": {
     "duration": 0.038431,
     "end_time": "2022-05-11T16:22:15.589828",
     "exception": false,
     "start_time": "2022-05-11T16:22:15.551397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, df, augmentations):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.augmentations = augmentations\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        duration = CONFIG['crop_len']\n",
    "        sample_rate = CONFIG['sample_rate']\n",
    "        \n",
    "        fname = self.df.iloc[idx]['filename']\n",
    "        wav_len = self.df.iloc[idx]['duration']\n",
    "        \n",
    "        max_offset = max(0, wav_len - duration)\n",
    "        random_offset = random.randint(0, max_offset)\n",
    "                \n",
    "        wav, sr = load_wav(fname, random_offset, duration)\n",
    "        to_pad = duration * sample_rate - wav.shape[0]\n",
    "        if to_pad > 0:\n",
    "            wav = np.pad(wav, (0, to_pad))\n",
    "            \n",
    "        if self.augmentations:\n",
    "            try:\n",
    "                wav = self.augmentations(wav, None)\n",
    "            except ValueError as e:\n",
    "                print(random_offset)\n",
    "                raise e\n",
    "        target = self.df.iloc[idx]['target']\n",
    "        \n",
    "        # TODO: add weighting\n",
    "            \n",
    "        wav = torch.tensor(wav)\n",
    "        target = torch.tensor(target, dtype=float)\n",
    "        return {\n",
    "            'wav': wav,\n",
    "            'target': target,\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d09b43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T09:17:01.036366Z",
     "iopub.status.busy": "2022-04-21T09:17:01.036048Z",
     "iopub.status.idle": "2022-04-21T09:17:01.05202Z",
     "shell.execute_reply": "2022-04-21T09:17:01.050779Z",
     "shell.execute_reply.started": "2022-04-21T09:17:01.036334Z"
    },
    "papermill": {
     "duration": 0.025737,
     "end_time": "2022-05-11T16:22:15.641233",
     "exception": false,
     "start_time": "2022-05-11T16:22:15.615496",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fcdd1b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T16:22:15.707509Z",
     "iopub.status.busy": "2022-05-11T16:22:15.705847Z",
     "iopub.status.idle": "2022-05-11T16:22:15.708081Z",
     "shell.execute_reply": "2022-05-11T16:22:15.708520Z",
     "shell.execute_reply.started": "2022-05-11T16:04:43.742862Z"
    },
    "papermill": {
     "duration": 0.041534,
     "end_time": "2022-05-11T16:22:15.708703",
     "exception": false,
     "start_time": "2022-05-11T16:22:15.667169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.distributions import Beta\n",
    "\n",
    "\n",
    "class Mixup(torch.nn.Module):\n",
    "    def __init__(self, mix_beta=1):\n",
    "\n",
    "        super(Mixup, self).__init__()\n",
    "        self.beta_distribution = Beta(mix_beta, mix_beta)\n",
    "\n",
    "    def forward(self, X, Y, weight=None):\n",
    "\n",
    "        bs = X.shape[0]\n",
    "        n_dims = len(X.shape)\n",
    "        perm = torch.randperm(bs)\n",
    "        coeffs = self.beta_distribution.rsample(torch.Size((bs,))).to(X.device)\n",
    "\n",
    "        if n_dims == 2:\n",
    "            X = coeffs.view(-1, 1) * X + (1 - coeffs.view(-1, 1)) * X[perm]\n",
    "        elif n_dims == 3:\n",
    "            X = coeffs.view(-1, 1, 1) * X + (1 - coeffs.view(-1, 1, 1)) * X[perm]\n",
    "        else:\n",
    "            X = coeffs.view(-1, 1, 1, 1) * X + (1 - coeffs.view(-1, 1, 1, 1)) * X[perm]\n",
    "\n",
    "        Y = coeffs.view(-1, 1) * Y + (1 - coeffs.view(-1, 1)) * Y[perm]\n",
    "\n",
    "        if weight is None:\n",
    "            return X, Y\n",
    "        else:\n",
    "            weight = coeffs.view(-1) * weight + (1 - coeffs.view(-1)) * weight[perm]\n",
    "            return X, Y, weight\n",
    "        \n",
    "        \n",
    "class Attention(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, activation='linear'):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "        self.attn = torch.nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "        self.cla = torch.nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: b, c, t\n",
    "        attn = torch.softmax(torch.tanh(self.attn(x)), dim=-1) # b, c, t\n",
    "        x = self.cla(x) # b, c, t\n",
    "        x = torch.sum(x * attn, dim=-1) #b, c\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db5e6c94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T16:22:15.781111Z",
     "iopub.status.busy": "2022-05-11T16:22:15.780138Z",
     "iopub.status.idle": "2022-05-11T16:22:15.782392Z",
     "shell.execute_reply": "2022-05-11T16:22:15.782881Z",
     "shell.execute_reply.started": "2022-05-11T16:04:46.303091Z"
    },
    "papermill": {
     "duration": 0.048153,
     "end_time": "2022-05-11T16:22:15.783044",
     "exception": false,
     "start_time": "2022-05-11T16:22:15.734891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, backbone_path=None):\n",
    "        super().__init__()\n",
    "        self.audio2image = self._init_audio2image()\n",
    "        self.backbone = self._init_backbone()\n",
    "        self.load_backbone(backbone_path)\n",
    "        self.head = self._init_head(self.backbone.feature_info[-1]['num_chs'])      \n",
    "        self.loss = torch.nn.BCEWithLogitsLoss()\n",
    "        self.mixup = Mixup()\n",
    "        \n",
    "    def forward(self, wav_tensor, y=None):\n",
    "        # wav_tensor: b, t\n",
    "        if self.training:\n",
    "            wav_tensor = self.batch_crop(wav_tensor) # b, t\n",
    "            \n",
    "        spectrogram = self.audio2image(wav_tensor) # b, m, t\n",
    "        spectrogram = spectrogram.permute(0, 2, 1) # b, t, m\n",
    "        spectrogram = spectrogram[:, None, :, :] # b, c, t, m\n",
    "        \n",
    "        if self.training:\n",
    "            spectrogram = spectrogram.permute(0, 2, 1, 3) # b, t, c, m\n",
    "            spectrogram = self.batch_uncrop(spectrogram)\n",
    "            \n",
    "            spectrogram, y = self.mixup(spectrogram, y)\n",
    "            \n",
    "            spectrogram = self.batch_crop(spectrogram)\n",
    "            spectrogram = spectrogram.permute(0, 2, 1, 3) # b, c, t, m\n",
    "                \n",
    "        x = self.backbone(spectrogram) # b, c, t, m\n",
    "        if self.training:\n",
    "            x = x.permute(0, 2, 1, 3) # b, t, c, m\n",
    "            x = self.batch_uncrop(x)\n",
    "            x = x.permute(0, 2, 1, 3) # b, c, t, m\n",
    "        \n",
    "        # average mel axis\n",
    "        x = torch.mean(x, axis=-1)\n",
    "                \n",
    "        logits = self.head(x) # b, n_out\n",
    "        \n",
    "        if y is not None:\n",
    "            loss = self.loss(logits, y)\n",
    "        else:\n",
    "            loss = None\n",
    "\n",
    "        return {'loss': loss, 'logits': logits.sigmoid()}\n",
    "    \n",
    "    def batch_crop(self, tensor):\n",
    "        factor = int(CONFIG['crop_len'] // TEST_SIZE)\n",
    "        b, t = tensor.shape[:2]\n",
    "        tensor = tensor.reshape(b * factor, t // factor, *tensor.shape[2:])\n",
    "        return tensor\n",
    "    \n",
    "    def batch_uncrop(self, tensor):\n",
    "        factor = int(CONFIG['crop_len'] // TEST_SIZE)\n",
    "        b, t = tensor.shape[:2]\n",
    "        tensor = tensor.reshape(b // factor, t * factor, *tensor.shape[2:])\n",
    "        return tensor\n",
    "    \n",
    "    @staticmethod\n",
    "    def _init_audio2image():\n",
    "        mel = ta.transforms.MelSpectrogram(\n",
    "            sample_rate=32000,\n",
    "            n_fft=2048,\n",
    "            win_length=2048,\n",
    "            hop_length=512,\n",
    "            f_min=16,\n",
    "            f_max=16386,\n",
    "            pad=0,\n",
    "            n_mels=256,\n",
    "            power=2,\n",
    "            normalized=False,\n",
    "        )\n",
    "        db_scale = ta.transforms.AmplitudeToDB(top_db=80.0)\n",
    "        audio2image = torch.nn.Sequential(mel, db_scale)\n",
    "        return audio2image\n",
    "    \n",
    "    @staticmethod\n",
    "    def _init_backbone():\n",
    "        backbone = \"resnet18\"\n",
    "        pretrained = False\n",
    "        pretrained_weights = None\n",
    "        train = True\n",
    "        val = False\n",
    "        in_chans = 1\n",
    "\n",
    "        backbone = timm.create_model(\n",
    "            backbone,\n",
    "            pretrained=pretrained,\n",
    "            num_classes=0,\n",
    "            global_pool=\"\",\n",
    "            in_chans=in_chans,\n",
    "        )\n",
    "        return backbone\n",
    "    \n",
    "    @staticmethod\n",
    "    def _init_head(num_chs):\n",
    "        head = Attention(num_chs, len(all_species), activation='linear')\n",
    "        return head\n",
    "    \n",
    "    def load_backbone(self, weights_path=None):\n",
    "        if weights_path:\n",
    "            state_dict=torch.load(weights_path)\n",
    "            conv1_weight = state_dict['conv1.weight']\n",
    "            state_dict['conv1.weight'] = conv1_weight.sum(dim=1, keepdim=True)\n",
    "            state_dict.pop('fc.bias')\n",
    "            state_dict.pop('fc.weight')\n",
    "            self.backbone.load_state_dict(state_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec960238",
   "metadata": {
    "papermill": {
     "duration": 0.029733,
     "end_time": "2022-05-11T16:22:15.839746",
     "exception": false,
     "start_time": "2022-05-11T16:22:15.810013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21589aec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T16:22:15.902916Z",
     "iopub.status.busy": "2022-05-11T16:22:15.902191Z",
     "iopub.status.idle": "2022-05-11T16:22:15.909138Z",
     "shell.execute_reply": "2022-05-11T16:22:15.909593Z",
     "shell.execute_reply.started": "2022-05-11T16:04:49.247879Z"
    },
    "papermill": {
     "duration": 0.04056,
     "end_time": "2022-05-11T16:22:15.909778",
     "exception": false,
     "start_time": "2022-05-11T16:22:15.869218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('../input/timm-pretrained-resnet/index.json') as fin:\n",
    "    timm_index = json.load(fin)\n",
    "resnet_path = os.path.join('../input/timm-pretrained-resnet/resnet', timm_index['resnet']['resnet18'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11f40976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T16:22:15.972623Z",
     "iopub.status.busy": "2022-05-11T16:22:15.970740Z",
     "iopub.status.idle": "2022-05-11T16:22:15.973274Z",
     "shell.execute_reply": "2022-05-11T16:22:15.973700Z",
     "shell.execute_reply.started": "2022-05-11T16:04:49.934392Z"
    },
    "papermill": {
     "duration": 0.035336,
     "end_time": "2022-05-11T16:22:15.973842",
     "exception": false,
     "start_time": "2022-05-11T16:22:15.938506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9561e420",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T16:22:16.031675Z",
     "iopub.status.busy": "2022-05-11T16:22:16.030760Z",
     "iopub.status.idle": "2022-05-11T16:22:16.046311Z",
     "shell.execute_reply": "2022-05-11T16:22:16.045833Z",
     "shell.execute_reply.started": "2022-05-11T16:04:51.992060Z"
    },
    "papermill": {
     "duration": 0.046325,
     "end_time": "2022-05-11T16:22:16.046447",
     "exception": false,
     "start_time": "2022-05-11T16:22:16.000122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_meta, val_meta = train_test_split(train_meta, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21644444",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T16:22:16.108050Z",
     "iopub.status.busy": "2022-05-11T16:22:16.107363Z",
     "iopub.status.idle": "2022-05-11T16:22:20.327186Z",
     "shell.execute_reply": "2022-05-11T16:22:20.329027Z",
     "shell.execute_reply.started": "2022-05-11T16:04:53.205881Z"
    },
    "papermill": {
     "duration": 4.256992,
     "end_time": "2022-05-11T16:22:20.329431",
     "exception": false,
     "start_time": "2022-05-11T16:22:16.072439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Net(resnet_path)\n",
    "train_dataset = BirdDataset(\n",
    "    train_meta,\n",
    "    Compose(\n",
    "                [\n",
    "                    OneOf(\n",
    "                        [\n",
    "                            NoiseInjection(p=1, max_noise_level=0.04),\n",
    "                            GaussianNoise(p=1, min_snr=5, max_snr=20),\n",
    "#                             PinkNoise(p=1, min_snr=5, max_snr=20),\n",
    "                        ],\n",
    "                        p=0.2,\n",
    "                    ),\n",
    "                    RandomVolume(p=0.2, limit=4),\n",
    "                    Normalize(p=1),\n",
    "                ]\n",
    "            )\n",
    ")\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=False,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_dataset = BirdDataset(\n",
    "    val_meta,\n",
    "    Compose([Normalize(p=1)])\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=False,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9eccb345",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T16:22:20.423450Z",
     "iopub.status.busy": "2022-05-11T16:22:20.422550Z",
     "iopub.status.idle": "2022-05-11T16:22:20.424980Z",
     "shell.execute_reply": "2022-05-11T16:22:20.425592Z",
     "shell.execute_reply.started": "2022-05-11T16:04:57.686880Z"
    },
    "papermill": {
     "duration": 0.051071,
     "end_time": "2022-05-11T16:22:20.425792",
     "exception": false,
     "start_time": "2022-05-11T16:22:20.374721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_path = '../input/birdclefsubmit/9_model.pt'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# model = torch.load(model_path, map_location=device)\n",
    "# model.load_state_dict(state_dict)\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "699beed2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T16:22:20.519779Z",
     "iopub.status.busy": "2022-05-11T16:22:20.518915Z",
     "iopub.status.idle": "2022-05-11T16:22:20.526194Z",
     "shell.execute_reply": "2022-05-11T16:22:20.526969Z",
     "shell.execute_reply.started": "2022-05-11T16:04:57.864817Z"
    },
    "papermill": {
     "duration": 0.059345,
     "end_time": "2022-05-11T16:22:20.527168",
     "exception": false,
     "start_time": "2022-05-11T16:22:20.467823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, dataloader, device):\n",
    "    tqdm_dataloader = tqdm(dataloader)\n",
    "    loss_list = []\n",
    "    model.train()\n",
    "    for batch in tqdm_dataloader:\n",
    "        loss = model(batch['wav'].to(device), batch['target'].to(device))['loss']\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_list.append(loss.item())\n",
    "    return loss_list\n",
    "    \n",
    "\n",
    "def val_epoch(model, dataloader, device):\n",
    "    tqdm_dataloader = tqdm(dataloader)\n",
    "    loss_list = []\n",
    "    model.eval()\n",
    "    y_true = None\n",
    "    y_pred = None\n",
    "    \n",
    "    for batch in tqdm_dataloader:\n",
    "        logits = model(batch['wav'].to(device))['logits']\n",
    "        batch_target = batch['target'].cpu().numpy()\n",
    "        batch_pred = logits.cpu().numpy()\n",
    "        \n",
    "        if y_true is None:\n",
    "            y_true = batch_target\n",
    "            y_pred = batch_pred\n",
    "        else:\n",
    "            y_true = np.vstack((y_true, batch_target))\n",
    "            y_pred = np.vstack((y_pred, batch_pred))\n",
    "        \n",
    "    return y_true, y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b567df6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T16:22:20.620879Z",
     "iopub.status.busy": "2022-05-11T16:22:20.620007Z",
     "iopub.status.idle": "2022-05-11T16:22:20.629093Z",
     "shell.execute_reply": "2022-05-11T16:22:20.629841Z",
     "shell.execute_reply.started": "2022-05-11T16:05:11.213647Z"
    },
    "papermill": {
     "duration": 0.060879,
     "end_time": "2022-05-11T16:22:20.630062",
     "exception": false,
     "start_time": "2022-05-11T16:22:20.569183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score_pred(y_true, y_pred, trsh, score_conf):\n",
    "    score_dict = {}\n",
    "    for score_f, score_kwargs, score_prefix in score_conf:\n",
    "        score_dict.update({\n",
    "            f'{score_prefix}-{t}': score_f(y_true, y_pred > t, **score_kwargs)\n",
    "            for t in trsh\n",
    "        })\n",
    "    return score_dict\n",
    "\n",
    "\n",
    "import sklearn.metrics\n",
    "\n",
    "def comp_metric(y_true, y_pred, epsilon=1e-9):\n",
    "    \"\"\" Function to calculate competition metric in an sklearn like fashion\n",
    "\n",
    "    Args:\n",
    "        y_true{array-like, sparse matrix} of shape (n_samples, n_outputs)\n",
    "            - Ground truth (correct) target values.\n",
    "        y_pred{array-like, sparse matrix} of shape (n_samples, n_outputs)\n",
    "            - Estimated targets as returned by a classifier.\n",
    "    Returns:\n",
    "        The single calculated score representative of this competitions evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    # Get representative confusion matrices for each label\n",
    "    mlbl_cms = sklearn.metrics.multilabel_confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Get two scores (TP and TN SCORES)\n",
    "    tp_scores = np.array([\n",
    "        mlbl_cm[1, 1]/(epsilon+mlbl_cm[:, 1].sum()) \\\n",
    "        for mlbl_cm in mlbl_cms\n",
    "        ])\n",
    "    tn_scores = np.array([\n",
    "        mlbl_cm[0, 0]/(epsilon+mlbl_cm[:, 0].sum()) \\\n",
    "        for mlbl_cm in mlbl_cms\n",
    "        ])\n",
    "\n",
    "    # Get average\n",
    "    tp_mean = tp_scores.mean()\n",
    "    tn_mean = tn_scores.mean()\n",
    "\n",
    "    return round((tp_mean+tn_mean)/2, 8)\n",
    "\n",
    "\n",
    "def balanced_accuracy(pred, target, eps=1e-6):\n",
    "    tp = (pred * target).sum(axis=-1)\n",
    "    fn = ((1 - pred) * target).sum(axis=-1)\n",
    "    fp = (pred * (1 - target)).sum(axis=-1)\n",
    "    tn = ((1 - pred) * (1 - target)).sum(axis=-1)\n",
    "    tpr = tp / (tp + fn + eps)\n",
    "    tnr = tn / (tn + fp + eps)\n",
    "    return (0.5 * (tpr + tnr)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcf1f2b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T16:22:20.720134Z",
     "iopub.status.busy": "2022-05-11T16:22:20.719331Z",
     "iopub.status.idle": "2022-05-11T16:22:20.724196Z",
     "shell.execute_reply": "2022-05-11T16:22:20.723468Z",
     "shell.execute_reply.started": "2022-05-11T16:05:18.569605Z"
    },
    "papermill": {
     "duration": 0.052041,
     "end_time": "2022-05-11T16:22:20.724373",
     "exception": false,
     "start_time": "2022-05-11T16:22:20.672332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_conf = [\n",
    "    [f1_score, {'average': 'macro'}, 'f1'],\n",
    "    [comp_metric, {}, 'comp_metric'],\n",
    "    [balanced_accuracy, {}, 'balanced_accuracy']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "158ea8d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T16:22:20.817483Z",
     "iopub.status.busy": "2022-05-11T16:22:20.816567Z",
     "iopub.status.idle": "2022-05-11T18:40:34.031955Z",
     "shell.execute_reply": "2022-05-11T18:40:34.032454Z"
    },
    "papermill": {
     "duration": 8293.264255,
     "end_time": "2022-05-11T18:40:34.032649",
     "exception": false,
     "start_time": "2022-05-11T16:22:20.768394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [11:53<00:00,  3.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train loss:\t0.050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:34<00:00,  3.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 val scores:\n",
      "\tf1-0.1: 0.005904889839201814\n",
      "\tf1-0.4: 0.0017804412020149384\n",
      "\tf1-0.3: 0.001776466337468385\n",
      "\tf1-0.2: 0.003249090787903309\n",
      "\tcomp_metric-0.1: 0.49992994\n",
      "\tcomp_metric-0.4: 0.49711071\n",
      "\tcomp_metric-0.3: 0.49699692\n",
      "\tcomp_metric-0.2: 0.50027031\n",
      "\tbalanced_accuracy-0.1: 0.5107905110834818\n",
      "\tbalanced_accuracy-0.4: 0.5032661244521772\n",
      "\tbalanced_accuracy-0.3: 0.5062301021627575\n",
      "\tbalanced_accuracy-0.2: 0.5085963884695998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [11:19<00:00,  3.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 train loss:\t0.037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:22<00:00,  3.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 val scores:\n",
      "\tf1-0.1: 0.027033849122260326\n",
      "\tf1-0.4: 0.018142708333145227\n",
      "\tf1-0.3: 0.018785164083193882\n",
      "\tf1-0.2: 0.02127612074688056\n",
      "\tcomp_metric-0.1: 0.51960961\n",
      "\tcomp_metric-0.4: 0.51333256\n",
      "\tcomp_metric-0.3: 0.51167081\n",
      "\tcomp_metric-0.2: 0.51407679\n",
      "\tbalanced_accuracy-0.1: 0.5583332673519819\n",
      "\tbalanced_accuracy-0.4: 0.547072081622852\n",
      "\tbalanced_accuracy-0.3: 0.5503982153673509\n",
      "\tbalanced_accuracy-0.2: 0.5559929552864539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [11:22<00:00,  3.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 train loss:\t0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:23<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 val scores:\n",
      "\tf1-0.1: 0.1121819042128423\n",
      "\tf1-0.4: 0.08285671873387351\n",
      "\tf1-0.3: 0.09285454776759769\n",
      "\tf1-0.2: 0.10431258612121645\n",
      "\tcomp_metric-0.1: 0.56295326\n",
      "\tcomp_metric-0.4: 0.577455\n",
      "\tcomp_metric-0.3: 0.57290245\n",
      "\tcomp_metric-0.2: 0.57305623\n",
      "\tbalanced_accuracy-0.1: 0.6493013198954362\n",
      "\tbalanced_accuracy-0.4: 0.6111653594542074\n",
      "\tbalanced_accuracy-0.3: 0.6271443706163543\n",
      "\tbalanced_accuracy-0.2: 0.6439986889530447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [11:24<00:00,  3.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 train loss:\t0.030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:26<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 val scores:\n",
      "\tf1-0.1: 0.1805224451807214\n",
      "\tf1-0.4: 0.13784254354636327\n",
      "\tf1-0.3: 0.15094806474850322\n",
      "\tf1-0.2: 0.16990522830381574\n",
      "\tcomp_metric-0.1: 0.59674168\n",
      "\tcomp_metric-0.4: 0.61582874\n",
      "\tcomp_metric-0.3: 0.60891723\n",
      "\tcomp_metric-0.2: 0.6071952\n",
      "\tbalanced_accuracy-0.1: 0.7056628896968791\n",
      "\tbalanced_accuracy-0.4: 0.6800911653901802\n",
      "\tbalanced_accuracy-0.3: 0.696776290684886\n",
      "\tbalanced_accuracy-0.2: 0.7111233986416694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [11:18<00:00,  3.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 train loss:\t0.028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:26<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 val scores:\n",
      "\tf1-0.1: 0.21796864406938593\n",
      "\tf1-0.4: 0.17121325017970193\n",
      "\tf1-0.3: 0.19152267854548644\n",
      "\tf1-0.2: 0.20835214615415493\n",
      "\tcomp_metric-0.1: 0.61504775\n",
      "\tcomp_metric-0.4: 0.63582148\n",
      "\tcomp_metric-0.3: 0.64806704\n",
      "\tcomp_metric-0.2: 0.63856206\n",
      "\tbalanced_accuracy-0.1: 0.7167532414179364\n",
      "\tbalanced_accuracy-0.4: 0.6955858494654591\n",
      "\tbalanced_accuracy-0.3: 0.712571551604692\n",
      "\tbalanced_accuracy-0.2: 0.7234849518396546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [11:20<00:00,  3.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 train loss:\t0.027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:23<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 val scores:\n",
      "\tf1-0.1: 0.2512657401563303\n",
      "\tf1-0.4: 0.2295542598515118\n",
      "\tf1-0.3: 0.24077940008037244\n",
      "\tf1-0.2: 0.2524350526209989\n",
      "\tcomp_metric-0.1: 0.62837303\n",
      "\tcomp_metric-0.4: 0.66180966\n",
      "\tcomp_metric-0.3: 0.65216606\n",
      "\tcomp_metric-0.2: 0.6468649\n",
      "\tbalanced_accuracy-0.1: 0.7431702782594599\n",
      "\tbalanced_accuracy-0.4: 0.7484570849052739\n",
      "\tbalanced_accuracy-0.3: 0.7586157569023497\n",
      "\tbalanced_accuracy-0.2: 0.7613733541225814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [11:14<00:00,  3.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 train loss:\t0.026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:26<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 val scores:\n",
      "\tf1-0.1: 0.24064872478643645\n",
      "\tf1-0.4: 0.20252232090717004\n",
      "\tf1-0.3: 0.21019003437237127\n",
      "\tf1-0.2: 0.2305656530894011\n",
      "\tcomp_metric-0.1: 0.64080417\n",
      "\tcomp_metric-0.4: 0.66294881\n",
      "\tcomp_metric-0.3: 0.66479199\n",
      "\tcomp_metric-0.2: 0.65238864\n",
      "\tbalanced_accuracy-0.1: 0.7053768718732224\n",
      "\tbalanced_accuracy-0.4: 0.6991037675687346\n",
      "\tbalanced_accuracy-0.3: 0.7092935871433989\n",
      "\tbalanced_accuracy-0.2: 0.717830680492405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [11:21<00:00,  3.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 train loss:\t0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:25<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 val scores:\n",
      "\tf1-0.1: 0.30592284734445646\n",
      "\tf1-0.4: 0.28266418076260075\n",
      "\tf1-0.3: 0.29363336829398834\n",
      "\tf1-0.2: 0.3023420984490839\n",
      "\tcomp_metric-0.1: 0.65673965\n",
      "\tcomp_metric-0.4: 0.70757947\n",
      "\tcomp_metric-0.3: 0.69443038\n",
      "\tcomp_metric-0.2: 0.68013074\n",
      "\tbalanced_accuracy-0.1: 0.7622138394960898\n",
      "\tbalanced_accuracy-0.4: 0.7674638866863177\n",
      "\tbalanced_accuracy-0.3: 0.7785961626105657\n",
      "\tbalanced_accuracy-0.2: 0.7840385362357434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [11:22<00:00,  3.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 train loss:\t0.024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:23<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 val scores:\n",
      "\tf1-0.1: 0.33017603764459863\n",
      "\tf1-0.4: 0.3078971937409136\n",
      "\tf1-0.3: 0.31711207128270624\n",
      "\tf1-0.2: 0.3375207065504641\n",
      "\tcomp_metric-0.1: 0.67315883\n",
      "\tcomp_metric-0.4: 0.71240481\n",
      "\tcomp_metric-0.3: 0.70630272\n",
      "\tcomp_metric-0.2: 0.70820667\n",
      "\tbalanced_accuracy-0.1: 0.7685383282485523\n",
      "\tbalanced_accuracy-0.4: 0.7784249252305927\n",
      "\tbalanced_accuracy-0.3: 0.7870844212988631\n",
      "\tbalanced_accuracy-0.2: 0.7918554554072144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [11:13<00:00,  3.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 train loss:\t0.023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:24<00:00,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 val scores:\n",
      "\tf1-0.1: 0.33363933206155616\n",
      "\tf1-0.4: 0.3235419526388814\n",
      "\tf1-0.3: 0.32722256951817913\n",
      "\tf1-0.2: 0.3384155114477694\n",
      "\tcomp_metric-0.1: 0.6753217\n",
      "\tcomp_metric-0.4: 0.7328664\n",
      "\tcomp_metric-0.3: 0.71912892\n",
      "\tcomp_metric-0.2: 0.70110392\n",
      "\tbalanced_accuracy-0.1: 0.7568669119773269\n",
      "\tbalanced_accuracy-0.4: 0.7752561282011735\n",
      "\tbalanced_accuracy-0.3: 0.7769569969592962\n",
      "\tbalanced_accuracy-0.2: 0.779585657915643\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "epochs = 10\n",
    "model.to(device)\n",
    "for e in range(epochs):\n",
    "    epoch_loss = train_epoch(model, optimizer, train_dataloader, device)\n",
    "    print(f'{e} train loss:', f'{np.mean(epoch_loss):.3f}', sep='\\t')\n",
    "    with torch.no_grad():\n",
    "        y_true, y_pred = val_epoch(model, val_dataloader, device)\n",
    "    score_dict = score_pred(\n",
    "        y_true, y_pred,\n",
    "        score_conf=score_conf,\n",
    "        trsh={0.1, 0.2, 0.3, 0.4}\n",
    "    )\n",
    "    torch.save(model, f'{e}_model.pt')\n",
    "    print(f'{e} val scores:')\n",
    "    print(*[\n",
    "        f'\\t{case}: {case_score}' \n",
    "        for case, case_score in score_dict.items()\n",
    "    ], sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db0e4325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T18:40:35.758870Z",
     "iopub.status.busy": "2022-05-11T18:40:35.758019Z",
     "iopub.status.idle": "2022-05-11T18:40:36.112336Z",
     "shell.execute_reply": "2022-05-11T18:40:36.112793Z"
    },
    "papermill": {
     "duration": 1.10273,
     "end_time": "2022-05-11T18:40:36.112969",
     "exception": false,
     "start_time": "2022-05-11T18:40:35.010239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1-0.1': 0.33363933206155616,\n",
       " 'f1-0.25': 0.33730968713714216,\n",
       " 'f1-0.3': 0.32722256951817913,\n",
       " 'f1-0.2': 0.3384155114477694,\n",
       " 'f1-0.15': 0.33879490542361324,\n",
       " 'comp_metric-0.1': 0.6753217,\n",
       " 'comp_metric-0.25': 0.71384632,\n",
       " 'comp_metric-0.3': 0.71912892,\n",
       " 'comp_metric-0.2': 0.70110392,\n",
       " 'comp_metric-0.15': 0.68914757,\n",
       " 'balanced_accuracy-0.1': 0.7568669119773269,\n",
       " 'balanced_accuracy-0.25': 0.7799686526861095,\n",
       " 'balanced_accuracy-0.3': 0.7769569969592962,\n",
       " 'balanced_accuracy-0.2': 0.779585657915643,\n",
       " 'balanced_accuracy-0.15': 0.7731807205998932}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_pred(\n",
    "        y_true, y_pred,\n",
    "        score_conf=score_conf,\n",
    "        trsh={0.1, 0.15, 0.2, 0.25, 0.3}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9276e36c",
   "metadata": {
    "papermill": {
     "duration": 0.765376,
     "end_time": "2022-05-11T18:40:37.633743",
     "exception": false,
     "start_time": "2022-05-11T18:40:36.868367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "102336cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T18:40:39.134343Z",
     "iopub.status.busy": "2022-05-11T18:40:39.133156Z",
     "iopub.status.idle": "2022-05-11T18:40:39.141181Z",
     "shell.execute_reply": "2022-05-11T18:40:39.141630Z"
    },
    "papermill": {
     "duration": 0.756912,
     "end_time": "2022-05-11T18:40:39.141775",
     "exception": false,
     "start_time": "2022-05-11T18:40:38.384863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_root, 'scored_birds.json')) as fin:\n",
    "    test_birds = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23568677",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T18:40:41.147128Z",
     "iopub.status.busy": "2022-05-11T18:40:41.146448Z",
     "iopub.status.idle": "2022-05-11T18:40:41.148803Z",
     "shell.execute_reply": "2022-05-11T18:40:41.149295Z"
    },
    "papermill": {
     "duration": 1.114988,
     "end_time": "2022-05-11T18:40:41.149448",
     "exception": false,
     "start_time": "2022-05-11T18:40:40.034460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_folder):\n",
    "        super().__init__()\n",
    "        self.test_folder = test_folder\n",
    "        self.fnames = [f for f in os.listdir(test_folder) if f.endswith('.ogg')]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fpath = os.path.join(self.test_folder, self.fnames[idx])\n",
    "        wav, sr = load_wav(fpath, 0, None)\n",
    "        wav = torch.tensor(wav)\n",
    "        assert (13 * 5 * sr) > len(wav) \n",
    "        wav = wav[:len(wav) // 12 * 12].reshape((12, len(wav) // 12))\n",
    "        return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9c38d4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T18:40:42.706176Z",
     "iopub.status.busy": "2022-05-11T18:40:42.705445Z",
     "iopub.status.idle": "2022-05-11T18:40:42.710861Z",
     "shell.execute_reply": "2022-05-11T18:40:42.710450Z"
    },
    "papermill": {
     "duration": 0.758441,
     "end_time": "2022-05-11T18:40:42.710975",
     "exception": false,
     "start_time": "2022-05-11T18:40:41.952534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(os.path.join(data_root, 'test_soundscapes'))\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    drop_last=False,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23c88172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T18:40:44.223147Z",
     "iopub.status.busy": "2022-05-11T18:40:44.222484Z",
     "iopub.status.idle": "2022-05-11T18:40:44.455314Z",
     "shell.execute_reply": "2022-05-11T18:40:44.454814Z"
    },
    "papermill": {
     "duration": 0.997279,
     "end_time": "2022-05-11T18:40:44.455444",
     "exception": false,
     "start_time": "2022-05-11T18:40:43.458165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.18it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "treshold = 0.1\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm(enumerate(test_dataloader)):\n",
    "        batch_size, part_count, part_size = batch.shape\n",
    "        batch = batch.reshape(batch_size * part_count, part_size)\n",
    "        pred = model(batch.to(device))['logits']\n",
    "        pred = pred.cpu().numpy()\n",
    "        pred = pred > treshold\n",
    "        \n",
    "        for j, chunk_pred in enumerate(pred):\n",
    "            inbatch_number = j // part_count\n",
    "            chunk_number = j % part_count + 1\n",
    "            f_idx = i * batch_size + inbatch_number\n",
    "            fname = test_dataset.fnames[f_idx]\n",
    "            prefix = fname.split('.')[0]\n",
    "            sufix = f'{5 * chunk_number}'\n",
    "            \n",
    "            pred_list.extend([{\n",
    "                'row_id': '_'.join([prefix, b, sufix]),\n",
    "                'target': chunk_pred[species2id[b]]\n",
    "            } for b in test_birds])\n",
    "pred_pd = pd.DataFrame(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2778cd28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T18:40:46.239144Z",
     "iopub.status.busy": "2022-05-11T18:40:46.238374Z",
     "iopub.status.idle": "2022-05-11T18:40:46.255756Z",
     "shell.execute_reply": "2022-05-11T18:40:46.255334Z"
    },
    "papermill": {
     "duration": 1.049374,
     "end_time": "2022-05-11T18:40:46.255871",
     "exception": false,
     "start_time": "2022-05-11T18:40:45.206497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_453028782_akiapo_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soundscape_453028782_aniani_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soundscape_453028782_apapan_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soundscape_453028782_barpet_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soundscape_453028782_crehon_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>soundscape_453028782_omao_60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>soundscape_453028782_puaioh_60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>soundscape_453028782_skylar_60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>soundscape_453028782_warwhe1_60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>soundscape_453028782_yefcan_60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              row_id  target\n",
       "0      soundscape_453028782_akiapo_5   False\n",
       "1      soundscape_453028782_aniani_5   False\n",
       "2      soundscape_453028782_apapan_5   False\n",
       "3      soundscape_453028782_barpet_5   False\n",
       "4      soundscape_453028782_crehon_5   False\n",
       "..                               ...     ...\n",
       "247     soundscape_453028782_omao_60   False\n",
       "248   soundscape_453028782_puaioh_60   False\n",
       "249   soundscape_453028782_skylar_60   False\n",
       "250  soundscape_453028782_warwhe1_60   False\n",
       "251   soundscape_453028782_yefcan_60   False\n",
       "\n",
       "[252 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_pd.to_csv(\"submission.csv\", index=False)\n",
    "pred_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "878f7822",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T18:40:47.777002Z",
     "iopub.status.busy": "2022-05-11T18:40:47.776036Z",
     "iopub.status.idle": "2022-05-11T18:40:47.777961Z",
     "shell.execute_reply": "2022-05-11T18:40:47.778423Z"
    },
    "papermill": {
     "duration": 0.769899,
     "end_time": "2022-05-11T18:40:47.778556",
     "exception": false,
     "start_time": "2022-05-11T18:40:47.008657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def chunk_wav(wav, sr, window_size):\n",
    "#     chunks_count = len(wav) // (window_size * sr)\n",
    "#     chunk_size = window_size * sr\n",
    "#     chunks = []\n",
    "#     for chunk_idx in range(chunks_count):\n",
    "#         left = chunk_idx * sr\n",
    "#         right = min(left + chunk_size, len(wav))\n",
    "#         chunks.append(wav[left:right])\n",
    "#     chunk_tensor = torch.tensor(chunks)\n",
    "#     return chunk_tensor\n",
    "\n",
    "# file_list = os.listdir(os.path.join(data_root, 'test_soundscapes'))\n",
    "\n",
    "# # This is where we will store our results\n",
    "# treshold = 0.5\n",
    "# pred = {'row_id': [], 'target': []}\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     # Process audio files and make predictions\n",
    "#     for fname in file_list:\n",
    "#         prefix = fname.split('.')[0]\n",
    "#         # Complete file path\n",
    "#         fpath = os.path.join(data_root, 'test_soundscapes', fname)\n",
    "#         wav, sr = load_wav(fpath, 0, None)\n",
    "#         chunk_tensor = chunk_wav(wav, sr, window_size=5)\n",
    "\n",
    "#         # Open file with librosa and split signal into 5-second chunks\n",
    "#         # sig, rate = librosa.load(path)\n",
    "#         # ...\n",
    "\n",
    "#         # Let's assume we have a list of 12 audio chunks (1min / 5s == 12 segments)\n",
    "#         chunk_score = model(chunk_tensor.to(device))['logits'].cpu().numpy()\n",
    "\n",
    "#         # Make prediction for each chunk\n",
    "#         # Each scored bird gets a random value in our case\n",
    "#         # since we don't actually have a model\n",
    "#         for i, all_score in enumerate(chunk_score):        \n",
    "#             chunk_end_time = (i + 1) * 5\n",
    "#             for bird in test_birds:\n",
    "\n",
    "#                 # This is our random prediction score for this bird\n",
    "#                 bird_score = all_score[species2id[bird]]\n",
    "\n",
    "#                 # Assemble the row_id which we need to do for each scored bird\n",
    "#                 row_id = prefix + '_' + bird + '_' + str(chunk_end_time)\n",
    "\n",
    "#                 # Put the result into our prediction dict and\n",
    "#                 # apply a \"confidence\" threshold of 0.5\n",
    "#                 pred['row_id'].append(row_id)\n",
    "#                 pred['target'].append(True if bird_score > treshold else False)\n",
    "\n",
    "\n",
    "# # Make a new data frame and look at some results        \n",
    "# results = pd.DataFrame(pred, columns = ['row_id', 'target'])\n",
    "\n",
    "# # Quick sanity check\n",
    "# print(results.head()) \n",
    "    \n",
    "# # Convert our results to csv\n",
    "# results.to_csv(\"submission.csv\", index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cadf26b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-11T18:40:49.278507Z",
     "iopub.status.busy": "2022-05-11T18:40:49.277597Z",
     "iopub.status.idle": "2022-05-11T18:40:49.279947Z",
     "shell.execute_reply": "2022-05-11T18:40:49.280425Z"
    },
    "papermill": {
     "duration": 0.757989,
     "end_time": "2022-05-11T18:40:49.280595",
     "exception": false,
     "start_time": "2022-05-11T18:40:48.522606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_fnames = [f for f in os.listdir(f'{data_root}/test_soundscapes') if f.endswith('.ogg')]\n",
    "# test_pd = []\n",
    "# for fname in test_fnames:\n",
    "#     fpath = os.path.join(data_root, 'test_soundscapes', fname)\n",
    "#     wav, sr = librosa.load(fpath, sr=None)\n",
    "#     prefix = fname.split('.')[0]\n",
    "#     window_size = 5 * sr\n",
    "#     for i, chunk in enumerate(wav[::window_size]):\n",
    "#         end_time = (i + 1) * 5\n",
    "#         samples = [{\n",
    "#             'row_id': f'{prefix}_{b}_{end_time}',\n",
    "#             'file_id': fname,\n",
    "#             'bird': b,\n",
    "#             'end_time': end_time\n",
    "#         } for b in test_birds]\n",
    "#         test_pd.extend(samples)\n",
    "        \n",
    "# test_pd = pd.DataFrame(test_pd)\n",
    "# test_pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8332.800539,
   "end_time": "2022-05-11T18:40:52.463549",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-11T16:21:59.663010",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
