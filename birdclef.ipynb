{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport json\n\nimport librosa\n\nimport torch\nimport torchaudio as ta\nimport timm\n\nfrom tqdm import tqdm\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-30T08:29:56.489712Z","iopub.execute_input":"2022-04-30T08:29:56.489963Z","iopub.status.idle":"2022-04-30T08:29:56.495244Z","shell.execute_reply.started":"2022-04-30T08:29:56.489935Z","shell.execute_reply":"2022-04-30T08:29:56.494572Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"data_root = '/kaggle/input/birdclef-2022'\ntrain_meta = pd.read_csv(os.path.join(data_root, 'train_metadata.csv'))\nebird_taxonomy = pd.read_csv(os.path.join(data_root, 'eBird_Taxonomy_v2021.csv'))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:29:57.210765Z","iopub.execute_input":"2022-04-30T08:29:57.211526Z","iopub.status.idle":"2022-04-30T08:29:57.317697Z","shell.execute_reply.started":"2022-04-30T08:29:57.211487Z","shell.execute_reply":"2022-04-30T08:29:57.316953Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_meta.loc[:, 'secondary_labels'] = train_meta.secondary_labels.apply(eval)\ntrain_meta['target_raw'] = train_meta.secondary_labels + train_meta.primary_label.apply(lambda x: [x])","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:30:02.001620Z","iopub.execute_input":"2022-04-30T08:30:02.002275Z","iopub.status.idle":"2022-04-30T08:30:02.080789Z","shell.execute_reply.started":"2022-04-30T08:30:02.002235Z","shell.execute_reply":"2022-04-30T08:30:02.080095Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"all_species = sorted(set(train_meta.target_raw.sum()))\nspecies2id = {s: i for i, s in enumerate(all_species)}\nid2species = {i: s for i, s in enumerate(all_species)}\n\ntrain_meta['target'] = train_meta.target_raw.apply(lambda species: [int(s in species) for s in all_species])","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:30:02.481408Z","iopub.execute_input":"2022-04-30T08:30:02.481634Z","iopub.status.idle":"2022-04-30T08:30:03.258184Z","shell.execute_reply.started":"2022-04-30T08:30:02.481608Z","shell.execute_reply":"2022-04-30T08:30:03.257444Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def load_wav(fname, offset, duration):\n#     fname = 'afrsil1/XC125458.ogg'\n    fpath = os.path.join(data_root, 'train_audio', fname)\n    wav, sr = librosa.load(fpath, sr=None, duration=duration)\n    assert sr <= 32000, sr\n    return wav, sr","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:30:03.259731Z","iopub.execute_input":"2022-04-30T08:30:03.259982Z","iopub.status.idle":"2022-04-30T08:30:03.264754Z","shell.execute_reply.started":"2022-04-30T08:30:03.259945Z","shell.execute_reply":"2022-04-30T08:30:03.264100Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# %%time\n# duration = 30\n# sample_rate = 32000\n\n# wav, sr = load_wav('afrsil1/XC125458.ogg', 5, duration)\n# to_pad = duration * sample_rate - wav.shape[0]\n\n# if to_pad > 0:\n#     wav = np.pad(wav, (0, to_pad))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:30:03.265764Z","iopub.execute_input":"2022-04-30T08:30:03.266467Z","iopub.status.idle":"2022-04-30T08:30:03.277073Z","shell.execute_reply.started":"2022-04-30T08:30:03.266418Z","shell.execute_reply":"2022-04-30T08:30:03.276254Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Torch Dataset","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\nclass BirdDataset(Dataset):\n    def __init__(self, df):\n        super().__init__()\n        self.df = df\n        \n    def __getitem__(self, idx):\n        duration = 30\n        sample_rate = 32000\n        \n        fname = self.df.iloc[idx]['filename']\n        # TODO: add random offset\n        wav, sr = load_wav(fname, 0, duration)\n        to_pad = duration * sample_rate - wav.shape[0]\n        if to_pad > 0:\n            wav = np.pad(wav, (0, to_pad))\n            \n        target = self.df.iloc[idx]['target']\n        \n        # TODO: add weighting\n            \n        wav = torch.tensor(wav)\n        target = torch.tensor(target, dtype=float)\n        return {\n            'wav': wav,\n            'target': target,\n        }\n\n    def __len__(self):\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:30:03.893479Z","iopub.execute_input":"2022-04-30T08:30:03.893999Z","iopub.status.idle":"2022-04-30T08:30:03.902713Z","shell.execute_reply.started":"2022-04-30T08:30:03.893963Z","shell.execute_reply":"2022-04-30T08:30:03.901840Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### Model","metadata":{"execution":{"iopub.status.busy":"2022-04-21T09:17:01.036048Z","iopub.execute_input":"2022-04-21T09:17:01.036366Z","iopub.status.idle":"2022-04-21T09:17:01.05202Z","shell.execute_reply.started":"2022-04-21T09:17:01.036334Z","shell.execute_reply":"2022-04-21T09:17:01.050779Z"}}},{"cell_type":"code","source":"class Net(torch.nn.Module):\n    def __init__(self, backbone_path=None):\n        super().__init__()\n        self.audio2image = self._init_audio2image()\n        self.backbone = self._init_backbone()\n        self.load_backbone(backbone_path)\n        self.head = self._init_head(self.backbone.feature_info[-1]['num_chs'])      \n        self.loss = torch.nn.BCEWithLogitsLoss()\n        \n    def forward(self, wav_tensor, y=None):\n        spectrogram = self.audio2image(wav_tensor)\n        spectrogram = spectrogram.permute(0, 2, 1)\n        spectrogram = spectrogram[:, None, :, :]\n        x = self.backbone(spectrogram)\n        logits = self.head(x)\n        \n        if y is not None:\n            loss = self.loss(logits, y)\n        else:\n            loss = None\n\n        return {'loss': loss, 'logits': logits.sigmoid()}\n\n    \n    @staticmethod\n    def _init_audio2image():\n        mel = ta.transforms.MelSpectrogram(\n            sample_rate=32000,\n            n_fft=2048,\n            win_length=2048,\n            hop_length=512,\n            f_min=16,\n            f_max=16386,\n            pad=0,\n            n_mels=256,\n            power=2,\n            normalized=False,\n        )\n        db_scale = ta.transforms.AmplitudeToDB(top_db=80.0)\n        audio2image = torch.nn.Sequential(mel, db_scale)\n        return audio2image\n    \n    @staticmethod\n    def _init_backbone():\n        backbone = \"resnet18\"\n        pretrained = False\n        pretrained_weights = None\n        train = True\n        val = False\n        in_chans = 1\n\n        backbone = timm.create_model(\n            backbone,\n            pretrained=pretrained,\n            num_classes=0,\n            global_pool=\"\",\n            in_chans=in_chans,\n        )\n        return backbone\n    \n    @staticmethod\n    def _init_head(num_chs):\n        head = torch.nn.Sequential(\n            torch.nn.AdaptiveAvgPool2d(output_size=1),\n            torch.nn.Flatten(),\n            torch.nn.Linear(num_chs, len(all_species))\n        )\n        return head\n    \n    def load_backbone(self, weights_path=None):\n        if weights_path:\n            state_dict=torch.load(weights_path)\n            conv1_weight = state_dict['conv1.weight']\n            state_dict['conv1.weight'] = conv1_weight.sum(dim=1, keepdim=True)\n            state_dict.pop('fc.bias')\n            state_dict.pop('fc.weight')\n            self.backbone.load_state_dict(state_dict)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:30:04.525608Z","iopub.execute_input":"2022-04-30T08:30:04.525850Z","iopub.status.idle":"2022-04-30T08:30:04.541247Z","shell.execute_reply.started":"2022-04-30T08:30:04.525823Z","shell.execute_reply":"2022-04-30T08:30:04.540497Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### Train loop","metadata":{}},{"cell_type":"code","source":"with open('../input/timm-pretrained-resnet/index.json') as fin:\n    timm_index = json.load(fin)\nresnet_path = os.path.join('../input/timm-pretrained-resnet/resnet', timm_index['resnet']['resnet18'])","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:30:05.111131Z","iopub.execute_input":"2022-04-30T08:30:05.111398Z","iopub.status.idle":"2022-04-30T08:30:05.118620Z","shell.execute_reply.started":"2022-04-30T08:30:05.111369Z","shell.execute_reply":"2022-04-30T08:30:05.117866Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:30:05.490964Z","iopub.execute_input":"2022-04-30T08:30:05.491554Z","iopub.status.idle":"2022-04-30T08:30:05.496475Z","shell.execute_reply.started":"2022-04-30T08:30:05.491520Z","shell.execute_reply":"2022-04-30T08:30:05.495218Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"train_meta, val_meta = train_test_split(train_meta, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:30:05.904294Z","iopub.execute_input":"2022-04-30T08:30:05.904531Z","iopub.status.idle":"2022-04-30T08:30:05.919111Z","shell.execute_reply.started":"2022-04-30T08:30:05.904505Z","shell.execute_reply":"2022-04-30T08:30:05.918429Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model = Net(resnet_path)\ntrain_dataset = BirdDataset(train_meta)\ntrain_dataloader = DataLoader(\n    train_dataset,\n    batch_size=64,\n    shuffle=True,\n    num_workers=2,\n    pin_memory=False,\n    drop_last=True,\n)\n\nval_dataset = BirdDataset(val_meta)\nval_dataloader = DataLoader(\n    val_dataset,\n    batch_size=64,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=False,\n    drop_last=False,\n)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\noptimizer = torch.optim.Adam(model.parameters())","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:30:06.236389Z","iopub.execute_input":"2022-04-30T08:30:06.237142Z","iopub.status.idle":"2022-04-30T08:30:06.559796Z","shell.execute_reply.started":"2022-04-30T08:30:06.237102Z","shell.execute_reply":"2022-04-30T08:30:06.558955Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model, optimizer, dataloader, device):\n    tqdm_dataloader = tqdm(dataloader)\n    loss_list = []\n    model.train()\n    for batch in tqdm_dataloader:\n        loss = model(batch['wav'].to(device), batch['target'].to(device))['loss']\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        loss_list.append(loss.item())\n    return loss_list\n    \n\ndef val_epoch(model, dataloader, device):\n    tqdm_dataloader = tqdm(dataloader)\n    loss_list = []\n    model.eval()\n    y_true = None\n    y_pred = None\n    \n    for batch in tqdm_dataloader:\n        logits = model(batch['wav'].to(device))['logits']\n        batch_target = batch['target'].cpu().numpy()\n        batch_pred = logits.cpu().numpy()\n        \n        if y_true is None:\n            y_true = batch_target\n            y_pred = batch_pred\n        else:\n            y_true = np.vstack((y_true, batch_target))\n            y_pred = np.vstack((y_pred, batch_pred))\n        \n    return y_true, y_pred\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:30:07.148815Z","iopub.execute_input":"2022-04-30T08:30:07.149554Z","iopub.status.idle":"2022-04-30T08:30:07.162146Z","shell.execute_reply.started":"2022-04-30T08:30:07.149517Z","shell.execute_reply":"2022-04-30T08:30:07.159639Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def score_pred(y_true, y_pred, trsh, score_conf):\n    score_dict = {}\n    for score_f, score_kwargs, score_prefix in score_conf:\n        score_dict.update({\n            f'{score_prefix}-{t}': score_f(y_true, y_pred > t, **score_kwargs)\n            for t in trsh\n        })\n    return score_dict\n\n\nimport sklearn.metrics\n\ndef comp_metric(y_true, y_pred, epsilon=1e-9):\n    \"\"\" Function to calculate competition metric in an sklearn like fashion\n\n    Args:\n        y_true{array-like, sparse matrix} of shape (n_samples, n_outputs)\n            - Ground truth (correct) target values.\n        y_pred{array-like, sparse matrix} of shape (n_samples, n_outputs)\n            - Estimated targets as returned by a classifier.\n    Returns:\n        The single calculated score representative of this competitions evaluation\n    \"\"\"\n\n    # Get representative confusion matrices for each label\n    mlbl_cms = sklearn.metrics.multilabel_confusion_matrix(y_true, y_pred)\n\n    # Get two scores (TP and TN SCORES)\n    tp_scores = np.array([\n        mlbl_cm[1, 1]/(epsilon+mlbl_cm[:, 1].sum()) \\\n        for mlbl_cm in mlbl_cms\n        ])\n    tn_scores = np.array([\n        mlbl_cm[0, 0]/(epsilon+mlbl_cm[:, 0].sum()) \\\n        for mlbl_cm in mlbl_cms\n        ])\n\n    # Get average\n    tp_mean = tp_scores.mean()\n    tn_mean = tn_scores.mean()\n\n    return round((tp_mean+tn_mean)/2, 8)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:32:36.978934Z","iopub.execute_input":"2022-04-30T08:32:36.979311Z","iopub.status.idle":"2022-04-30T08:32:36.988141Z","shell.execute_reply.started":"2022-04-30T08:32:36.979176Z","shell.execute_reply":"2022-04-30T08:32:36.987399Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"score_conf = [\n    [f1_score, {'average': 'macro'}, 'f1'],\n    [comp_metric, {}, 'comp_metric']\n]","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:33:42.700371Z","iopub.execute_input":"2022-04-30T08:33:42.701094Z","iopub.status.idle":"2022-04-30T08:33:42.705316Z","shell.execute_reply.started":"2022-04-30T08:33:42.701042Z","shell.execute_reply":"2022-04-30T08:33:42.704414Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"\nepochs = 1\nmodel.to(device)\nfor e in range(epochs):\n    epoch_loss = train_epoch(model, optimizer, train_dataloader, device)\n    print(f'{e} train loss:', f'{np.mean(epoch_loss):.3f}', sep='\\t')\n    with torch.no_grad():\n        y_true, y_pred = val_epoch(model, val_dataloader, device)\n    score_dict = score_pred(\n        y_true, y_pred,\n        score_conf=score_conf,\n        trsh={0.3, 0.4, 0.5, 0.6}\n    )\n    torch.save(model, f'{e}_model.pt')\n    print(f'{e} val scores:')\n    print(*[\n        f'\\t{case}: {case_score}' \n        for case, case_score in score_dict.items()\n    ], sep='\\n')\n","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:33:59.667654Z","iopub.execute_input":"2022-04-30T08:33:59.667933Z","iopub.status.idle":"2022-04-30T08:35:57.682448Z","shell.execute_reply.started":"2022-04-30T08:33:59.667902Z","shell.execute_reply":"2022-04-30T08:35:57.681456Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"100%|██████████| 47/47 [01:57<00:00,  2.50s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/1519092015.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mscore_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrsh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{e}_model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{e} val scores:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: score_pred() missing 1 required positional argument: 'score_conf'"],"ename":"TypeError","evalue":"score_pred() missing 1 required positional argument: 'score_conf'","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-04-30T08:39:12.504078Z","iopub.execute_input":"2022-04-30T08:39:12.504865Z","iopub.status.idle":"2022-04-30T08:39:12.917099Z","shell.execute_reply.started":"2022-04-30T08:39:12.504827Z","shell.execute_reply":"2022-04-30T08:39:12.916324Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Submit","metadata":{}},{"cell_type":"code","source":"with open(os.path.join(data_root, 'scored_birds.json')) as fin:\n    test_birds = json.load(fin)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T21:09:02.513487Z","iopub.execute_input":"2022-04-26T21:09:02.513766Z","iopub.status.idle":"2022-04-26T21:09:02.543443Z","shell.execute_reply.started":"2022-04-26T21:09:02.513736Z","shell.execute_reply":"2022-04-26T21:09:02.54281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, test_folder):\n        super().__init__()\n        self.test_folder = test_folder\n        self.fnames = [f for f in os.listdir(test_folder) if f.endswith('.ogg')]\n        \n    def __len__(self):\n        return len(self.fnames)\n    \n    def __getitem__(self, idx):\n        fpath = os.path.join(self.test_folder, self.fnames[idx])\n        wav, sr = load_wav(fpath, 0, None)\n        wav = torch.tensor(wav)\n        assert (13 * 5 * sr) > len(wav) \n        wav = wav[:len(wav) // 12 * 12].reshape((12, len(wav) // 12))\n        return wav","metadata":{"execution":{"iopub.status.busy":"2022-04-26T21:09:04.32293Z","iopub.execute_input":"2022-04-26T21:09:04.323721Z","iopub.status.idle":"2022-04-26T21:09:04.336316Z","shell.execute_reply.started":"2022-04-26T21:09:04.323676Z","shell.execute_reply":"2022-04-26T21:09:04.33538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(os.path.join(data_root, 'test_soundscapes'))\ntest_dataloader = DataLoader(\n    test_dataset,\n    batch_size=1,\n    shuffle=False,\n    num_workers=2,\n    drop_last=False,   \n)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T21:09:06.034536Z","iopub.execute_input":"2022-04-26T21:09:06.035122Z","iopub.status.idle":"2022-04-26T21:09:06.043876Z","shell.execute_reply.started":"2022-04-26T21:09:06.03508Z","shell.execute_reply":"2022-04-26T21:09:06.04304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_list = []\ntreshold = 0.1\nmodel.eval()\nwith torch.no_grad():\n    for i, batch in tqdm(enumerate(test_dataloader)):\n        batch_size, part_count, part_size = batch.shape\n        batch = batch.reshape(batch_size * part_count, part_size)\n        pred = model(batch.to(device))['logits']\n        pred = pred.cpu().numpy()\n        pred = pred > treshold\n        \n        for j, chunk_pred in enumerate(pred):\n            inbatch_number = j // part_count\n            chunk_number = j % part_count + 1\n            f_idx = i * batch_size + inbatch_number\n            fname = test_dataset.fnames[f_idx]\n            prefix = fname.split('.')[0]\n            sufix = f'{5 * chunk_number}'\n            \n            pred_list.extend([{\n                'row_id': '_'.join([prefix, b, sufix]),\n                'target': chunk_pred[species2id[b]]\n            } for b in test_birds])\npred_pd = pd.DataFrame(pred_list)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T21:09:22.267572Z","iopub.execute_input":"2022-04-26T21:09:22.267846Z","iopub.status.idle":"2022-04-26T21:09:22.504385Z","shell.execute_reply.started":"2022-04-26T21:09:22.267799Z","shell.execute_reply":"2022-04-26T21:09:22.503538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_pd.to_csv(\"submission.csv\", index=False)\npred_pd","metadata":{"execution":{"iopub.status.busy":"2022-04-26T21:09:23.724651Z","iopub.execute_input":"2022-04-26T21:09:23.725436Z","iopub.status.idle":"2022-04-26T21:09:23.740815Z","shell.execute_reply.started":"2022-04-26T21:09:23.725397Z","shell.execute_reply":"2022-04-26T21:09:23.740159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def chunk_wav(wav, sr, window_size):\n#     chunks_count = len(wav) // (window_size * sr)\n#     chunk_size = window_size * sr\n#     chunks = []\n#     for chunk_idx in range(chunks_count):\n#         left = chunk_idx * sr\n#         right = min(left + chunk_size, len(wav))\n#         chunks.append(wav[left:right])\n#     chunk_tensor = torch.tensor(chunks)\n#     return chunk_tensor\n\n# file_list = os.listdir(os.path.join(data_root, 'test_soundscapes'))\n\n# # This is where we will store our results\n# treshold = 0.5\n# pred = {'row_id': [], 'target': []}\n# model.eval()\n# with torch.no_grad():\n#     # Process audio files and make predictions\n#     for fname in file_list:\n#         prefix = fname.split('.')[0]\n#         # Complete file path\n#         fpath = os.path.join(data_root, 'test_soundscapes', fname)\n#         wav, sr = load_wav(fpath, 0, None)\n#         chunk_tensor = chunk_wav(wav, sr, window_size=5)\n\n#         # Open file with librosa and split signal into 5-second chunks\n#         # sig, rate = librosa.load(path)\n#         # ...\n\n#         # Let's assume we have a list of 12 audio chunks (1min / 5s == 12 segments)\n#         chunk_score = model(chunk_tensor.to(device))['logits'].cpu().numpy()\n\n#         # Make prediction for each chunk\n#         # Each scored bird gets a random value in our case\n#         # since we don't actually have a model\n#         for i, all_score in enumerate(chunk_score):        \n#             chunk_end_time = (i + 1) * 5\n#             for bird in test_birds:\n\n#                 # This is our random prediction score for this bird\n#                 bird_score = all_score[species2id[bird]]\n\n#                 # Assemble the row_id which we need to do for each scored bird\n#                 row_id = prefix + '_' + bird + '_' + str(chunk_end_time)\n\n#                 # Put the result into our prediction dict and\n#                 # apply a \"confidence\" threshold of 0.5\n#                 pred['row_id'].append(row_id)\n#                 pred['target'].append(True if bird_score > treshold else False)\n\n\n# # Make a new data frame and look at some results        \n# results = pd.DataFrame(pred, columns = ['row_id', 'target'])\n\n# # Quick sanity check\n# print(results.head()) \n    \n# # Convert our results to csv\n# results.to_csv(\"submission.csv\", index=False)    ","metadata":{"execution":{"iopub.status.busy":"2022-04-23T15:00:22.026005Z","iopub.execute_input":"2022-04-23T15:00:22.026332Z","iopub.status.idle":"2022-04-23T15:00:22.45859Z","shell.execute_reply.started":"2022-04-23T15:00:22.026291Z","shell.execute_reply":"2022-04-23T15:00:22.457601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_fnames = [f for f in os.listdir(f'{data_root}/test_soundscapes') if f.endswith('.ogg')]\n# test_pd = []\n# for fname in test_fnames:\n#     fpath = os.path.join(data_root, 'test_soundscapes', fname)\n#     wav, sr = librosa.load(fpath, sr=None)\n#     prefix = fname.split('.')[0]\n#     window_size = 5 * sr\n#     for i, chunk in enumerate(wav[::window_size]):\n#         end_time = (i + 1) * 5\n#         samples = [{\n#             'row_id': f'{prefix}_{b}_{end_time}',\n#             'file_id': fname,\n#             'bird': b,\n#             'end_time': end_time\n#         } for b in test_birds]\n#         test_pd.extend(samples)\n        \n# test_pd = pd.DataFrame(test_pd)\n# test_pd","metadata":{},"execution_count":null,"outputs":[]}]}