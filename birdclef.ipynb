{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c5b5f80",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-10T12:07:08.502812Z",
     "iopub.status.busy": "2022-05-10T12:07:08.501284Z",
     "iopub.status.idle": "2022-05-10T12:07:14.180584Z",
     "shell.execute_reply": "2022-05-10T12:07:14.181100Z",
     "shell.execute_reply.started": "2022-05-10T10:49:18.177588Z"
    },
    "papermill": {
     "duration": 5.709201,
     "end_time": "2022-05-10T12:07:14.181354",
     "exception": false,
     "start_time": "2022-05-10T12:07:08.472153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import sys\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import random\n",
    "\n",
    "import librosa\n",
    "\n",
    "import torch\n",
    "import torchaudio as ta\n",
    "import timm\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "593eea26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T12:07:14.234178Z",
     "iopub.status.busy": "2022-05-10T12:07:14.233387Z",
     "iopub.status.idle": "2022-05-10T12:07:14.541078Z",
     "shell.execute_reply": "2022-05-10T12:07:14.540589Z",
     "shell.execute_reply.started": "2022-05-10T10:49:23.613220Z"
    },
    "papermill": {
     "duration": 0.334409,
     "end_time": "2022-05-10T12:07:14.541205",
     "exception": false,
     "start_time": "2022-05-10T12:07:14.206796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_root = '/kaggle/input/birdclef-2022'\n",
    "train_meta = pd.read_csv('../input/birdclef-data-with-wav-durations/train_metadata_extended.csv')\n",
    "ebird_taxonomy = pd.read_csv(os.path.join(data_root, 'eBird_Taxonomy_v2021.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9d75cd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T12:07:14.611656Z",
     "iopub.status.busy": "2022-05-10T12:07:14.606548Z",
     "iopub.status.idle": "2022-05-10T12:07:14.666656Z",
     "shell.execute_reply": "2022-05-10T12:07:14.666226Z",
     "shell.execute_reply.started": "2022-05-10T10:49:23.937900Z"
    },
    "papermill": {
     "duration": 0.101668,
     "end_time": "2022-05-10T12:07:14.666771",
     "exception": false,
     "start_time": "2022-05-10T12:07:14.565103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_meta.loc[:, 'secondary_labels'] = train_meta.secondary_labels.apply(eval)\n",
    "train_meta['target_raw'] = train_meta.secondary_labels + train_meta.primary_label.apply(lambda x: [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a29270d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T12:07:15.128001Z",
     "iopub.status.busy": "2022-05-10T12:07:15.117904Z",
     "iopub.status.idle": "2022-05-10T12:07:15.469671Z",
     "shell.execute_reply": "2022-05-10T12:07:15.469185Z",
     "shell.execute_reply.started": "2022-05-10T10:49:24.017905Z"
    },
    "papermill": {
     "duration": 0.779105,
     "end_time": "2022-05-10T12:07:15.469810",
     "exception": false,
     "start_time": "2022-05-10T12:07:14.690705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_species = sorted(set(train_meta.target_raw.sum()))\n",
    "species2id = {s: i for i, s in enumerate(all_species)}\n",
    "id2species = {i: s for i, s in enumerate(all_species)}\n",
    "\n",
    "train_meta['target'] = train_meta.target_raw.apply(lambda species: [int(s in species) for s in all_species])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e4fd315",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T12:07:15.522054Z",
     "iopub.status.busy": "2022-05-10T12:07:15.521387Z",
     "iopub.status.idle": "2022-05-10T12:07:15.524200Z",
     "shell.execute_reply": "2022-05-10T12:07:15.524668Z",
     "shell.execute_reply.started": "2022-05-10T10:49:25.110692Z"
    },
    "papermill": {
     "duration": 0.031282,
     "end_time": "2022-05-10T12:07:15.524827",
     "exception": false,
     "start_time": "2022-05-10T12:07:15.493545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_wav(fname, offset, duration):\n",
    "#     fname = 'afrsil1/XC125458.ogg'\n",
    "    fpath = os.path.join(data_root, 'train_audio', fname)\n",
    "    wav, sr = librosa.load(fpath, sr=None, duration=duration, offset=offset)\n",
    "    assert sr <= 32000, sr\n",
    "    return wav, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b873729",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T12:07:15.575599Z",
     "iopub.status.busy": "2022-05-10T12:07:15.574852Z",
     "iopub.status.idle": "2022-05-10T12:07:15.576866Z",
     "shell.execute_reply": "2022-05-10T12:07:15.577231Z",
     "shell.execute_reply.started": "2022-05-10T10:49:25.123199Z"
    },
    "papermill": {
     "duration": 0.028751,
     "end_time": "2022-05-10T12:07:15.577349",
     "exception": false,
     "start_time": "2022-05-10T12:07:15.548598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# duration = 30\n",
    "# sample_rate = 32000\n",
    "\n",
    "# wav, sr = load_wav('afrsil1/XC125458.ogg', 5, duration)\n",
    "# to_pad = duration * sample_rate - wav.shape[0]\n",
    "\n",
    "# if to_pad > 0:\n",
    "#     wav = np.pad(wav, (0, to_pad))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7d0295",
   "metadata": {
    "papermill": {
     "duration": 0.023506,
     "end_time": "2022-05-10T12:07:15.625757",
     "exception": false,
     "start_time": "2022-05-10T12:07:15.602251",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dcc3de2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T12:07:15.676707Z",
     "iopub.status.busy": "2022-05-10T12:07:15.676183Z",
     "iopub.status.idle": "2022-05-10T12:07:15.679662Z",
     "shell.execute_reply": "2022-05-10T12:07:15.679252Z",
     "shell.execute_reply.started": "2022-05-10T10:49:25.129464Z"
    },
    "papermill": {
     "duration": 0.030685,
     "end_time": "2022-05-10T12:07:15.679767",
     "exception": false,
     "start_time": "2022-05-10T12:07:15.649082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_SIZE = 5 \n",
    "CONFIG = {\n",
    "    'crop_len': 30,\n",
    "    'sample_rate': 32000,    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4bfe233",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T12:07:15.735933Z",
     "iopub.status.busy": "2022-05-10T12:07:15.735135Z",
     "iopub.status.idle": "2022-05-10T12:07:15.737144Z",
     "shell.execute_reply": "2022-05-10T12:07:15.737588Z",
     "shell.execute_reply.started": "2022-05-10T10:49:25.139744Z"
    },
    "papermill": {
     "duration": 0.034627,
     "end_time": "2022-05-10T12:07:15.737723",
     "exception": false,
     "start_time": "2022-05-10T12:07:15.703096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        duration = CONFIG['crop_len']\n",
    "        sample_rate = CONFIG['sample_rate']\n",
    "        \n",
    "        fname = self.df.iloc[idx]['filename']\n",
    "        wav_len = train_meta.iloc[0]['duration']\n",
    "        \n",
    "        max_offset = max(0, wav_len - duration)\n",
    "        random_offset = random.randint(0, max_offset)\n",
    "                \n",
    "        wav, sr = load_wav(fname, random_offset, duration)\n",
    "        to_pad = duration * sample_rate - wav.shape[0]\n",
    "        if to_pad > 0:\n",
    "            wav = np.pad(wav, (0, to_pad))\n",
    "            \n",
    "        target = self.df.iloc[idx]['target']\n",
    "        \n",
    "        # TODO: add weighting\n",
    "            \n",
    "        wav = torch.tensor(wav)\n",
    "        target = torch.tensor(target, dtype=float)\n",
    "        return {\n",
    "            'wav': wav,\n",
    "            'target': target,\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce00298",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T09:17:01.036366Z",
     "iopub.status.busy": "2022-04-21T09:17:01.036048Z",
     "iopub.status.idle": "2022-04-21T09:17:01.05202Z",
     "shell.execute_reply": "2022-04-21T09:17:01.050779Z",
     "shell.execute_reply.started": "2022-04-21T09:17:01.036334Z"
    },
    "papermill": {
     "duration": 0.023554,
     "end_time": "2022-05-10T12:07:15.784917",
     "exception": false,
     "start_time": "2022-05-10T12:07:15.761363",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e3e0e8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T12:07:15.844937Z",
     "iopub.status.busy": "2022-05-10T12:07:15.844077Z",
     "iopub.status.idle": "2022-05-10T12:07:15.846698Z",
     "shell.execute_reply": "2022-05-10T12:07:15.846282Z",
     "shell.execute_reply.started": "2022-05-10T10:56:37.034455Z"
    },
    "papermill": {
     "duration": 0.038385,
     "end_time": "2022-05-10T12:07:15.846803",
     "exception": false,
     "start_time": "2022-05-10T12:07:15.808418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.distributions import Beta\n",
    "\n",
    "\n",
    "class Mixup(torch.nn.Module):\n",
    "    def __init__(self, mix_beta=1):\n",
    "\n",
    "        super(Mixup, self).__init__()\n",
    "        self.beta_distribution = Beta(mix_beta, mix_beta)\n",
    "\n",
    "    def forward(self, X, Y, weight=None):\n",
    "\n",
    "        bs = X.shape[0]\n",
    "        n_dims = len(X.shape)\n",
    "        perm = torch.randperm(bs)\n",
    "        coeffs = self.beta_distribution.rsample(torch.Size((bs,))).to(X.device)\n",
    "\n",
    "        if n_dims == 2:\n",
    "            X = coeffs.view(-1, 1) * X + (1 - coeffs.view(-1, 1)) * X[perm]\n",
    "        elif n_dims == 3:\n",
    "            X = coeffs.view(-1, 1, 1) * X + (1 - coeffs.view(-1, 1, 1)) * X[perm]\n",
    "        else:\n",
    "            X = coeffs.view(-1, 1, 1, 1) * X + (1 - coeffs.view(-1, 1, 1, 1)) * X[perm]\n",
    "\n",
    "        Y = coeffs.view(-1, 1) * Y + (1 - coeffs.view(-1, 1)) * Y[perm]\n",
    "\n",
    "        if weight is None:\n",
    "            return X, Y\n",
    "        else:\n",
    "            weight = coeffs.view(-1) * weight + (1 - coeffs.view(-1)) * weight[perm]\n",
    "            return X, Y, weight\n",
    "        \n",
    "        \n",
    "class Attention(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, activation='linear'):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "        self.attn = torch.nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "        self.cla = torch.nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: b, c, t\n",
    "        attn = torch.softmax(torch.tanh(self.attn(x)), dim=-1) # b, c, t\n",
    "        x = self.cla(x) # b, c, t\n",
    "        x = torch.sum(x * attn, dim=-1) #b, c\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96aded28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T12:07:15.914698Z",
     "iopub.status.busy": "2022-05-10T12:07:15.913122Z",
     "iopub.status.idle": "2022-05-10T12:07:15.915261Z",
     "shell.execute_reply": "2022-05-10T12:07:15.915673Z",
     "shell.execute_reply.started": "2022-05-10T10:56:40.467388Z"
    },
    "papermill": {
     "duration": 0.045653,
     "end_time": "2022-05-10T12:07:15.915789",
     "exception": false,
     "start_time": "2022-05-10T12:07:15.870136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, backbone_path=None):\n",
    "        super().__init__()\n",
    "        self.audio2image = self._init_audio2image()\n",
    "        self.backbone = self._init_backbone()\n",
    "        self.load_backbone(backbone_path)\n",
    "        self.head = self._init_head(self.backbone.feature_info[-1]['num_chs'])      \n",
    "        self.loss = torch.nn.BCEWithLogitsLoss()\n",
    "        self.mixup = Mixup()\n",
    "        \n",
    "    def forward(self, wav_tensor, y=None):\n",
    "        # wav_tensor: b, t\n",
    "        if self.training:\n",
    "            wav_tensor = self.batch_crop(wav_tensor) # b, t\n",
    "            \n",
    "        spectrogram = self.audio2image(wav_tensor) # b, m, t\n",
    "        spectrogram = spectrogram.permute(0, 2, 1) # b, t, m\n",
    "        spectrogram = spectrogram[:, None, :, :] # b, c, t, m\n",
    "        \n",
    "        if self.training:\n",
    "            spectrogram = spectrogram.permute(0, 2, 1, 3) # b, t, c, m\n",
    "            spectrogram = self.batch_uncrop(spectrogram)\n",
    "            \n",
    "            spectrogram, y = self.mixup(spectrogram, y)\n",
    "            \n",
    "            spectrogram = self.batch_crop(spectrogram)\n",
    "            spectrogram = spectrogram.permute(0, 2, 1, 3) # b, c, t, m\n",
    "                \n",
    "        x = self.backbone(spectrogram) # b, c, t, m\n",
    "        if self.training:\n",
    "            x = x.permute(0, 2, 1, 3) # b, t, c, m\n",
    "            x = self.batch_uncrop(x)\n",
    "            x = x.permute(0, 2, 1, 3) # b, c, t, m\n",
    "        \n",
    "        # average mel axis\n",
    "        x = torch.mean(x, axis=-1)\n",
    "                \n",
    "        logits = self.head(x) # b, n_out\n",
    "        \n",
    "        if y is not None:\n",
    "            loss = self.loss(logits, y)\n",
    "        else:\n",
    "            loss = None\n",
    "\n",
    "        return {'loss': loss, 'logits': logits.sigmoid()}\n",
    "    \n",
    "    def batch_crop(self, tensor):\n",
    "        factor = int(CONFIG['crop_len'] // TEST_SIZE)\n",
    "        b, t = tensor.shape[:2]\n",
    "        tensor = tensor.reshape(b * factor, t // factor, *tensor.shape[2:])\n",
    "        return tensor\n",
    "    \n",
    "    def batch_uncrop(self, tensor):\n",
    "        factor = int(CONFIG['crop_len'] // TEST_SIZE)\n",
    "        b, t = tensor.shape[:2]\n",
    "        tensor = tensor.reshape(b // factor, t * factor, *tensor.shape[2:])\n",
    "        return tensor\n",
    "    \n",
    "    @staticmethod\n",
    "    def _init_audio2image():\n",
    "        mel = ta.transforms.MelSpectrogram(\n",
    "            sample_rate=32000,\n",
    "            n_fft=2048,\n",
    "            win_length=2048,\n",
    "            hop_length=512,\n",
    "            f_min=16,\n",
    "            f_max=16386,\n",
    "            pad=0,\n",
    "            n_mels=256,\n",
    "            power=2,\n",
    "            normalized=False,\n",
    "        )\n",
    "        db_scale = ta.transforms.AmplitudeToDB(top_db=80.0)\n",
    "        audio2image = torch.nn.Sequential(mel, db_scale)\n",
    "        return audio2image\n",
    "    \n",
    "    @staticmethod\n",
    "    def _init_backbone():\n",
    "        backbone = \"resnet18\"\n",
    "        pretrained = False\n",
    "        pretrained_weights = None\n",
    "        train = True\n",
    "        val = False\n",
    "        in_chans = 1\n",
    "\n",
    "        backbone = timm.create_model(\n",
    "            backbone,\n",
    "            pretrained=pretrained,\n",
    "            num_classes=0,\n",
    "            global_pool=\"\",\n",
    "            in_chans=in_chans,\n",
    "        )\n",
    "        return backbone\n",
    "    \n",
    "    @staticmethod\n",
    "    def _init_head(num_chs):\n",
    "        head = Attention(num_chs, len(all_species), activation='linear')\n",
    "        return head\n",
    "    \n",
    "    def load_backbone(self, weights_path=None):\n",
    "        if weights_path:\n",
    "            state_dict=torch.load(weights_path)\n",
    "            conv1_weight = state_dict['conv1.weight']\n",
    "            state_dict['conv1.weight'] = conv1_weight.sum(dim=1, keepdim=True)\n",
    "            state_dict.pop('fc.bias')\n",
    "            state_dict.pop('fc.weight')\n",
    "            self.backbone.load_state_dict(state_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca37cab9",
   "metadata": {
    "papermill": {
     "duration": 0.023165,
     "end_time": "2022-05-10T12:07:15.962291",
     "exception": false,
     "start_time": "2022-05-10T12:07:15.939126",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb84ee36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T12:07:16.013148Z",
     "iopub.status.busy": "2022-05-10T12:07:16.012659Z",
     "iopub.status.idle": "2022-05-10T12:07:16.020960Z",
     "shell.execute_reply": "2022-05-10T12:07:16.020349Z",
     "shell.execute_reply.started": "2022-05-10T10:56:43.525840Z"
    },
    "papermill": {
     "duration": 0.035178,
     "end_time": "2022-05-10T12:07:16.021082",
     "exception": false,
     "start_time": "2022-05-10T12:07:15.985904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('../input/timm-pretrained-resnet/index.json') as fin:\n",
    "    timm_index = json.load(fin)\n",
    "resnet_path = os.path.join('../input/timm-pretrained-resnet/resnet', timm_index['resnet']['resnet18'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "906a7de1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T12:07:16.073369Z",
     "iopub.status.busy": "2022-05-10T12:07:16.072639Z",
     "iopub.status.idle": "2022-05-10T12:07:16.075127Z",
     "shell.execute_reply": "2022-05-10T12:07:16.074698Z",
     "shell.execute_reply.started": "2022-05-10T10:56:44.556699Z"
    },
    "papermill": {
     "duration": 0.029402,
     "end_time": "2022-05-10T12:07:16.075225",
     "exception": false,
     "start_time": "2022-05-10T12:07:16.045823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcdf147f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T12:07:16.128211Z",
     "iopub.status.busy": "2022-05-10T12:07:16.127433Z",
     "iopub.status.idle": "2022-05-10T12:07:16.138999Z",
     "shell.execute_reply": "2022-05-10T12:07:16.139362Z",
     "shell.execute_reply.started": "2022-05-10T10:56:46.686476Z"
    },
    "papermill": {
     "duration": 0.040884,
     "end_time": "2022-05-10T12:07:16.139482",
     "exception": false,
     "start_time": "2022-05-10T12:07:16.098598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_meta, val_meta = train_test_split(train_meta, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cb6e749",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T12:07:16.193359Z",
     "iopub.status.busy": "2022-05-10T12:07:16.192813Z",
     "iopub.status.idle": "2022-05-10T12:07:20.207839Z",
     "shell.execute_reply": "2022-05-10T12:07:20.207327Z",
     "shell.execute_reply.started": "2022-05-10T10:56:49.053081Z"
    },
    "papermill": {
     "duration": 4.045078,
     "end_time": "2022-05-10T12:07:20.207977",
     "exception": false,
     "start_time": "2022-05-10T12:07:16.162899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Net(resnet_path)\n",
    "train_dataset = BirdDataset(train_meta)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=False,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_dataset = BirdDataset(val_meta)\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=False,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eea7b532",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T12:07:20.263850Z",
     "iopub.status.busy": "2022-05-10T12:07:20.258371Z",
     "iopub.status.idle": "2022-05-10T12:07:20.266108Z",
     "shell.execute_reply": "2022-05-10T12:07:20.265591Z",
     "shell.execute_reply.started": "2022-05-10T10:56:53.574155Z"
    },
    "papermill": {
     "duration": 0.034533,
     "end_time": "2022-05-10T12:07:20.266212",
     "exception": false,
     "start_time": "2022-05-10T12:07:20.231679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, dataloader, device):\n",
    "    tqdm_dataloader = tqdm(dataloader)\n",
    "    loss_list = []\n",
    "    model.train()\n",
    "    for batch in tqdm_dataloader:\n",
    "        loss = model(batch['wav'].to(device), batch['target'].to(device))['loss']\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_list.append(loss.item())\n",
    "    return loss_list\n",
    "    \n",
    "\n",
    "def val_epoch(model, dataloader, device):\n",
    "    tqdm_dataloader = tqdm(dataloader)\n",
    "    loss_list = []\n",
    "    model.eval()\n",
    "    y_true = None\n",
    "    y_pred = None\n",
    "    \n",
    "    for batch in tqdm_dataloader:\n",
    "        logits = model(batch['wav'].to(device))['logits']\n",
    "        batch_target = batch['target'].cpu().numpy()\n",
    "        batch_pred = logits.cpu().numpy()\n",
    "        \n",
    "        if y_true is None:\n",
    "            y_true = batch_target\n",
    "            y_pred = batch_pred\n",
    "        else:\n",
    "            y_true = np.vstack((y_true, batch_target))\n",
    "            y_pred = np.vstack((y_pred, batch_pred))\n",
    "        \n",
    "    return y_true, y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa1ba28c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T12:07:20.323967Z",
     "iopub.status.busy": "2022-05-10T12:07:20.323265Z",
     "iopub.status.idle": "2022-05-10T12:07:20.325339Z",
     "shell.execute_reply": "2022-05-10T12:07:20.325733Z",
     "shell.execute_reply.started": "2022-05-10T10:56:53.593679Z"
    },
    "papermill": {
     "duration": 0.036295,
     "end_time": "2022-05-10T12:07:20.325865",
     "exception": false,
     "start_time": "2022-05-10T12:07:20.289570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score_pred(y_true, y_pred, trsh, score_conf):\n",
    "    score_dict = {}\n",
    "    for score_f, score_kwargs, score_prefix in score_conf:\n",
    "        score_dict.update({\n",
    "            f'{score_prefix}-{t}': score_f(y_true, y_pred > t, **score_kwargs)\n",
    "            for t in trsh\n",
    "        })\n",
    "    return score_dict\n",
    "\n",
    "\n",
    "import sklearn.metrics\n",
    "\n",
    "def comp_metric(y_true, y_pred, epsilon=1e-9):\n",
    "    \"\"\" Function to calculate competition metric in an sklearn like fashion\n",
    "\n",
    "    Args:\n",
    "        y_true{array-like, sparse matrix} of shape (n_samples, n_outputs)\n",
    "            - Ground truth (correct) target values.\n",
    "        y_pred{array-like, sparse matrix} of shape (n_samples, n_outputs)\n",
    "            - Estimated targets as returned by a classifier.\n",
    "    Returns:\n",
    "        The single calculated score representative of this competitions evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    # Get representative confusion matrices for each label\n",
    "    mlbl_cms = sklearn.metrics.multilabel_confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Get two scores (TP and TN SCORES)\n",
    "    tp_scores = np.array([\n",
    "        mlbl_cm[1, 1]/(epsilon+mlbl_cm[:, 1].sum()) \\\n",
    "        for mlbl_cm in mlbl_cms\n",
    "        ])\n",
    "    tn_scores = np.array([\n",
    "        mlbl_cm[0, 0]/(epsilon+mlbl_cm[:, 0].sum()) \\\n",
    "        for mlbl_cm in mlbl_cms\n",
    "        ])\n",
    "\n",
    "    # Get average\n",
    "    tp_mean = tp_scores.mean()\n",
    "    tn_mean = tn_scores.mean()\n",
    "\n",
    "    return round((tp_mean+tn_mean)/2, 8)\n",
    "\n",
    "\n",
    "def balanced_accuracy(pred, target, eps=1e-6):\n",
    "    tp = (pred * target).sum(axis=-1)\n",
    "    fn = ((1 - pred) * target).sum(axis=-1)\n",
    "    fp = (pred * (1 - target)).sum(axis=-1)\n",
    "    tn = ((1 - pred) * (1 - target)).sum(axis=-1)\n",
    "    tpr = tp / (tp + fn + eps)\n",
    "    tnr = tn / (tn + fp + eps)\n",
    "    return (0.5 * (tpr + tnr)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38e4a8e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T12:07:20.377094Z",
     "iopub.status.busy": "2022-05-10T12:07:20.376345Z",
     "iopub.status.idle": "2022-05-10T12:07:20.378668Z",
     "shell.execute_reply": "2022-05-10T12:07:20.378221Z",
     "shell.execute_reply.started": "2022-05-10T10:56:53.616072Z"
    },
    "papermill": {
     "duration": 0.02971,
     "end_time": "2022-05-10T12:07:20.378772",
     "exception": false,
     "start_time": "2022-05-10T12:07:20.349062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_conf = [\n",
    "    [f1_score, {'average': 'macro'}, 'f1'],\n",
    "    [comp_metric, {}, 'comp_metric'],\n",
    "    [balanced_accuracy, {}, 'balanced_accuracy']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9eb3b79c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T12:07:20.432314Z",
     "iopub.status.busy": "2022-05-10T12:07:20.431538Z",
     "iopub.status.idle": "2022-05-10T13:41:12.251673Z",
     "shell.execute_reply": "2022-05-10T13:41:12.251187Z"
    },
    "papermill": {
     "duration": 5631.849479,
     "end_time": "2022-05-10T13:41:12.251810",
     "exception": false,
     "start_time": "2022-05-10T12:07:20.402331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [08:06<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train loss:\t0.048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:53<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 val scores:\n",
      "\tf1-0.1: 0.02785076176624267\n",
      "\tf1-0.4: 0.01838242431988643\n",
      "\tf1-0.3: 0.01993751517692378\n",
      "\tf1-0.2: 0.022816580528668206\n",
      "\tcomp_metric-0.1: 0.51116656\n",
      "\tcomp_metric-0.4: 0.50820996\n",
      "\tcomp_metric-0.3: 0.50809563\n",
      "\tcomp_metric-0.2: 0.51283226\n",
      "\tbalanced_accuracy-0.1: 0.550834179757332\n",
      "\tbalanced_accuracy-0.4: 0.5304477856908878\n",
      "\tbalanced_accuracy-0.3: 0.5350658075987573\n",
      "\tbalanced_accuracy-0.2: 0.5400039616246725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [07:29<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 train loss:\t0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:43<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 val scores:\n",
      "\tf1-0.1: 0.10440764928801999\n",
      "\tf1-0.4: 0.06976993519299571\n",
      "\tf1-0.3: 0.079297963298281\n",
      "\tf1-0.2: 0.0906366698490779\n",
      "\tcomp_metric-0.1: 0.55764078\n",
      "\tcomp_metric-0.4: 0.56546624\n",
      "\tcomp_metric-0.3: 0.56333231\n",
      "\tcomp_metric-0.2: 0.55709439\n",
      "\tbalanced_accuracy-0.1: 0.630207631422816\n",
      "\tbalanced_accuracy-0.4: 0.5926188176105743\n",
      "\tbalanced_accuracy-0.3: 0.606493126383713\n",
      "\tbalanced_accuracy-0.2: 0.6237727162394577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [07:42<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 train loss:\t0.030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:45<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 val scores:\n",
      "\tf1-0.1: 0.16215474379038622\n",
      "\tf1-0.4: 0.11175814314628367\n",
      "\tf1-0.3: 0.1287866320022398\n",
      "\tf1-0.2: 0.14559821332869446\n",
      "\tcomp_metric-0.1: 0.59595873\n",
      "\tcomp_metric-0.4: 0.60747019\n",
      "\tcomp_metric-0.3: 0.61088935\n",
      "\tcomp_metric-0.2: 0.6055229\n",
      "\tbalanced_accuracy-0.1: 0.6877930571529352\n",
      "\tbalanced_accuracy-0.4: 0.635354002883715\n",
      "\tbalanced_accuracy-0.3: 0.654663264612551\n",
      "\tbalanced_accuracy-0.2: 0.6764531738902231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [07:36<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 train loss:\t0.027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:45<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 val scores:\n",
      "\tf1-0.1: 0.1505942996120673\n",
      "\tf1-0.4: 0.11114010675216307\n",
      "\tf1-0.3: 0.11901302426813193\n",
      "\tf1-0.2: 0.13486983236157427\n",
      "\tcomp_metric-0.1: 0.60675943\n",
      "\tcomp_metric-0.4: 0.61569632\n",
      "\tcomp_metric-0.3: 0.60689447\n",
      "\tcomp_metric-0.2: 0.61350158\n",
      "\tbalanced_accuracy-0.1: 0.6570813153081547\n",
      "\tbalanced_accuracy-0.4: 0.6385276689197753\n",
      "\tbalanced_accuracy-0.3: 0.6489609194616872\n",
      "\tbalanced_accuracy-0.2: 0.6601684061527413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [07:34<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 train loss:\t0.026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:44<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 val scores:\n",
      "\tf1-0.1: 0.19421171922612343\n",
      "\tf1-0.4: 0.13964265924665184\n",
      "\tf1-0.3: 0.15134406695915809\n",
      "\tf1-0.2: 0.17297539655965255\n",
      "\tcomp_metric-0.1: 0.6363768\n",
      "\tcomp_metric-0.4: 0.6307933\n",
      "\tcomp_metric-0.3: 0.6366906\n",
      "\tcomp_metric-0.2: 0.64223401\n",
      "\tbalanced_accuracy-0.1: 0.689635029550626\n",
      "\tbalanced_accuracy-0.4: 0.6467264428669777\n",
      "\tbalanced_accuracy-0.3: 0.661541033765906\n",
      "\tbalanced_accuracy-0.2: 0.6812770472191835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [07:31<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 train loss:\t0.024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:42<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 val scores:\n",
      "\tf1-0.1: 0.28690224130786024\n",
      "\tf1-0.4: 0.26983714885972776\n",
      "\tf1-0.3: 0.2753571856871604\n",
      "\tf1-0.2: 0.2854550760936979\n",
      "\tcomp_metric-0.1: 0.64793041\n",
      "\tcomp_metric-0.4: 0.69731961\n",
      "\tcomp_metric-0.3: 0.68487579\n",
      "\tcomp_metric-0.2: 0.67275955\n",
      "\tbalanced_accuracy-0.1: 0.7455407214736353\n",
      "\tbalanced_accuracy-0.4: 0.7423640102401375\n",
      "\tbalanced_accuracy-0.3: 0.7526250261065794\n",
      "\tbalanced_accuracy-0.2: 0.758434351411963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [07:39<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 train loss:\t0.023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:42<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 val scores:\n",
      "\tf1-0.1: 0.2946613933519787\n",
      "\tf1-0.4: 0.26439997843091456\n",
      "\tf1-0.3: 0.27758825810667725\n",
      "\tf1-0.2: 0.28540951613682464\n",
      "\tcomp_metric-0.1: 0.66281063\n",
      "\tcomp_metric-0.4: 0.69507413\n",
      "\tcomp_metric-0.3: 0.69017093\n",
      "\tcomp_metric-0.2: 0.68296256\n",
      "\tbalanced_accuracy-0.1: 0.7444899795846703\n",
      "\tbalanced_accuracy-0.4: 0.7523785430898147\n",
      "\tbalanced_accuracy-0.3: 0.7610632381275686\n",
      "\tbalanced_accuracy-0.2: 0.7630784890068999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [07:32<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 train loss:\t0.022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:44<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 val scores:\n",
      "\tf1-0.1: 0.31372541445602914\n",
      "\tf1-0.4: 0.2751714586723098\n",
      "\tf1-0.3: 0.29751279139388076\n",
      "\tf1-0.2: 0.3122069845481974\n",
      "\tcomp_metric-0.1: 0.68440083\n",
      "\tcomp_metric-0.4: 0.72020475\n",
      "\tcomp_metric-0.3: 0.71787852\n",
      "\tcomp_metric-0.2: 0.71132752\n",
      "\tbalanced_accuracy-0.1: 0.7601718744481615\n",
      "\tbalanced_accuracy-0.4: 0.7479663814610451\n",
      "\tbalanced_accuracy-0.3: 0.7605264684764387\n",
      "\tbalanced_accuracy-0.2: 0.770465079044059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [07:28<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 train loss:\t0.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:44<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 val scores:\n",
      "\tf1-0.1: 0.3612682957556494\n",
      "\tf1-0.4: 0.3277640506806172\n",
      "\tf1-0.3: 0.338721925154208\n",
      "\tf1-0.2: 0.35055938994529184\n",
      "\tcomp_metric-0.1: 0.69045586\n",
      "\tcomp_metric-0.4: 0.73429276\n",
      "\tcomp_metric-0.3: 0.72148431\n",
      "\tcomp_metric-0.2: 0.7113206\n",
      "\tbalanced_accuracy-0.1: 0.7851551260899097\n",
      "\tbalanced_accuracy-0.4: 0.7712625351214399\n",
      "\tbalanced_accuracy-0.3: 0.7839360691994245\n",
      "\tbalanced_accuracy-0.2: 0.7954382314162467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 185/185 [07:33<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 train loss:\t0.020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:45<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 val scores:\n",
      "\tf1-0.1: 0.37000017576687083\n",
      "\tf1-0.4: 0.3598725197120665\n",
      "\tf1-0.3: 0.3739288758865253\n",
      "\tf1-0.2: 0.38388376033431454\n",
      "\tcomp_metric-0.1: 0.6833308\n",
      "\tcomp_metric-0.4: 0.74028545\n",
      "\tcomp_metric-0.3: 0.73314187\n",
      "\tcomp_metric-0.2: 0.71913055\n",
      "\tbalanced_accuracy-0.1: 0.7632549465146488\n",
      "\tbalanced_accuracy-0.4: 0.7805323504592091\n",
      "\tbalanced_accuracy-0.3: 0.7886386633785687\n",
      "\tbalanced_accuracy-0.2: 0.7886708153171288\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "epochs = 10\n",
    "model.to(device)\n",
    "for e in range(epochs):\n",
    "    epoch_loss = train_epoch(model, optimizer, train_dataloader, device)\n",
    "    print(f'{e} train loss:', f'{np.mean(epoch_loss):.3f}', sep='\\t')\n",
    "    with torch.no_grad():\n",
    "        y_true, y_pred = val_epoch(model, val_dataloader, device)\n",
    "    score_dict = score_pred(\n",
    "        y_true, y_pred,\n",
    "        score_conf=score_conf,\n",
    "        trsh={0.1, 0.2, 0.3, 0.4}\n",
    "    )\n",
    "    torch.save(model, f'{e}_model.pt')\n",
    "    print(f'{e} val scores:')\n",
    "    print(*[\n",
    "        f'\\t{case}: {case_score}' \n",
    "        for case, case_score in score_dict.items()\n",
    "    ], sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "142e219a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T13:41:14.027870Z",
     "iopub.status.busy": "2022-05-10T13:41:14.027043Z",
     "iopub.status.idle": "2022-05-10T13:41:14.379236Z",
     "shell.execute_reply": "2022-05-10T13:41:14.379698Z"
    },
    "papermill": {
     "duration": 1.310739,
     "end_time": "2022-05-10T13:41:14.379846",
     "exception": false,
     "start_time": "2022-05-10T13:41:13.069107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1-0.1': 0.37000017576687083,\n",
       " 'f1-0.25': 0.3777747174069073,\n",
       " 'f1-0.3': 0.3739288758865253,\n",
       " 'f1-0.2': 0.38388376033431454,\n",
       " 'f1-0.15': 0.3776436788848753,\n",
       " 'comp_metric-0.1': 0.6833308,\n",
       " 'comp_metric-0.25': 0.72730619,\n",
       " 'comp_metric-0.3': 0.73314187,\n",
       " 'comp_metric-0.2': 0.71913055,\n",
       " 'comp_metric-0.15': 0.70495069,\n",
       " 'balanced_accuracy-0.1': 0.7632549465146488,\n",
       " 'balanced_accuracy-0.25': 0.790655280497284,\n",
       " 'balanced_accuracy-0.3': 0.7886386633785687,\n",
       " 'balanced_accuracy-0.2': 0.7886708153171288,\n",
       " 'balanced_accuracy-0.15': 0.7810565321406316}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_pred(\n",
    "        y_true, y_pred,\n",
    "        score_conf=score_conf,\n",
    "        trsh={0.1, 0.15, 0.2, 0.25, 0.3}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53633239",
   "metadata": {
    "papermill": {
     "duration": 0.7508,
     "end_time": "2022-05-10T13:41:15.881903",
     "exception": false,
     "start_time": "2022-05-10T13:41:15.131103",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c8871b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T13:41:17.399425Z",
     "iopub.status.busy": "2022-05-10T13:41:17.398614Z",
     "iopub.status.idle": "2022-05-10T13:41:17.404431Z",
     "shell.execute_reply": "2022-05-10T13:41:17.404946Z"
    },
    "papermill": {
     "duration": 0.76182,
     "end_time": "2022-05-10T13:41:17.405159",
     "exception": false,
     "start_time": "2022-05-10T13:41:16.643339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_root, 'scored_birds.json')) as fin:\n",
    "    test_birds = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f30d59b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T13:41:18.925772Z",
     "iopub.status.busy": "2022-05-10T13:41:18.924978Z",
     "iopub.status.idle": "2022-05-10T13:41:18.927568Z",
     "shell.execute_reply": "2022-05-10T13:41:18.927166Z"
    },
    "papermill": {
     "duration": 0.758878,
     "end_time": "2022-05-10T13:41:18.927694",
     "exception": false,
     "start_time": "2022-05-10T13:41:18.168816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, test_folder):\n",
    "        super().__init__()\n",
    "        self.test_folder = test_folder\n",
    "        self.fnames = [f for f in os.listdir(test_folder) if f.endswith('.ogg')]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fpath = os.path.join(self.test_folder, self.fnames[idx])\n",
    "        wav, sr = load_wav(fpath, 0, None)\n",
    "        wav = torch.tensor(wav)\n",
    "        assert (13 * 5 * sr) > len(wav) \n",
    "        wav = wav[:len(wav) // 12 * 12].reshape((12, len(wav) // 12))\n",
    "        return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbd38005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T13:41:20.529632Z",
     "iopub.status.busy": "2022-05-10T13:41:20.529073Z",
     "iopub.status.idle": "2022-05-10T13:41:20.533413Z",
     "shell.execute_reply": "2022-05-10T13:41:20.532989Z"
    },
    "papermill": {
     "duration": 0.809837,
     "end_time": "2022-05-10T13:41:20.533521",
     "exception": false,
     "start_time": "2022-05-10T13:41:19.723684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(os.path.join(data_root, 'test_soundscapes'))\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    drop_last=False,   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebe4ab4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T13:41:22.053252Z",
     "iopub.status.busy": "2022-05-10T13:41:22.051956Z",
     "iopub.status.idle": "2022-05-10T13:41:22.280682Z",
     "shell.execute_reply": "2022-05-10T13:41:22.280246Z"
    },
    "papermill": {
     "duration": 0.997115,
     "end_time": "2022-05-10T13:41:22.280814",
     "exception": false,
     "start_time": "2022-05-10T13:41:21.283699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.23it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "treshold = 0.1\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm(enumerate(test_dataloader)):\n",
    "        batch_size, part_count, part_size = batch.shape\n",
    "        batch = batch.reshape(batch_size * part_count, part_size)\n",
    "        pred = model(batch.to(device))['logits']\n",
    "        pred = pred.cpu().numpy()\n",
    "        pred = pred > treshold\n",
    "        \n",
    "        for j, chunk_pred in enumerate(pred):\n",
    "            inbatch_number = j // part_count\n",
    "            chunk_number = j % part_count + 1\n",
    "            f_idx = i * batch_size + inbatch_number\n",
    "            fname = test_dataset.fnames[f_idx]\n",
    "            prefix = fname.split('.')[0]\n",
    "            sufix = f'{5 * chunk_number}'\n",
    "            \n",
    "            pred_list.extend([{\n",
    "                'row_id': '_'.join([prefix, b, sufix]),\n",
    "                'target': chunk_pred[species2id[b]]\n",
    "            } for b in test_birds])\n",
    "pred_pd = pd.DataFrame(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc3be00e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T13:41:23.815508Z",
     "iopub.status.busy": "2022-05-10T13:41:23.814814Z",
     "iopub.status.idle": "2022-05-10T13:41:23.832168Z",
     "shell.execute_reply": "2022-05-10T13:41:23.832530Z"
    },
    "papermill": {
     "duration": 0.783593,
     "end_time": "2022-05-10T13:41:23.832686",
     "exception": false,
     "start_time": "2022-05-10T13:41:23.049093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_453028782_akiapo_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soundscape_453028782_aniani_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soundscape_453028782_apapan_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soundscape_453028782_barpet_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soundscape_453028782_crehon_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>soundscape_453028782_omao_60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>soundscape_453028782_puaioh_60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>soundscape_453028782_skylar_60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>soundscape_453028782_warwhe1_60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>soundscape_453028782_yefcan_60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              row_id  target\n",
       "0      soundscape_453028782_akiapo_5   False\n",
       "1      soundscape_453028782_aniani_5   False\n",
       "2      soundscape_453028782_apapan_5   False\n",
       "3      soundscape_453028782_barpet_5   False\n",
       "4      soundscape_453028782_crehon_5   False\n",
       "..                               ...     ...\n",
       "247     soundscape_453028782_omao_60   False\n",
       "248   soundscape_453028782_puaioh_60   False\n",
       "249   soundscape_453028782_skylar_60   False\n",
       "250  soundscape_453028782_warwhe1_60   False\n",
       "251   soundscape_453028782_yefcan_60   False\n",
       "\n",
       "[252 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_pd.to_csv(\"submission.csv\", index=False)\n",
    "pred_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6372908",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T13:41:25.598194Z",
     "iopub.status.busy": "2022-05-10T13:41:25.597325Z",
     "iopub.status.idle": "2022-05-10T13:41:25.599142Z",
     "shell.execute_reply": "2022-05-10T13:41:25.599535Z"
    },
    "papermill": {
     "duration": 0.769192,
     "end_time": "2022-05-10T13:41:25.599682",
     "exception": false,
     "start_time": "2022-05-10T13:41:24.830490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def chunk_wav(wav, sr, window_size):\n",
    "#     chunks_count = len(wav) // (window_size * sr)\n",
    "#     chunk_size = window_size * sr\n",
    "#     chunks = []\n",
    "#     for chunk_idx in range(chunks_count):\n",
    "#         left = chunk_idx * sr\n",
    "#         right = min(left + chunk_size, len(wav))\n",
    "#         chunks.append(wav[left:right])\n",
    "#     chunk_tensor = torch.tensor(chunks)\n",
    "#     return chunk_tensor\n",
    "\n",
    "# file_list = os.listdir(os.path.join(data_root, 'test_soundscapes'))\n",
    "\n",
    "# # This is where we will store our results\n",
    "# treshold = 0.5\n",
    "# pred = {'row_id': [], 'target': []}\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     # Process audio files and make predictions\n",
    "#     for fname in file_list:\n",
    "#         prefix = fname.split('.')[0]\n",
    "#         # Complete file path\n",
    "#         fpath = os.path.join(data_root, 'test_soundscapes', fname)\n",
    "#         wav, sr = load_wav(fpath, 0, None)\n",
    "#         chunk_tensor = chunk_wav(wav, sr, window_size=5)\n",
    "\n",
    "#         # Open file with librosa and split signal into 5-second chunks\n",
    "#         # sig, rate = librosa.load(path)\n",
    "#         # ...\n",
    "\n",
    "#         # Let's assume we have a list of 12 audio chunks (1min / 5s == 12 segments)\n",
    "#         chunk_score = model(chunk_tensor.to(device))['logits'].cpu().numpy()\n",
    "\n",
    "#         # Make prediction for each chunk\n",
    "#         # Each scored bird gets a random value in our case\n",
    "#         # since we don't actually have a model\n",
    "#         for i, all_score in enumerate(chunk_score):        \n",
    "#             chunk_end_time = (i + 1) * 5\n",
    "#             for bird in test_birds:\n",
    "\n",
    "#                 # This is our random prediction score for this bird\n",
    "#                 bird_score = all_score[species2id[bird]]\n",
    "\n",
    "#                 # Assemble the row_id which we need to do for each scored bird\n",
    "#                 row_id = prefix + '_' + bird + '_' + str(chunk_end_time)\n",
    "\n",
    "#                 # Put the result into our prediction dict and\n",
    "#                 # apply a \"confidence\" threshold of 0.5\n",
    "#                 pred['row_id'].append(row_id)\n",
    "#                 pred['target'].append(True if bird_score > treshold else False)\n",
    "\n",
    "\n",
    "# # Make a new data frame and look at some results        \n",
    "# results = pd.DataFrame(pred, columns = ['row_id', 'target'])\n",
    "\n",
    "# # Quick sanity check\n",
    "# print(results.head()) \n",
    "    \n",
    "# # Convert our results to csv\n",
    "# results.to_csv(\"submission.csv\", index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee49b1b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-10T13:41:27.124742Z",
     "iopub.status.busy": "2022-05-10T13:41:27.123745Z",
     "iopub.status.idle": "2022-05-10T13:41:27.125764Z",
     "shell.execute_reply": "2022-05-10T13:41:27.126249Z"
    },
    "papermill": {
     "duration": 0.765183,
     "end_time": "2022-05-10T13:41:27.126378",
     "exception": false,
     "start_time": "2022-05-10T13:41:26.361195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_fnames = [f for f in os.listdir(f'{data_root}/test_soundscapes') if f.endswith('.ogg')]\n",
    "# test_pd = []\n",
    "# for fname in test_fnames:\n",
    "#     fpath = os.path.join(data_root, 'test_soundscapes', fname)\n",
    "#     wav, sr = librosa.load(fpath, sr=None)\n",
    "#     prefix = fname.split('.')[0]\n",
    "#     window_size = 5 * sr\n",
    "#     for i, chunk in enumerate(wav[::window_size]):\n",
    "#         end_time = (i + 1) * 5\n",
    "#         samples = [{\n",
    "#             'row_id': f'{prefix}_{b}_{end_time}',\n",
    "#             'file_id': fname,\n",
    "#             'bird': b,\n",
    "#             'end_time': end_time\n",
    "#         } for b in test_birds]\n",
    "#         test_pd.extend(samples)\n",
    "        \n",
    "# test_pd = pd.DataFrame(test_pd)\n",
    "# test_pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5670.396823,
   "end_time": "2022-05-10T13:41:30.699785",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-10T12:07:00.302962",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
